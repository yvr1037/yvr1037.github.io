<!DOCTYPE HTML>
<html lang="zn-en">
    <!-- shw2018 洪卫  modify 2019.08.15-->



<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <meta name="keywords" content="notes of huggingface transformer, 机器学习,深度学习">
    <meta name="baidu-site-verification" content="fmlEuI34ir" />
    <meta name="google-site-verification" content="KeoTn_OFy4ndJwXNmm2gMeQfPhd7alqE9vQDwI32KCY" />
    <meta name="description" content="PerfaceHuggingFace-Transformers手册是开源公司HuggingFace开发的涵盖很多模型的框架。
Transformers(前身是称为pytorch Transformers和pytorch pretrained">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>notes of huggingface transformer | yvr</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.bootcss.com/materialize/1.0.0/css/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.bootcss.com/aos/3.0.0-beta.6/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="https://cdn.bootcss.com/lightgallery/1.6.12/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    
    <style type="text/css">
        
            
            code[class*="language-"],
            pre[class*="language-"] {
                white-space: pre !important;
            }

        
    </style>

    <script src="https://libs.baidu.com/jquery/2.1.4/jquery.min.js"></script>
    <script src="https://sdk.jinrishici.com/v2/browser/jinrishici.js" charset="utf-8"></script>
    
    <script>
        var _hmt = _hmt || [];
        (function () {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?46e79e71af0709a5b9106bf20cecc493";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>

    
    
        <script>
            (function(){
                var bp = document.createElement('script');
                var curProtocol = window.location.protocol.split(':')[0];
                if (curProtocol === 'https') {
                    bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
                }
                else {
                    bp.src = 'http://push.zhanzhang.baidu.com/push.js';
                }
                var s = document.getElementsByTagName("script")[0];
                s.parentNode.insertBefore(bp, s);
            })();
        </script>
    

<meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style><!-- hexo-inject:begin --><!-- hexo-inject:end -->
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head>

    <body>

        <!-- hexo-inject:begin --><!-- hexo-inject:end --><header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/team.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">yvr</span>
                </a>
            </div>
            


<!-- <a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right">
    
    <li class="hide-on-med-and-down">
        <a href="/" class="waves-effect waves-light">
            
            <i class="fa fa-home"></i>
            
            <span>Index</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/tags" class="waves-effect waves-light">
            
            <i class="fa fa-tags"></i>
            
            <span>Tags</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/categories" class="waves-effect waves-light">
            
            <i class="fa fa-bookmark"></i>
            
            <span>Categories</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/archives" class="waves-effect waves-light">
            
            <i class="fa fa-archive"></i>
            
            <span>Archives</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/galleries" class="waves-effect waves-light">
            
            <i class="fa fa-photo"></i>
            
            <span>Galleries</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/about" class="waves-effect waves-light">
            
            <i class="fa fa-user-circle-o"></i>
            
            <span>About</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/contact" class="waves-effect waves-light">
            
            <i class="fa fa-envelope"></i>
            
            <span>Contact</span>
        </a>
    </li>
    
    <li class="hide-on-med-and-down">
        <a href="/friends" class="waves-effect waves-light">
            
            <i class="fa fa-address-book"></i>
            
            <span>Friends</span>
        </a>
    </li>
    
    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="Search"></i>
        </a>
    </li>
</ul> -->

<!-- 支持二级菜单特性 洪卫 shw2018 modify 2019.09.17  -->
<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fa fa-navicon"></i></a>
<ul class="right nav-menu">
    
      <li class="hide-on-med-and-down nav-item" >

        
            <a href="/" class="waves-effect waves-light">
              
                <i class="fa fa-home"></i>
              
              <span>Index</span>
            </a>

            
      </li>
    
      <li class="hide-on-med-and-down nav-item" >

        
            <a href="/tags" class="waves-effect waves-light">
              
                <i class="fa fa-tags"></i>
              
              <span>Tags</span>
            </a>

            
      </li>
    
      <li class="hide-on-med-and-down nav-item" >

        
            <a href="/categories" class="waves-effect waves-light">
              
                <i class="fa fa-bookmark"></i>
              
              <span>Categories</span>
            </a>

            
      </li>
    
      <li class="hide-on-med-and-down nav-item" >

        
            <a href="/archives" class="waves-effect waves-light">
              
                <i class="fa fa-archive"></i>
              
              <span>Archives</span>
            </a>

            
      </li>
    
      <li class="hide-on-med-and-down nav-item" >

        
            <a href="/galleries" class="waves-effect waves-light">
              
                <i class="fa fa-photo"></i>
              
              <span>Galleries</span>
            </a>

            
      </li>
    
      <li class="hide-on-med-and-down nav-item" >

        
            <a href="/about" class="waves-effect waves-light">
              
                <i class="fa fa-user-circle-o"></i>
              
              <span>About</span>
            </a>

            
      </li>
    
      <li class="hide-on-med-and-down nav-item" >

        
            <a href="/contact" class="waves-effect waves-light">
              
                <i class="fa fa-envelope"></i>
              
              <span>Contact</span>
            </a>

            
      </li>
    
      <li class="hide-on-med-and-down nav-item" >

        
            <a href="/friends" class="waves-effect waves-light">
              
                <i class="fa fa-address-book"></i>
              
              <span>Friends</span>
            </a>

            
      </li>
    

    <li>
        <a href="#searchModal" class="modal-trigger waves-effect waves-light">
            <i id="searchIcon" class="fa fa-search" title="Search"></i>
        </a>
    </li>

</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/team.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">yvr</div>
        <div class="logo-desc">
            
            啦啦啦
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li>
            <a href="/" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-home"></i>
                
                Index
            </a>
        </li>
        
        <li>
            <a href="/tags" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-tags"></i>
                
                Tags
            </a>
        </li>
        
        <li>
            <a href="/categories" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-bookmark"></i>
                
                Categories
            </a>
        </li>
        
        <li>
            <a href="/archives" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-archive"></i>
                
                Archives
            </a>
        </li>
        
        <li>
            <a href="/galleries" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-photo"></i>
                
                Galleries
            </a>
        </li>
        
        <li>
            <a href="/about" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-user-circle-o"></i>
                
                About
            </a>
        </li>
        
        <li>
            <a href="/contact" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-envelope"></i>
                
                Contact
            </a>
        </li>
        
        <li>
            <a href="/friends" class="waves-effect waves-light">
                
                <i class="fa fa-fw fa-address-book"></i>
                
                Friends
            </a>
        </li>
        
        
    </ul>

   
   
<!-- 支持二级菜单特性 洪卫 shw2018 modify 2019.09.17  -->
<!-- <ul class="menu-list mobile-menu-list">
    
        <li class="m-nav-item">
                
                    <a href="/" class="waves-effect waves-light">
                        
                        <i class="fa fa-fw fa-home"></i>
                        
                        Index
                    </a>
              
            </li>
        
        <li class="m-nav-item">
                
                    <a href="/tags" class="waves-effect waves-light">
                        
                        <i class="fa fa-fw fa-tags"></i>
                        
                        Tags
                    </a>
              
            </li>
        
        <li class="m-nav-item">
                
                    <a href="/categories" class="waves-effect waves-light">
                        
                        <i class="fa fa-fw fa-bookmark"></i>
                        
                        Categories
                    </a>
              
            </li>
        
        <li class="m-nav-item">
                
                    <a href="/archives" class="waves-effect waves-light">
                        
                        <i class="fa fa-fw fa-archive"></i>
                        
                        Archives
                    </a>
              
            </li>
        
        <li class="m-nav-item">
                
                    <a href="/galleries" class="waves-effect waves-light">
                        
                        <i class="fa fa-fw fa-photo"></i>
                        
                        Galleries
                    </a>
              
            </li>
        
        <li class="m-nav-item">
                
                    <a href="/about" class="waves-effect waves-light">
                        
                        <i class="fa fa-fw fa-user-circle-o"></i>
                        
                        About
                    </a>
              
            </li>
        
        <li class="m-nav-item">
                
                    <a href="/contact" class="waves-effect waves-light">
                        
                        <i class="fa fa-fw fa-envelope"></i>
                        
                        Contact
                    </a>
              
            </li>
        
        <li class="m-nav-item">
                
                    <a href="/friends" class="waves-effect waves-light">
                        
                        <i class="fa fa-fw fa-address-book"></i>
                        
                        Friends
                    </a>
              
            </li>
        

        
    </ul> -->

</div>

        </div>

        
    </nav>

</header>

        
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/23.jpg')">
    <div class="container">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <div class="description center-align post-title">
                        notes of huggingface transformer
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>



<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 20px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- shw2018 洪卫  modify 2019.08.15-->
<!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/transformer/" target="_blank">
                                <span class="chip bg-color">transformer</span>
                            </a>
                        
                            <a href="/tags/pytorch/" target="_blank">
                                <span class="chip bg-color">pytorch</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fa fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/dialogue/" class="post-category" target="_blank">
                                dialogue
                            </a>
                        
                    </div>
                    
                </div>
            </div>
            
            <div class="post-info">
                <div class="post-date info-break-policy">
                    <i class="fa fa-calendar-minus-o fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2021-11-25
                </div>

                <div class="post-author info-break-policy">
                    <i class="fa fa-user-o fa-fw"></i>Author:&nbsp;&nbsp;
                    
                        yvr1037
                    
                </div>

                
                    
                    <div class="info-break-policy">
                        <i class="fa fa-file-word-o fa-fw"></i>Word Count:&nbsp;&nbsp;
                        6.3k
                    </div>
                    

                    
                    <div class="info-break-policy">
                        <i class="fa fa-clock-o fa-fw"></i>Read Times:&nbsp;&nbsp;
                        31 Min
                    </div>
                    
                
                
                
                        <span id="busuanzi_container_site_pv" style='display:none'></span>
                        <i class="fa fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv" ></span>
    
                

            </div>
        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <h4 id="Perface"><a href="#Perface" class="headerlink" title="Perface"></a>Perface</h4><p>HuggingFace-Transformers手册是开源公司HuggingFace开发的涵盖很多模型的框架。</p>
<p>Transformers(前身是称为pytorch Transformers和pytorch pretrained bert)为自然语言理解(NLU)和自然语言生成(NLG)提供了最先进的通用架构(bert,GPT-2,RoBERTTa,XLM,DistileBert,XLNet,CTRL…..),其中超过32个100多种语言的预训练模型并同时支持Tensorflow 2.0和Pytorch两大深度学习框架.</p>
<p>The library was designed with two strong goals in mind:</p>
<ul>
<li><p>Be as easy and fast to use as possible:</p>
<blockquote>
<ul>
<li>We strongly limited the number of user-facing abstractions to learn, in fact, there are almost no abstractions, just three standard classes required to use each model: <a target="_blank" rel="noopener" href="https://huggingface.co/transformers/main_classes/configuration.html">configuration</a>, <a target="_blank" rel="noopener" href="https://huggingface.co/transformers/main_classes/model.html">models</a> and <a target="_blank" rel="noopener" href="https://huggingface.co/transformers/main_classes/tokenizer.html">tokenizer</a>.</li>
<li>All of these classes can be initialized in a simple and unified way from pretrained instances by using a common <code>from_pretrained()</code> instantiation method which will take care of downloading (if needed), caching and loading the related class instance and associated data (configurations’ hyper-parameters, tokenizers’ vocabulary, and models’ weights) from a pretrained checkpoint provided on <a target="_blank" rel="noopener" href="https://huggingface.co/models">Hugging Face Hub</a> or your own saved checkpoint.</li>
<li>On top of those three base classes, the library provides two APIs: <a target="_blank" rel="noopener" href="https://huggingface.co/transformers/main_classes/pipelines.html#transformers.pipeline"><code>pipeline()</code></a> for quickly using a model (plus its associated tokenizer and configuration) on a given task and <a target="_blank" rel="noopener" href="https://huggingface.co/transformers/main_classes/trainer.html#transformers.Trainer"><code>Trainer()</code></a>/<a target="_blank" rel="noopener" href="https://huggingface.co/transformers/main_classes/trainer.html#transformers.TFTrainer"><code>TFTrainer()</code></a> to quickly train or fine-tune a given model.</li>
<li>As a consequence, this library is NOT a modular toolbox of building blocks for neural nets. If you want to extend/build-upon the library, just use regular Python/PyTorch/TensorFlow/Keras modules and inherit from the base classes of the library to reuse functionalities like model loading/saving.</li>
</ul>
</blockquote>
</li>
<li><p>Provide state-of-the-art models with performances as close as possible to the original models:</p>
<blockquote>
<ul>
<li>We provide at least one example for each architecture which reproduces a result provided by the official authors of said architecture.</li>
<li>The code is usually as close to the original code base as possible which means some PyTorch code may be not as <em>pytorchic</em> as it could be as a result of being converted TensorFlow code and vice versa.</li>
</ul>
</blockquote>
</li>
</ul>
<p>这是<a target="_blank" rel="noopener" href="https://huggingface.co/transformers/philosophy.html%E5%AE%98%E7%BD%91%E7%BB%99%E5%87%BA%E7%9A%84%E8%A7%A3%E9%87%8A%EF%BC%9A">https://huggingface.co/transformers/philosophy.html官网给出的解释：</a></p>
<ul>
<li>架构<ul>
<li>使用每个模型都需要三个标准类:<strong>configuration</strong>,<strong>models</strong>,<strong>tokenizer</strong>.model用于指定使用的模型,例如model为bert，那么相应的网络结构是bert的网络结构；configuration是模型具体的架构配置，例如可以配置多头的数量等等,这里配置需要注意的地方就是，如果自定义配置不改变核心网络结构的则仍旧可以使用预训练模型权重，如果配置涉及到核心结构的修改，例如前馈网络的隐层神经元的个数，则无法使用预训练模型权重，这个时候transformers会默认你要重新自己预训练一个模型从而随机初始化整个模型的权重，这是是一种半灵活性的设计.</li>
<li>所有这些类都可以使用通用的from_pretrained()实例化方法，以简单统一的方式从受过训练的实例中初始化，该方法将负责下载（如果需要），缓存和加载相关的类实例以及相关的数据(config的的超参数，tokenizer生成器的词汇表和模型的权重)在 <a href="https://link.zhihu.com/?target=https://huggingface.co/models">Hugging Face Hub</a> 上提供的预先训练的检查点或您自己保存的检查点</li>
<li>在这三个基本类的基础上，该库提供了两个API：<ul>
<li><a href="https://link.zhihu.com/?target=https://huggingface.co/transformers/main_classes/pipelines.html%23transformers.pipeline">pipeline()</a>用于在给定任务上快速使用模型（及其关联的tokenizer和configuration）和 </li>
<li>Trainer或者<a href="https://link.zhihu.com/?target=https://huggingface.co/transformers/main_classes/trainer.html%23transformers.TFTrainer">TF</a>trainer 快速训练或微调给定模型</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>因此<strong>Transformers</strong>不是神经网络构建模块化的模块工具箱。如果要扩展/构建库，只需使用常规的Python / PyTorch / TensorFlow / Keras模块并从库的基类继承即可重用模型加载/保存之类的功能。</p>
<p>现有的预训练模型整体上都属于下面的五个类别：</p>
<h5 id="Decoders-or-autoregressive-models"><a href="#Decoders-or-autoregressive-models" class="headerlink" title="Decoders or autoregressive models"></a>Decoders or autoregressive models</h5><p>自回归模型在经典语言建模任务上进行了预训练：猜测下一个已读完所有先前token的token。它们对应于transformer模型的解码器部分，并且在整个句子的顶部使用了一个掩码，以便注意头只能看到文本中的之前内容，而不能看到其后的内容。尽管可以对这些模型进行微调并在许多任务上取得出色的结果，但其最自然的应用是文本生成。此类模型的典型例子是GPT</p>
<h5 id="Encoders-or-autoencoding-models"><a href="#Encoders-or-autoencoding-models" class="headerlink" title="Encoders or autoencoding models"></a>Encoders or autoencoding models</h5><p>通过以某种方式破坏输入token并尝试重建原始句子来对自编码模型进行预训练。从某种意义上说，它们与transformer中的的编码器相对应，因为它们无需任何掩码即可访问完整的输入。这些模型通常建立整个句子的双向表示。可以对它们进行微调并在许多任务（例如文本生成）上取得出色的结果，但是它们最自然的应用是文本分类或token分类（比如词性标注）。此类模型的典型例子是BERT</p>
<p>自动回归模型和自动编码模型之间的唯一区别在于模型的预训练方式。因此，相同的体系结构既可以用于自动回归模型，也可以用于自动编码模型.</p>
<h5 id="Sequence-to-Sequence-models"><a href="#Sequence-to-Sequence-models" class="headerlink" title="Sequence-to-Sequence models"></a>Sequence-to-Sequence models</h5><p>序列到序列模型将transformers的编码器和解码器同时用于翻译任务或通过将其他任务转换为序列到序列问题来训练得到的。可以将它们微调来适应许多任务（这里应该是说把sequence to sequence的预训练模型的encoder或者decoder单独抽取出来，然后用法就和上面两种模型的用法一致），但最自然的应用是翻译，摘要和问题解答。T5是一个典型的例子.</p>
<h5 id="Multimodal-models"><a href="#Multimodal-models" class="headerlink" title="Multimodal models"></a>Multimodal models</h5><p>多模态模型将文本输入与其他类型的输入（例如图像）混合在一起，并且更特定于给定任务.</p>
<p><img src="https://s2.loli.net/2021/12/23/zu7FbaZfjXMVUyG.png" alt="image-20211125193439861.png"></p>
<p>这种模型没有提供任何预训练权重只是定义了模型的结构.</p>
<h5 id="Retrieval-based-models"><a href="#Retrieval-based-models" class="headerlink" title="Retrieval-based models"></a>Retrieval-based models</h5><p><img src="https://s2.loli.net/2021/12/23/aqH4X5ikoGsVjDp.png" alt="image-20211125193530708.png"></p>
<h4 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h4><p>  The most basic object in the 🤗 Transformers library is the <code>pipeline()</code> function. It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an intelligible answer:</p>
<p>  There are three main steps involved when you pass some text to a pipeline:</p>
<ol>
<li>The text is preprocessed into a format the model can understand.</li>
<li>The preprocessed inputs are passde to the model .</li>
<li>The predictions of the model are post-processed,so you can make sense of them.</li>
</ol>
<p>Some of the currently <strong>available pipelines</strong> are:</p>
<ul>
<li>feature-extraction(get the vector representation of a text)</li>
<li>file-mask</li>
<li>ner(named entity recogniton)</li>
<li>question-answering</li>
<li>sentiment-analysis</li>
<li>summarization</li>
<li>text-generation</li>
<li>translation</li>
<li>zero-shot-classification</li>
</ul>
<h4 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h4><h5 id="Transformer-history"><a href="#Transformer-history" class="headerlink" title="Transformer history"></a>Transformer history</h5><p><img src="https://s6.jpg.cm/2021/12/23/Lbta92.png" alt="Lbta92.png"></p>
<p>The <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">Transformer architecture</a> was introduced in June 2017. The focus of the original research was on translation tasks. This was followed by the introduction of several influential models, including:</p>
<ul>
<li><strong>June 2018</strong>: <a target="_blank" rel="noopener" href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">GPT</a>, the first pretrained Transformer model, used for fine-tuning on various NLP tasks and obtained state-of-the-art results</li>
<li><strong>October 2018</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1810.04805">BERT</a>, another large pretrained model, this one designed to produce better summaries of sentences (more on this in the next chapter!)</li>
<li><strong>February 2019</strong>: <a target="_blank" rel="noopener" href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">GPT-2</a>, an improved (and bigger) version of GPT that was not immediately publicly released due to ethical concerns</li>
<li><strong>October 2019</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1910.01108">DistilBERT</a>, a distilled version of BERT that is 60% faster, 40% lighter in memory, and still retains 97% of BERT’s performance</li>
<li><strong>October 2019</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1910.13461">BART</a> and <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1910.10683">T5</a>, two large pretrained models using the same architecture as the original Transformer model (the first to do so)</li>
<li><strong>May 2020</strong>, <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2005.14165">GPT-3</a>, an even bigger version of GPT-2 that is able to perform well on a variety of tasks without the need for fine-tuning (called <em>zero-shot learning</em>)</li>
</ul>
<p>This list is far from comprehensive, and is just meant to highlight a few of the different kinds of Transformer models. Broadly, they can be grouped into three categories:</p>
<ul>
<li>GPT-like (also called <em>auto-regressive</em> Transformer models)</li>
<li>BERT-like (also called <em>auto-encoding</em> Transformer models)</li>
<li>BART/T5-like (also called <em>sequence-to-sequence</em> Transformer models)</li>
</ul>
<p>We will dive into these families in more depth later on.</p>
<h5 id="Transformers-are-language-models"><a href="#Transformers-are-language-models" class="headerlink" title="Transformers are language models"></a>Transformers are language models</h5><p>All the Transformer models mentioned above (GPT, BERT, BART, T5, etc.) have been trained as <em>language models</em>. This means they have been trained on large amounts of raw text in a self-supervised fashion. <strong>Self-supervised</strong> learning is a type of training in which the objective is automatically computed from the inputs of the model. That means that humans are not needed to label the data!</p>
<p>所有上述提到的模型都已经被训练成了对应的语言模型。这也就是说这些模型以自我监督的方式接受了大量原始文本的训练。自监督学习是一种训练类型，目标是根据模型的输入自动计算的。也就是说不需要人类手动标记数据。</p>
<hr>
<p>This type of model develops a statistical understanding of the language it has been trained on, but it’s not very useful for specific practical tasks. Because of this, the general pretrained model then goes through a process called <em><strong>transfer learning</strong></em>. During this process, the model is fine-tuned in a supervised way — that is, using human-annotated labels — on a given task</p>
<p>这种类型的模型对其所训练的语言有统计理解但对于特定的实际任务不是很有用。因此通用的预训练模型都会经历一个称为<strong>迁移学习</strong>的过程。在这个过程中，模型在给定的任务上以有监督的方式进行微调——即使用人工标注的数据标签。</p>
<hr>
<p>An example of a task is predicting the next word in a sentence having read the <em>n</em> previous words. This is called *<strong>causal language modeling</strong> because the output depends on the past and present inputs, but not the future ones.  </p>
<p>任务的一个实例就是预测已经阅读的前n个单词的句子的下一个单词。这也被称为<strong>因果语言建模</strong>，因为输出取决于过去和现在的输入而不是未来的输入。</p>
<p><img src="https://s6.jpg.cm/2021/12/23/LbtxQH.png" alt="LbtxQH.png"></p>
<p>Another example is <em>masked language modeling</em>, in which the model predicts a masked word in the sentence.</p>
<p>另一个例子是掩码语言建模，其中模型预测句子的掩码词。</p>
<h5 id="Transformer-are-big-models"><a href="#Transformer-are-big-models" class="headerlink" title="Transformer are big models"></a>Transformer are big models</h5><p>Apart from a few outliers (like DistilBERT), the general strategy to achieve better performance is by increasing the models’ sizes as well as the amount of data they are pretrained on.</p>
<p>除了一些特殊(如 DistilBERT)外，实现更好性能的一般策略是增加模型的大小以及预训练的数据量。</p>
<p><img src="https://s6.jpg.cm/2021/12/23/LbtDYL.png" alt="LbtDYL.png"></p>
<p>Unfortunately, training a model, especially a large one, requires a large amount of data. This becomes very costly in terms of time and compute resources. It even translates to environmental impact, as can be seen in the following graph.</p>
<p><img src="https://s6.jpg.cm/2021/12/23/LbtZRU.png" alt="LbtZRU.png"></p>
<h5 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h5><p><em>Pretraining</em> is the act of training a model from scratch: the weights are randomly initialized, and the training starts without any prior knowledge.</p>
<p>预训练是从头开始训练模型的行为：权重随机初始化,训练在没有任何先验知识的情况下开始.</p>
<p><img src="https://s6.jpg.cm/2021/12/23/LbNGuO.png" alt="LbNGuO.png"></p>
<p>This pretraining is usually done on very large amounts of data. Therefore, it requires a very large corpus of data, and training can take up to several weeks.</p>
<p><em>Fine-tuning</em>, on the other hand, is the training done <strong>after</strong> a model has been pretrained. To perform fine-tuning, you first acquire a pretrained language model, then perform additional training with a dataset specific to your task.</p>
<p>微调是在模型预训练后进行的训练。要进行微调，首先需要获得一个预训练的语言模型然后使用特定于任务的数据集进行额外的训练。</p>
<ul>
<li>The pretrained model was already trained on a dataset that has some similarities with the fine-tuning dataset. The fine-tuning process is thus able to take advantage of knowledge acquired by the initial model during pretraining (for instance, with NLP problems, the pretrained model will have some kind of statistical understanding of the language you are using for your task).</li>
<li>Since the pretrained model was already trained on lots of data, the fine-tuning requires way less data to get decent results.</li>
<li>For the same reason, the amount of time and resources needed to get good results are much lower</li>
</ul>
<p>For example, one could leverage a pretrained model trained on the English language and then fine-tune it on an arXiv corpus, resulting in a science/research-based model. The fine-tuning will only require a limited amount of data: the knowledge the pretrained model has acquired is “transferred,” hence the term <em>transfer learning</em>.</p>
<p><img src="https://s6.jpg.cm/2021/12/23/LbNIBw.png" alt="LbNIBw.png"></p>
<p>Fine-tuning a model therefore has lower time, data, financial, and environmental costs. It is also quicker and easier to iterate over different fine-tuning schemes, as the training is less constraining than a full pretraining.</p>
<p>微调模型具有更低的时间,数据,经济和环境成本。迭代不同的微调方案也更快更容易，因为训练比完全预训练的约束更少。</p>
<p>This process will also achieve better results than training from scratch (unless you have lots of data), which is why you should always try to leverage a pretrained model — one as close as possible to the task you have at hand — and fine-tune it.</p>
<h5 id="General-Transformer-Architecture"><a href="#General-Transformer-Architecture" class="headerlink" title="General Transformer Architecture"></a>General Transformer Architecture</h5><p><img src="https://s6.jpg.cm/2021/12/23/LbNLO8.png" alt="LbNLO8.png"></p>
<p>The transformer is based on the attention mechanism.</p>
<p><img src="https://s6.jpg.cm/2021/12/23/LbNR8i.png" alt="LbNR8i.png"></p>
<p>The combination of the two parts is known as an encoder-decoder or a sequence-to-sequence transformer.</p>
<p>The model is primarily composed of two blocks:</p>
<ul>
<li><strong>Encoder (left)</strong>: The encoder receives an input and builds a representation of it (its features). This means that the model is optimized to acquire understanding from the input.</li>
</ul>
<p>编码器接受输入并构建它的表示(其特征)，这意味着模型经过优化以从输入中获取理解。</p>
<ul>
<li><strong>Decoder (right)</strong>: The decoder uses the encoder’s representation (features) along with other inputs to generate a target sequence. This means that the model is optimized for generating outputs.</li>
</ul>
<p>解码器使用编码器的表示(特征)和其他输入生成目标序列，这意味着模型针对生成输出进行优化。</p>
<p>Each of these parts can be used independently, depending on the task:</p>
<ul>
<li><p><strong>Encoder-only models</strong>: Good for tasks that require understanding of the input, such as <strong>sentence classification and named entity recognition.</strong></p>
<p>适用于<strong>需要理解输入的任务，例如句子分类和命名实体识别。</strong></p>
</li>
<li><p><strong>Decoder-only models</strong>: Good for generative tasks such as <strong>text generation</strong>.</p>
<p>适用于<strong>生成任务，例如文本生成</strong></p>
</li>
<li><p><strong>Encoder-decoder models</strong> or <strong>sequence-to-sequence models</strong>: Good for generative tasks that require an input, such as <strong>translation or summarization</strong>.</p>
<p>适用于<strong>需要输入的生成任务，例如翻译或者摘要。</strong> </p>
</li>
</ul>
<h5 id="Atention-layers"><a href="#Atention-layers" class="headerlink" title="Atention layers"></a>Atention layers</h5><p>A key feature of Transformer models is that they are built with special layers called <em>attention layers</em>. In fact, the title of the paper introducing the Transformer architecture was <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">“Attention Is All You Need”</a>! We will explore the details of attention layers later in the course; for now, all you need to know is that this layer will tell the model to pay specific attention to certain words in the sentence you passed it (and more or less ignore the others) when dealing with the representation of each word.</p>
<p>Transformer模型的关键点就是他们由称为注意力层的特殊层构建而成。事实上，提出Transformer架构的论文是”Attention is all your need”。后面会详细探究Attenton layer的细节。</p>
<p>To put this into context, consider the task of translating text from English to French. Given the input “You like this course”, a translation model will need to also attend to the adjacent word “You” to get the proper translation for the word “like”, because in French the verb “like” is conjugated differently depending on the subject. The rest of the sentence, however, is not useful for the translation of that word. In the same vein, when translating “this” the model will also need to pay attention to the word “course”, because “this” translates differently depending on whether the associated noun is masculine or feminine. Again, the other words in the sentence will not matter for the translation of “this”. With more complex sentences (and more complex grammar rules), the model would need to pay special attention to words that might appear farther away in the sentence to properly translate each word.</p>
<h5 id="The-original-architecture"><a href="#The-original-architecture" class="headerlink" title="The original architecture"></a>The original architecture</h5><p>The Transformer architecture was originally designed for translation. During training, the encoder receives inputs (sentences) in a certain language, while the decoder receives the same sentences in the desired target language</p>
<p>Transformer架构最初是为了翻译而设计的,在训练期间，编码器接受某种语言的输入句子，而解码器接受所需目标语言的相同句子。</p>
<ul>
<li><p>In the encoder, the attention layers can use all the words in a sentence (since, as we just saw, the translation of a given word can be dependent on what is after as well as before it in the sentence).</p>
<p>在编码器中，注意力层可以使用句子中的所有单词(给定单词的翻译可以依赖于句子中它之后和之前的内容)</p>
</li>
<li><p>The decoder, however, works sequentially and can only pay attention to the words in the sentence that it has already translated (so, only the words before the word currently being generated). For example, when we have predicted the first three words of the translated target, we give them to the decoder which then uses all the inputs of the encoder to try to predict the fourth word.</p>
<p>解码器是按照顺序工作，只能关注已经翻译的句子中单词。比如，当我们预测翻译目标中的前三个单词时，我们将他们提供给解码器然后解码器使用编码器的所有输入尝试预测第四个单词。</p>
</li>
</ul>
<p>Note that the the first attention layer in a decoder block pays attention to all (past) inputs to the decoder, but the second attention layer uses the output of the encoder. It can thus access the whole input sentence to best predict the current word. This is very useful as different languages can have grammatical rules that put the words in different orders, or some context provided later in the sentence may be helpful to determine the best translation of a given word.</p>
<p>注意，解码器的第一个注意层关注解码器所有过去的输入，但第二个注意层使用编码器的输出。因此，它可以访问整个输入句子以最好的预测当前的单词，这是很有用的因为不同的语言有不同的语法规则，把单词放在不同的顺序或者句子后面提供的上下文可能有助于确定一个给定单词的最佳翻译。</p>
<p>The <em>attention mask</em> can also be used in the encoder/decoder to prevent the model from paying attention to some special words — for instance, the special padding word used to make all the inputs the same length when batching together sentences.</p>
<p><strong>attention mask</strong>也可以运用在编码/解码中，防止模型注意到某些特殊的单词</p>
<h5 id="Architecture-amp-amp-Checkpoints"><a href="#Architecture-amp-amp-Checkpoints" class="headerlink" title="Architecture &amp;&amp; Checkpoints"></a>Architecture &amp;&amp; Checkpoints</h5><p>As we dive into Transformer models in this course, you’ll see mentions of <em>architectures</em> and <em>checkpoints</em> as well as <em>models</em>. These terms all have slightly different meanings:</p>
<ul>
<li><strong>Architecture</strong>: This is the skeleton of the model — the definition of each layer and each operation that happens within the model.</li>
<li><strong>Checkpoints</strong>: These are the weights that will be loaded in a given architecture.</li>
<li><strong>Model</strong>: This is an umbrella term that isn’t as precise as “architecture” or “checkpoint”: it can mean both. This course will specify <em>architecture</em> or <em>checkpoint</em> when it matters to reduce ambiguity.</li>
</ul>
<p>For example, BERT is an architecture while <code>bert-base-cased</code>, a set of weights trained by the Google team for the first release of BERT, is a checkpoint. However, one can say “the BERT model” and “the <code>bert-base-cased</code> model.”</p>
<h4 id="Encoder-models"><a href="#Encoder-models" class="headerlink" title="Encoder models"></a>Encoder models</h4><p>Encoder models use only the encoder of a Transformer model. At each stage, the attention layers can access all the words in the initial sentence. These models are often characterized as having “bi-directional” attention, and are often called <em>auto-encoding models</em>.</p>
<p>Encoder model只使用the transformer model的encoder部分。在每个阶段，attention layers都可以访问初始句子的所有词。这些模型同v行被描述为具有”bi-directional”，通常被称为自编码模型。</p>
<p>The pretraining of these models usually revolves around somehow corrupting a given sentence (for instance, by masking random words in it) and tasking the model with finding or reconstructing the initial sentence.</p>
<p>这些模型的预训练通常围绕某种方式破坏给定的句子(例如，通过屏蔽其中的随机词)，并让模型查找或重构初始句子。</p>
<p>Encoder models are best suited for tasks requiring an understanding of the full sentence, such as sentence classification, named entity recognition (and more generally word classification), and extractive question answering.</p>
<p>编码器模型最适合需要理解完整句子的任务，例如sentence classification,ner(命名实体识别)(以及更加一般的单词分类)和eqa提取式回答.</p>
<h5 id="Representatives-of-this-family-of-models-include"><a href="#Representatives-of-this-family-of-models-include" class="headerlink" title="Representatives of this family of models include:"></a>Representatives of this family of models include:</h5><ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/albert.html">ALBERT</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/bert.html">BERT</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/distilbert.html">DistilBERT</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/electra.html">ELECTRA</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/roberta.html">RoBERTa</a></li>
</ul>
<h4 id="Decoder-models"><a href="#Decoder-models" class="headerlink" title="Decoder models"></a>Decoder models</h4><p>Decoder models use only the decoder of a Transformer model. At each stage, for a given word the attention layers can only access the words positioned before it in the sentence. These models are often called <em>auto-regressive models</em>.</p>
<p>解码器模型仅使用Transformer模型的解码器。在每个阶段，对于给定的单词，注意力层只能访问位于句子之前的单词。这些模型通常被称为自回归模型。</p>
<p>The pretraining of decoder models usually revolves around predicting the next word in the sentence.</p>
<p>解码器模型的预训练通常围绕预测句子中的下一个单词。</p>
<p>These models are best suited for tasks involving text generation.</p>
<p>这些模型最适合设计文本生成的任务.</p>
<h5 id="Representatives-of-this-family-of-models-include-1"><a href="#Representatives-of-this-family-of-models-include-1" class="headerlink" title="Representatives of this family of models include:"></a>Representatives of this family of models include:</h5><ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/ctrl.html">CTRL</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/gpt.html">GPT</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/gpt2.html">GPT-2</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/transformerxl.html">Transformer XL</a></li>
</ul>
<h4 id="Seq-to-Seq-models"><a href="#Seq-to-Seq-models" class="headerlink" title="Seq-to-Seq models"></a>Seq-to-Seq models</h4><p>Encoder-decoder models (also called <em>sequence-to-sequence models</em>) use both parts of the Transformer architecture. At each stage, the attention layers of the encoder can access all the words in the initial sentence, whereas the attention layers of the decoder can only access the words positioned before a given word in the input.</p>
<p>encoder-decoder models(也称为SeqtoSeq models)使用Transformer体系结构的所有部分。在每个阶段，编码器的注意力机制可以访问初始句子的每个单词,而解码器的注意力层只能访问输入中某个单词前面的单词。</p>
<p>The pretraining of these models can be done using the objectives of encoder or decoder models, but usually involves something a bit more complex. For instance, <a target="_blank" rel="noopener" href="https://huggingface.co/t5-base">T5</a> is pretrained by replacing random spans of text (that can contain several words) with a single mask special word, and the objective is then to predict the text that this mask word replaces.</p>
<p>这些模型的预训练可以使用编码器/解码器模型的目标来完成,但通常涉及一些更复杂的东西。例如，T5是通过一个掩码特殊词取代随机文本跨度(可以包含多个单词)进行预训练的，然后目标是预测这个掩码词取代的文本。</p>
<p>Sequence-to-sequence models are best suited for tasks revolving around generating new sentences depending on a given input, such as summarization, translation, or generative question answering.</p>
<p>Seq-to-Seq模型最适合根据给定的输入生成新句子的任务，比如摘要，翻译或者生成式问题回答。</p>
<h5 id="Representatives-of-this-family-of-models-include-2"><a href="#Representatives-of-this-family-of-models-include-2" class="headerlink" title="Representatives of this family of models include:"></a>Representatives of this family of models include:</h5><ul>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/bart.html">BART</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/mbart.html">mBART</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/marian.html">Marian</a></li>
<li><a target="_blank" rel="noopener" href="https://huggingface.co/transformers/model_doc/t5.html">T5</a></li>
</ul>
<h4 id="Bias-and-limitations"><a href="#Bias-and-limitations" class="headerlink" title="Bias and limitations"></a>Bias and limitations</h4><p>If your intent is to use a pretrained model or a fine-tuned version in production, please be aware that, while these models are powerful tools, they come with limitations. The biggest of these is that, to enable pretraining on large amounts of data, researchers often scrape all the content they can find, taking the best as well as the worst of what is available on the internet.</p>
<p>如果打算在production中使用一个预先训练的模型或者经过微调的版本，请注意，尽管这些模型是最强大的工具但是他们也有局限性。其中最大的问题是是为了能够对大量的数据进行训练，研究人员经常搜集他们能够找到的所有内容，并且从互联网上可获得的信息中挑选出最好的和最差的。</p>
<p>Example：<strong>pipeli    ne:fill-mask model:bert-base-uncased</strong></p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

unmasker <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"fill-mask"</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"bert-base-uncased"</span><span class="token punctuation">)</span>
result <span class="token operator">=</span> unmasker<span class="token punctuation">(</span><span class="token string">"This man works as a [MASK]."</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">[</span>r<span class="token punctuation">[</span><span class="token string">"token_str"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> r <span class="token keyword">in</span> result<span class="token punctuation">]</span><span class="token punctuation">)</span>

result <span class="token operator">=</span> unmasker<span class="token punctuation">(</span><span class="token string">"This woman works as a [MASK]."</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">[</span>r<span class="token punctuation">[</span><span class="token string">"token_str"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> r <span class="token keyword">in</span> result<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python"><code class="language-python">Some weights of the model checkpoint at bert<span class="token operator">-</span>base<span class="token operator">-</span>uncased were <span class="token operator">not</span> used when initializing BertForMaskedLM<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'cls.seq_relationship.bias'</span><span class="token punctuation">,</span> <span class="token string">'cls.seq_relationship.weight'</span><span class="token punctuation">]</span>
<span class="token operator">-</span> This IS expected <span class="token keyword">if</span> you are initializing BertForMaskedLM <span class="token keyword">from</span> the checkpoint of a model trained on another task <span class="token operator">or</span> <span class="token keyword">with</span> another architecture <span class="token punctuation">(</span>e<span class="token punctuation">.</span>g<span class="token punctuation">.</span> initializing a BertForSequenceClassification model <span class="token keyword">from</span> a BertForPreTraining model<span class="token punctuation">)</span><span class="token punctuation">.</span>
<span class="token operator">-</span> This IS NOT expected <span class="token keyword">if</span> you are initializing BertForMaskedLM <span class="token keyword">from</span> the checkpoint of a model that you expect to be exactly identical <span class="token punctuation">(</span>initializing a BertForSequenceClassification model <span class="token keyword">from</span> a BertForSequenceClassification model<span class="token punctuation">)</span><span class="token punctuation">.</span>
<span class="token punctuation">[</span><span class="token string">'carpenter'</span><span class="token punctuation">,</span> <span class="token string">'lawyer'</span><span class="token punctuation">,</span> <span class="token string">'farmer'</span><span class="token punctuation">,</span> <span class="token string">'businessman'</span><span class="token punctuation">,</span> <span class="token string">'doctor'</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token string">'nurse'</span><span class="token punctuation">,</span> <span class="token string">'maid'</span><span class="token punctuation">,</span> <span class="token string">'teacher'</span><span class="token punctuation">,</span> <span class="token string">'waitress'</span><span class="token punctuation">,</span> <span class="token string">'prostitute'</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>When asked to fill in the missing word in these two sentences, the model gives only one gender-free answer (waiter/waitress). The others are work occupations usually associated with one specific gender — and yes, prostitute ended up in the top 5 possibilities the model associates with “woman” and “work.” This happens even though BERT is one of the rare Transformer models not built by scraping data from all over the internet, but rather using apparently neutral data (it’s trained on the <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/wikipedia">English Wikipedia</a> and <a target="_blank" rel="noopener" href="https://huggingface.co/datasets/bookcorpus">BookCorpus</a> datasets).</p>
<p>可以通过例子发现,当需要填写这两句话中被屏蔽的单词时,模型只给出了一个不分性别的答案并按照‘man’和‘work’相关联，‘woman’和‘work’相关联可能性最大的前5种可能性中。</p>
<p>When you use these tools, you therefore need to keep in the back of your mind that the original model you are using could very easily generate sexist, racist, or homophobic content. Fine-tuning the model on your data won’t make this intrinsic bias disappear.</p>
<h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><p>In this chapter, you saw how to approach different NLP tasks using the high-level <code>pipeline()</code> function from 🤗 Transformers. You also saw how to search for and use models in the Hub, as well as how to use the Inference API to test the models directly in your browser.</p>
<p>We discussed how Transformer models work at a high level, and talked about the importance of transfer learning and fine-tuning. A key aspect is that you can use the full architecture or only the encoder or decoder, depending on what kind of task you aim to solve. The following table summarizes this:</p>
<p>关键点在于，可以使用完整的transformer架构也可以使用编码器和解码器，具体却决于你要解决的task特点，下表进行简单总结：</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Examples</th>
<th>Tasks</th>
</tr>
</thead>
<tbody><tr>
<td>Encoder</td>
<td>ALBERT, BERT, DistilBERT, ELECTRA, RoBERTa</td>
<td>Sentence classification, named entity recognition, extractive question answering</td>
</tr>
<tr>
<td>Decoder</td>
<td>CTRL, GPT, GPT-2, Transformer XL</td>
<td>Text generation</td>
</tr>
<tr>
<td>Encoder-decoder</td>
<td>BART, T5, Marian, mBART</td>
<td>Summarization, translation, generative question answering</td>
</tr>
</tbody></table>
<h4 id="Using-Transformers"><a href="#Using-Transformers" class="headerlink" title="Using Transformers"></a>Using Transformers</h4><ul>
<li><p><strong>Ease of use</strong>: Downloading, loading, and using a state-of-the-art NLP model for inference can be done in just two lines of code.</p>
<p>下载，加载和使用SOTA的NLP模型进行推理很简单的API调用即可</p>
</li>
<li><p><strong>Flexibility</strong>: At their core, all models are simple PyTorch <code>nn.Module</code> or TensorFlow <code>tf.keras.Model</code> classes and can be handled like any other models in their respective machine learning (ML) frameworks.</p>
<p>其实所有模型都是Pytorch <strong>nn.module</strong>和Tensorflow <strong>tf.keras.model</strong>类，并且可以像各自机器学习框架的任何其他模型一样进行处理。</p>
</li>
<li><p><strong>Simplicity</strong>: Hardly any abstractions are made across the library. The “All in one file” is a core concept: a model’s forward pass is entirely defined in a single file, so that the code itself is understandable and hackable.</p>
</li>
</ul>
<p>This last feature makes 🤗 Transformers quite different from other ML libraries. The models are not built on modules that are shared across files; instead, each model has its own layers. In addition to making the models more approachable and understandable, this allows you to easily experiment on one model without affecting others.</p>
<p>这些模型不是建立在跨文件共享的模块上.</p>
<p>This chapter will begin with an end-to-end example where we use a model and a tokenizer together to replicate the <code>pipeline()</code> function introduced in <a target="_blank" rel="noopener" href="https://huggingface.co/course/chapter1">Chapter 1</a>. Next, we’ll discuss the model API: we’ll dive into the model and configuration classes, and show you how to load a model and how it processes numerical inputs to output predictions.</p>
<p>接下来从一个端到端的例子开始，使用一个模型和分词器来深入理解pipeline函数；稍后，深入讨论模型API：深入研究模型和配置类，并展开如可加载模型以及如何处理数值输入以便输出预测。</p>
<p>Thene’ll look at the tokenizer API, which is the other main component of the <code>pipeline()</code> function. Tokenizers take care of the first and last processing steps, handling the conversion from text to numerical inputs for the neural network, and the conversion back to text when it is needed. Finally, we’ll show you how to handle sending multiple sentences through a model in a prepared batch, then wrap it all up with a closer look at the high-level <code>tokenizer()</code> function.    </p>
<h5 id="Behind-the-pipeline"><a href="#Behind-the-pipeline" class="headerlink" title="Behind the pipeline"></a>Behind the pipeline</h5><p>take a look at the example:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

classifier <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"sentiment-analysis"</span><span class="token punctuation">)</span>
classifier<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>
        <span class="token string">"I've been waiting for a HuggingFace course my whole life."</span><span class="token punctuation">,</span>
        <span class="token string">"I hate this so much!"</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>and obtained:</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token string">'POSITIVE'</span><span class="token punctuation">,</span> <span class="token string">'score'</span><span class="token punctuation">:</span> <span class="token number">0.9598047137260437</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
 <span class="token punctuation">{</span><span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token string">'NEGATIVE'</span><span class="token punctuation">,</span> <span class="token string">'score'</span><span class="token punctuation">:</span> <span class="token number">0.9994558095932007</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<p>As we can see,this pipeline groups together three steps: preprocessing, passing the inputs through the model, and postprocessing:</p>
<p><img src="https://s6.jpg.cm/2021/12/23/Lbo6gW.png" alt="Lbo6gW.png"></p>
<h6 id="Preprocessing-with-a-tokenizer"><a href="#Preprocessing-with-a-tokenizer" class="headerlink" title="Preprocessing with a tokenizer"></a>Preprocessing with a tokenizer</h6><p>Like other neural networks, Transformer models can’t process raw text directly, so the first step of our pipeline is to convert the text inputs into numbers that the model can make sense of. To do this we use a <em>tokenizer</em>, which will be responsible for:</p>
<ul>
<li>Splitting the input into words, subwords, or symbols (like punctuation) that are called <em>tokens</em></li>
<li>Mapping each token to an integer</li>
<li>Adding additional inputs that may be useful to the model</li>
</ul>
<p>All this preprocessing needs to be done in exactly the same way as when the model was pretrained, so we first need to download that information from the <a target="_blank" rel="noopener" href="https://huggingface.co/models">Model Hub</a>. To do this, we use the <code>AutoTokenizer</code> class and its <code>from_pretrained()</code> method. Using the checkpoint name of our model, it will automatically fetch the data associated with the model’s tokenizer and cache it (so it’s only downloaded the first time you run the code below).</p>
<p>​    </p>

            </div>
            <hr/>

            

            <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    <div class="social-share" data-disabled="qzone, qq, weibo, douban"></div>
    
</div>

<script src="/libs/share/js/social-share.min.js"></script>

            
            
            
            <div class="reprint1">
                <p>
                    <span class="reprint1-tip">
                        <i class="fa fa-exclamation-circle"></i>&nbsp;&nbsp;Reprint policy:
                    </span>
                    <a href="http://yvr1037.github.io" class="b-link-green">yvr</a>
                    <i class="fa fa-angle-right fa-lg fa-fw text-color"></i>
                    <a href="/year/11/25/notes-of-huggingface-transformer/" class="b-link-green">notes of huggingface transformer</a>
                </p>
            </div>

        </div>
    </div>

    
        <link rel="stylesheet" href="/libs/gitalk/gitalk.css">
<link rel="stylesheet" href="/css/my-gitalk.css">

<div class="card gitalk-card" data-aos="fade-up">
    <div id="gitalk-container" class="card-content"></div>
</div>

<script src="/libs/gitalk/gitalk.min.js"></script>
<script>
    let gitalk = new Gitalk({
        clientID: 'XXXXXXXXXXXXXXXXXXXXXXXXXXXX',
        clientSecret: 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX',
        repo: 'yvr1037.github.io',
        owner: 'yvr1037',
        admin: ["yvr"],
        id: 'year/11/25/notes-of-huggingface-transformer/',
        distractionFreeMode: false  // Facebook-like distraction free mode
    });

    gitalk.render('gitalk-container');
</script>
    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fa fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/year/12/16/SA-Study/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/7.jpg" class="responsive-img" alt="SA Study">
                        
                        <span class="card-title">SA Study</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            PerfaceSentiment Analysis是nlp领域一个高阶的task之一，这个任务目标是让计算机理解人类的情感世界，而在机器学习的认知智能阶段(三个阶段：计算智能，感知智能，认知智能)。
​    而情感分析任务也算是个分类任务
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="fa fa-clock-o fa-fw icon-date"></i>2021-12-16
                        </span>
                        <span class="publish-author">
                            
                            <i class="fa fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/nlp/" class="post-category" target="_blank">
                                    nlp
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Sentiment-Analysis/" target="_blank">
                        <span class="chip bg-color">Sentiment Analysis</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fa fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/year/11/21/Dialogue-system/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/14.jpg" class="responsive-img" alt="Dialogue_system">
                        
                        <span class="card-title">Dialogue_system</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            NLP领域比较传统和核心的task有很多
下面先介绍Chinese NLP的基本任务:
Co-reference ResolutionBackground

​    Co-reference identifies pieces of te
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="fa fa-clock-o fa-fw icon-date"></i>2021-11-21
                            </span>
                        <span class="publish-author">
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
</article>
</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + 'From: yvr<br />'
            + 'Author: yvr1037<br />'
            + 'Link: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="fa fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fa fa-list"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            // headingsOffset: -205,
            headingSelector: 'h1, h2, h3, h4, h5'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h1, h2, h3, h4, h5').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).slideUp(500);
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).slideDown(500);
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>
    

</main>


        <footer class="page-footer bg-color">
    <div class="container row center-align">
        <div class="col s12 m8 l8 copy-right">
            Copyright&copy; 2021 yvr. 

            <br>
            <span id="sitetime"></span><span class="my-face">ღゝ◡╹)ノ♡</span>
            <br>
            

            
                    
                        <span id="busuanzi_container_site_pv" style="display: none;"></span>
                        总访问量: <span id="busuanzi_value_site_pv" class="white-color"></span>
                    
        
                    
                        <span id="busuanzi_container_site_uv" style="display: none;"></span>
                        人次&nbsp; | &nbsp;访客人数: <span id="busuanzi_value_site_uv" class="white-color"></span> 人
                    
    
            

            
                &nbsp; | &nbsp;字数统计:&nbsp;
                <span class="white-color">44.8k</span> 字
            

            
            <br>

        </div>

        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/yvr1037" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fa fa-github"></i>
    </a>





    <a href="http://wpa.qq.com/msgrd?v=3&uin=1213917304&site=qq&menu=yes" class="tooltipped" target="_blank" data-tooltip="访问我的QQ空间" data-position="top" data-delay="50">
        <i class="fa fa-qq"></i>
    </a>




</div>

    </div>
</footer>

<div class="progress-bar"></div>

<!-- 增加建站时间 -->
<script language=javascript>
    function siteTime() {
        window.setTimeout("siteTime()", 1000);
        var seconds = 1000;
        var minutes = seconds * 60;
        var hours = minutes * 60;
        var days = hours * 24;
        var years = days * 365;
        var today = new Date();
        var todayYear = today.getFullYear();
        var todayMonth = today.getMonth() + 1;
        var todayDate = today.getDate();
        var todayHour = today.getHours();
        var todayMinute = today.getMinutes();
        var todaySecond = today.getSeconds();

        /* Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
        year - 作为date对象的年份，为4位年份值
        month - 0-11之间的整数，做为date对象的月份
        day - 1-31之间的整数，做为date对象的天数
        hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
        minutes - 0-59之间的整数，做为date对象的分钟数
        seconds - 0-59之间的整数，做为date对象的秒数
        microseconds - 0-999之间的整数，做为date对象的毫秒数 */

        var t1 = Date.UTC(2021, 09, 15, 19, 04, 09); //北京时间2021-09-15 19:04:09 
        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
        var diff = t2 - t1;
        var diffYears = Math.floor(diff / years);
        var diffDays = Math.floor((diff / days) - diffYears * 365);
        var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
        var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) / minutes);
        var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours - diffMinutes *
            minutes) / seconds);
        document.getElementById("sitetime").innerHTML = "本站已勉强运行 " + diffYears + " 年 " + diffDays + " 天 " + diffHours +
            " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒" ;
    } /*需要的可以取消*/
    siteTime();
</script>

<!-- 修改不蒜子初始化计数
<script>
    $(document).ready(function () {

        var int = setInterval(fixCount, 50);  // 50ms周期检测函数
        var pvcountOffset = 80000;  // 初始化首次数据
        var uvcountOffset = 20000;

        function fixCount() {
            if (document.getElementById("busuanzi_container_site_pv").style.display != "none") {
                $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + pvcountOffset);
                clearInterval(int);
            }
            if ($("#busuanzi_container_site_pv").css("display") != "none") {
                $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + uvcountOffset); // 加上初始数据 
                clearInterval(int); // 停止检测
            }
        }
    });
</script> -->





        <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fa fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
        <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fa fa-angle-up"></i>
    </a>
</div>


        <script src="https://cdn.bootcss.com/materialize/1.0.0/js/materialize.min.js"></script>
        <script src="https://cdn.bootcss.com/masonry/4.2.2/masonry.pkgd.min.js"></script>
        <script src="https://cdn.bootcss.com/aos/3.0.0-beta.6/aos.js"></script>
        <script src="https://cdn.bootcss.com/scrollprogress/3.0.2/scrollProgress.min.js"></script>
        <script src="https://cdn.bootcss.com/lightgallery/1.6.12/js/lightgallery-all.min.js"></script>
        <script src="/js/matery.js"></script>

        <!-- Global site tag (gtag.js) - Google Analytics -->



        

        
            <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
        

        <!-- 洪卫 shw2018 add 2019.08.28 -->
        <script type="text/javascript">
            var OriginTitile = document.title,
                st;
            document.addEventListener("visibilitychange", function () {
                document.hidden ? (document.title = "看不见我🙈~看不见我🙈~", clearTimeout(st)) : (document.title =
                    "(๑•̀ㅂ•́) ✧被发现了～", st = setTimeout(function () {
                        document.title = OriginTitile
                    }, 3e3))
            })
        </script>

        <!-- 鼠标点击烟花爆炸效果  洪卫 shw2018 add 2019.09.09 -->
        
            <canvas class="fireworks" style="position: fixed; left: 0; top: 0; z-index: 1; pointer-events: none;"></canvas>
            <script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script>
            <script type="text/javascript" src="/js/fireworks.js"></script>
        

        <!-- 背景雪花飘落特效洪卫 shw2018 add 2019.09.10 -->
        
            <script type="text/javascript">
            //只在桌面版网页启用特效
            var windowWidth = $(window).width();
            if (windowWidth > 768) {
                document.write('<script type="text/javascript" src="/js/sakura.js"><\/script>');
            }
            </script>
        

        <!-- 鼠标点击文字特效 洪卫 shw2018 add 2019.09.10-->
        
            <script src="/js/wenzi.js" type="text/javascript"></script>
        

        <!-- 背景雪花飘落特效 洪卫 shw2018 add 2019.09.10 -->
        
            <script type="text/javascript">
                var windowWidth = $(window).width();
                if (windowWidth > 768) {
                    document.write('<script type="text/javascript" src="/js/xuehuapiaoluo.js"><\/script>');
                }
            </script>
        

        <!-- 在线聊天工具  洪卫 shw2018 add 2019.09.11 -->
        
            <script src="//code.tidio.co/xxxxxxxxxxxxxxxxxxxxxxxxxxx.js"></script>
            <!--  在线聊天位置自定义  洪卫 shw2018 add 2019.09.13  -->
            <script> 
                $(document).ready(function () {

                    setInterval(change_Tidio, 50);  
                    function change_Tidio() { 

                        var tidio=$("#tidio-chat iframe");
                        if(tidio.css("display")=="block"&& $(window).width()>977 ){
                            document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" &&$(window).width()>977)>0? "-40px" : ($("div.toc-title").length&&$(window).width()>977)>0?"80px":"20px";   
                            document.getElementById("tidio-chat-iframe").style.right="-15px";   
                            document.getElementById("tidio-chat-iframe").style.height=parseInt(tidio.css("height"))>=520?"520px":tidio.css("height");
                            document.getElementById("tidio-chat-iframe").style.zIndex="997";
                        } 
                        else if(tidio.css("display")=="block"&&$(window).width()>601 &&$(window).width()<992 ){
                            document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && 601< $(window).width()<992)>0? "-40px":"20px" ;   
                            document.getElementById("tidio-chat-iframe").style.right="-15px"; 
                            document.getElementById("tidio-chat-iframe").style.zIndex="997";
                        }
                        else if(tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))<230){
                            document.getElementById("tidio-chat-iframe").style.bottom= ($("div#backTop.top-scroll").css("display")=="none" && $(window).width()<601)>0? "-10px":"45px" ;   
                            document.getElementById("tidio-chat-iframe").style.zIndex="997";
                        }

                        if( tidio.css("display")=="block"&&$(window).width()<601 && parseInt(tidio.css("height"))>=230){
                            document.getElementById("tidio-chat-iframe").style.zIndex="998";
                        }
                    } 
                }); 
            </script>
        

        <!-- 背景 canvas-nest  洪卫 shw 2018  add 2019.09.15-->
        
            <script type="text/javascript">
            var windowWidth = $(window).width();
            if (windowWidth > 992) {
                document.write('<script type="text/javascript" color="0,0,255" pointColor="0,0,255" opacity= "0.8" zIndex="--1" count="150"src="/libs/background/canvas-nest.js"><\/script>');
            }
            </script>
        

        <!-- 背景静止彩带  洪卫 shw 2018  add 2019.09.15-->
        

        <!-- 背景动态彩带 洪卫 shw 2018  add 2019.09.15-->
        
            <script type="text/javascript">
            var windowWidth = $(window).width();
            if (windowWidth > 992) {
                document.write('<script type="text/javascript" src="/libs/background/ribbon-dynamic.js"><\/script>');
            }
            </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
        

    </body>
</html>