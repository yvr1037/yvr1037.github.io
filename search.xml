<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>mmdetection-of-fenghuo-sockets-projects</title>
      <link href="/year/01/23/mmdetection-of-fenghuo-sockets-projects/"/>
      <url>/year/01/23/mmdetection-of-fenghuo-sockets-projects/</url>
      
        <content type="html"><![CDATA[<p>å‚è€ƒäº†ç»„å†…é€¯åŒå­¦åšå®¢(éå¸¸æ„Ÿè°¢):<a href="https://lry89757.github.io/2021/11/09/mmdet-project-of-fenghuo/">https://lry89757.github.io/2021/11/09/mmdet-project-of-fenghuo/</a></p><h4 id="Perface"><a href="#Perface" class="headerlink" title="Perface"></a>Perface</h4><blockquote><p><a href="https://zhuanlan.zhihu.com/p/256344471">https://zhuanlan.zhihu.com/p/256344471</a><br><a href="https://zhuanlan.zhihu.com/p/337375549">https://zhuanlan.zhihu.com/p/337375549</a><br><a href="https://zhuanlan.zhihu.com/p/431215846">https://zhuanlan.zhihu.com/p/431215846</a><br><a href="https://aistudio.baidu.com/paddle/forum/topic/show/990118">https://aistudio.baidu.com/paddle/forum/topic/show/990118</a></p></blockquote><p>â€‹    é¦–å…ˆäº†è§£ä¸€ä¸‹<a href="http://cocodataset.org/">cocoæ•°æ®é›†çš„åˆ¶ä½œ</a>ï¼ŒMS COCOçš„å…¨ç§°æ˜¯Microsoft Common Objects in Contextï¼Œèµ·æºäºå¾®è½¯äº2014å¹´å‡ºèµ„æ ‡æ³¨çš„Microsoft COCOæ•°æ®é›†ã€‚COCOæ•°æ®é›†æ˜¯ä¸€ä¸ªå¤§å‹çš„ã€ä¸°å¯Œçš„ç‰©ä½“æ£€æµ‹ï¼Œåˆ†å‰²å’Œå­—å¹•æ•°æ®é›†ã€‚è¿™ä¸ªæ•°æ®é›†ä»¥scene understandingä¸ºç›®æ ‡ï¼Œä¸»è¦ä»å¤æ‚çš„æ—¥å¸¸åœºæ™¯ä¸­æˆªå–ï¼Œå›¾åƒä¸­çš„ç›®æ ‡é€šè¿‡ç²¾ç¡®çš„segmentationè¿›è¡Œä½ç½®çš„æ ‡å®šã€‚å›¾åƒåŒ…æ‹¬91ç±»ç›®æ ‡ï¼Œ328,000å½±åƒå’Œ2,500,000ä¸ªlabelã€‚æ•°æ®é›†ä¸»è¦è§£å†³3ä¸ªé—®é¢˜ï¼šç›®æ ‡æ£€æµ‹ï¼Œç›®æ ‡ä¹‹é—´çš„ä¸Šä¸‹æ–‡å…³ç³»ï¼Œç›®æ ‡çš„2ç»´ä¸Šçš„ç²¾ç¡®å®šä½.</p><blockquote><p>COCOä¸€å…±æœ‰5ç§ä¸åŒä»»åŠ¡åˆ†ç±»ï¼Œåˆ†åˆ«æ˜¯ç›®æ ‡æ£€æµ‹ã€å…³é”®ç‚¹æ£€æµ‹ã€è¯­ä¹‰åˆ†å‰²ã€åœºæ™¯åˆ†å‰²å’Œå›¾åƒæè¿°ã€‚COCOæ•°æ®é›†çš„æ ‡æ³¨æ–‡ä»¶ä»¥JSONæ ¼å¼ä¿å­˜ï¼Œå®˜æ–¹çš„æ³¨é‡Šæ–‡ä»¶æœ‰ä»¨ captions_type.json instances_type.json person_keypoints_type.jsonï¼Œå…¶ä¸­çš„typeæ˜¯ train/val/test+year</p></blockquote><p>â€‹    socketsæ£€æµ‹ä»»åŠ¡æˆ‘å‚ç…§ä¸€äº›åšå®¢ä¸Šï¼š</p><blockquote><p><a href="https://aistudio.baidu.com/paddle/forum/topic/show/990118">VOCå’ŒCOCOæ•°æ®é›†åˆ¶ä½œ</a></p></blockquote><p>å†™çš„è½¬æ¢åçš„jsonæ–‡ä»¶ä¸­annonationé‡Œé¢çš„<strong>â€˜bboxâ€™</strong>ç¡®å®è½¬æ¢çš„æ—¶å€™å‡ºç°äº†å¾ˆå¤§çš„é—®é¢˜ï¼Œç¬¬ä¸€æ¬¡æ˜¯å…¨éƒ¨æ˜¯0ï¼Œç¬¬äºŒæ¬¡æˆ‘æ²¡æœ‰ç›´æ¥è½¬æ¢è€Œæ˜¯ç›´æ¥æŒ‰ç…§labelme rectangleæ ‡æ³¨æ ¼å¼çš„åæ ‡è®¡ç®—æ¨ç†å‡ºæ¡†çš„ç›¸å…³ä¿¡æ¯ä½†æ˜¯æœ€åè®­ç»ƒè¿˜æ˜¯å‡ºç°äº†å¤§é—®é¢˜,å†™è„šæœ¬è½¬cocoæ ¼å¼è¿™æ¡è·¯ç›®å‰åœ¨æˆ‘è¿™é‡Œæ˜¯å¤±è´¥äº†ï¼Œæœ€é‡è¦åšæ£€æµ‹çš„æ•°æ®annotation[â€˜bboxâ€™]æ•°æ®ä¿¡æ¯æ²¡æœ‰è½¬æˆåŠŸçœŸæ˜¯è‡´å‘½çš„ï¼š</p><p><img src="https://s6.jpg.cm/2021/12/23/LbtVF2.png" alt="LbtVF2.png"></p><p>â€‹    </p><p>â€‹    ä¹‹å‰åšçš„å›¾ç‰‡å¤„ç†å¯èƒ½æ˜¯å› ä¸ºæˆ‘è¿˜æ²¡æœ‰å­¦ä¹ å¾ˆå¤šç›®æ ‡æ£€æµ‹æ–¹é¢çš„ä¸œè¥¿ä»¥åŠå·¥ç¨‹èƒ½åŠ›å¤ªå¼±ï¼Œä¸ç®—ä¸€ä¸ªå°é¡¹ç›®åªæ˜¯ä¸€ä¸ªå°ä»»åŠ¡æˆ‘å°±åšäº†å¥½å‡ å¤©æœ€åä¹Ÿæ²¡ç”¨ä¸Šï¼Œå…¶å®è¿˜æ˜¯æ„Ÿè§‰æ²Ÿé€šä¸åŠæ—¶ä¸çŸ¥é“æœ€åè¦è¾¾åˆ°ä»€ä¹ˆæ•ˆæœï¼Œç›´åˆ°æœ€åæ‰æ˜ç™½æ˜¯ä¸ºäº†åç»­ç»„é‡Œæ— è®ºæ˜¯åšæ£€æµ‹è¿˜æ˜¯åˆ†å‰²ä»»åŠ¡æ—¶ä¾¿äºæé«˜ç²¾åº¦è¾¾åˆ°æ£€æµ‹çš„æ›´å¥½çš„æ•ˆæœ.</p><h4 id="mmdet-apiçš„æ¢è®¨"><a href="#mmdet-apiçš„æ¢è®¨" class="headerlink" title="mmdet.apiçš„æ¢è®¨"></a>mmdet.apiçš„æ¢è®¨</h4><blockquote><p>2021.12.20 æ™š 709</p></blockquote><p>è¿ç»­æäº†å‡ å¤©socketsæ•°æ®é›†çš„å¤„ç†éƒ½æ²¡æ•´æ˜ç™½ï¼Œå¥½èœå•Šï¼Œ</p><p>æ˜ç¡®ä»»åŠ¡:åšsocketså›¾ç‰‡æ’å­”çš„ç›®æ ‡æ£€æµ‹å’Œåˆ†ç±»ä»»åŠ¡ï¼š</p><p>å…ˆçœ‹<a href="https://mmdetection.readthedocs.io/en/latest/api.html">mmdetection</a>ä»‹ç»:</p><p><u>æ„Ÿè°¢ğŸ¦ŒåŒå­¦</u>ğŸ‚</p><p>æºç è¿½ç©¶ä¸€ä¸‹ <code>mmdet.apis.inference_detector()</code>,è¿™é‡Œå¤§éƒ¨åˆ†æœ‰åŠ©äºå¿«é€Ÿå®Œæˆé¡¹ç›®å‚è€ƒäº†<a href="https://lry89757.github.io/2021/12/05/feng-huo-xiang-mu-fen-lei-ren-wu-zong-jie/#toc-heading-3">é€¯åŒå­¦</a>è¿™ä¸€éƒ¨åˆ†ï¼Œåé¢è¿˜æ˜¯è¦èŠ±æ—¶é—´è¯»ä¸€ä¸‹mmdetectionå®˜æ–¹æŒ‡å¯¼æ–‡æ¡£.</p><p>dataloader of mmdetection</p><p>è’‹å“¥ä¸€ç›´æ¨èä¸è¦æ¯æ¬¡åšé¡¹ç›®éƒ½æ˜¯è½¬æ¢æˆcoco/vocæ ¼å¼ï¼Œè¿™æ ·æ¯”è¾ƒéº»çƒ¦çš„åŸå› åœ¨äºæ¯æ¬¡labelmeæ ‡æ³¨çš„ä¿¡æ¯æ–‡ä»¶æ ¼å¼å¾ˆæœ‰å¯èƒ½ä¸ä¸€æ ·ï¼Œæ¯æ¬¡è½¬åŒ–éƒ½è¦é‡å†™è„šæœ¬æ˜¯éå¸¸ç—›è‹¦çš„(ä½†æ˜¯æˆ‘è§‰å¾—å‰å‡ æ¬¡è¿˜æ˜¯æœ‰å¿…è¦è½¬æ ¼å¼ç§¯ç´¯ç»éªŒçš„)ï¼Œå½“ç„¶ç°é˜¶æ®µæˆ‘ä¹Ÿä¸ä¼šå†™dataloaderè½¬åŒ–ï¼Œåªèƒ½ç¡¬å†™è½¬åŒ–è„šæœ¬,<span class="github-emoji"><span>ğŸ˜ </span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f620.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>å¥½æ°”å‘€ï¼</p><p>çœ‹äº†ç»„é‡Œå…¶ä»–åŒå­¦çš„åšå®¢(å¼ºçƒˆå®‰åˆ©<a href="https://lry89757.github.io/2021/12/05/feng-huo-xiang-mu-fen-lei-ren-wu-zong-jie/">é€¯åŒå­¦çš„åšå®¢</a>æ˜ç™½MMDetectionéœ€è¦æ·±å…¥ç†è§£Rigistryæœºåˆ¶çš„ï¼Œéœ€è¦å‚ç…§ä¹‹å‰æº¯æºçš„è¿‡ç¨‹å»å¯»æ‰¾ã€‚</p><h5 id="socketsæ’å­”æ•°æ®å†å¤„ç†-thinking"><a href="#socketsæ’å­”æ•°æ®å†å¤„ç†-thinking" class="headerlink" title="socketsæ’å­”æ•°æ®å†å¤„ç†:thinking:"></a>socketsæ’å­”æ•°æ®å†å¤„ç†<span class="github-emoji"><span>ğŸ¤”</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f914.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span></h5><h4 id="socketsæ£€æµ‹"><a href="#socketsæ£€æµ‹" class="headerlink" title="socketsæ£€æµ‹"></a>socketsæ£€æµ‹</h4><blockquote><p>2021.12.21æ™š 709</p></blockquote><p><strong>gyf@ubuntu ~/projects/mmdetection</strong></p><p><code>% python tools/train.py configs/fenghuo/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py</code></p><h5 id="2021-12-21-21-51-09-265-mmdet-INFO-Environment-info"><a href="#2021-12-21-21-51-09-265-mmdet-INFO-Environment-info" class="headerlink" title="2021-12-21 21:51:09,265 - mmdet - INFO - Environment info:"></a>2021-12-21 21:51:09,265 - mmdet - INFO - Environment info:</h5><p>sys.platform: linux<br>Python: 3.9.7 (default, Sep 16 2021, 13:09:58) [GCC 7.5.0]<br>CUDA available: True<br>GPU 0,1,2,3: GeForce RTX 2080 Ti<br>CUDA_HOME: /usr/local/cuda<br>NVCC: Build cuda_11.0_bu.TC445_37.28845127_0<br>GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0<br>PyTorch: 1.10.1<br>PyTorch compiling details: PyTorch built with:</p><ul><li>GCC 7.3</li><li>C++ Version: 201402</li><li>Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications</li><li>Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)</li><li>OpenMP 201511 (a.k.a. OpenMP 4.5)</li><li>LAPACK is enabled (usually provided by MKL)</li><li>NNPACK is enabled</li><li>CPU capability usage: AVX2</li><li>CUDA Runtime 11.3</li><li>NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37</li><li>CuDNN 8.2</li><li>Magma 2.5.2</li><li>Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON,</li></ul><p>TorchVision: 0.11.2<br>OpenCV: 4.5.4<br>MMCV: 1.4.0<br>MMCV Compiler: GCC 7.3<br>MMCV CUDA Compiler: 11.3</p><h5 id="MMDetection-2-18-0-6cf9aa1"><a href="#MMDetection-2-18-0-6cf9aa1" class="headerlink" title="MMDetection: 2.18.0+6cf9aa1"></a>MMDetection: 2.18.0+6cf9aa1</h5><p>2021-12-21 21:51:10,501 - mmdet - INFO - Distributed training: False<br>2021-12-21 21:51:11,750 - mmdet - INFO - Config:<br>model = dict(<br>    type=â€™MaskRCNNâ€™,<br>    backbone=dict(<br>        type=â€™ResNetâ€™,<br>        depth=50,<br>        num_stages=4,<br>        out_indices=(0, 1, 2, 3),<br>        frozen_stages=1,<br>        norm_cfg=dict(type=â€™BNâ€™, requires_grad=False),<br>        norm_eval=True,<br>        style=â€™caffeâ€™,<br>        init_cfg=dict(<br>            type=â€™Pretrainedâ€™,<br>            checkpoint=â€™open-mmlab://detectron2/resnet50_caffeâ€™)),<br>    neck=dict(<br>        type=â€™FPNâ€™,<br>        in_channels=[256, 512, 1024, 2048],<br>        out_channels=256,<br>        num_outs=5),<br>    rpn_head=dict(<br>        type=â€™RPNHeadâ€™,<br>        in_channels=256,<br>        feat_channels=256,<br>        anchor_generator=dict(<br>            type=â€™AnchorGeneratorâ€™,<br>            scales=[8],<br>            ratios=[0.5, 1.0, 2.0],<br>            strides=[4, 8, 16, 32, 64]),<br>        bbox_coder=dict(<br>            type=â€™DeltaXYWHBBoxCoderâ€™,<br>            target_means=[0.0, 0.0, 0.0, 0.0],<br>            target_stds=[1.0, 1.0, 1.0, 1.0]),<br>        loss_cls=dict(<br>            type=â€™CrossEntropyLossâ€™, use_sigmoid=True, loss_weight=1.0),<br>        loss_bbox=dict(type=â€™L1Lossâ€™, loss_weight=1.0)),<br>    roi_head=dict(<br>        type=â€™StandardRoIHeadâ€™,<br>        bbox_roi_extractor=dict(<br>            type=â€™SingleRoIExtractorâ€™,<br>            roi_layer=dict(type=â€™RoIAlignâ€™, output_size=7, sampling_ratio=0),<br>            out_channels=256,<br>            featmap_strides=[4, 8, 16, 32]),<br>        bbox_head=dict(<br>            type=â€™Shared2FCBBoxHeadâ€™,<br>            in_channels=256,<br>            fc_out_channels=1024,<br>            roi_feat_size=7,<br>            num_classes=8,<br>            bbox_coder=dict(<br>                type=â€™DeltaXYWHBBoxCoderâ€™,<br>                target_means=[0.0, 0.0, 0.0, 0.0],<br>                target_stds=[0.1, 0.1, 0.2, 0.2]),<br>            reg_class_agnostic=False,<br>            loss_cls=dict(<br>                type=â€™CrossEntropyLossâ€™, use_sigmoid=False, loss_weight=1.0),<br>            loss_bbox=dict(type=â€™L1Lossâ€™, loss_weight=1.0)),<br>        mask_roi_extractor=dict(<br>            type=â€™SingleRoIExtractorâ€™,<br>            roi_layer=dict(type=â€™RoIAlignâ€™, output_size=14, sampling_ratio=0),<br>            out_channels=256,<br>            featmap_strides=[4, 8, 16, 32]),<br>        mask_head=dict(<br>            type=â€™FCNMaskHeadâ€™,<br>            num_convs=4,<br>            in_channels=256,<br>            conv_out_channels=256,<br>            num_classes=8,<br>            loss_mask=dict(<br>                type=â€™CrossEntropyLossâ€™, use_mask=True, loss_weight=1.0))),<br>    train_cfg=dict(<br>        rpn=dict(<br>            assigner=dict(<br>                type=â€™MaxIoUAssignerâ€™,<br>                pos_iou_thr=0.7,<br>                neg_iou_thr=0.3,<br>                min_pos_iou=0.3,<br>                match_low_quality=True,<br>                ignore_iof_thr=-1),<br>            sampler=dict(<br>                type=â€™RandomSamplerâ€™,<br>                num=256,<br>                pos_fraction=0.5,<br>                neg_pos_ub=-1,<br>                add_gt_as_proposals=False),<br>            allowed_border=-1,<br>            pos_weight=-1,<br>            debug=False),<br>        rpn_proposal=dict(<br>            nms_pre=2000,<br>            max_per_img=1000,<br>            nms=dict(type=â€™nmsâ€™, iou_threshold=0.7),<br>            min_bbox_size=0),<br>        rcnn=dict(<br>            assigner=dict(<br>                type=â€™MaxIoUAssignerâ€™,<br>                pos_iou_thr=0.5,<br>                neg_iou_thr=0.5,<br>                min_pos_iou=0.5,<br>                match_low_quality=True,<br>                ignore_iof_thr=-1),<br>            sampler=dict(<br>                type=â€™RandomSamplerâ€™,<br>                num=512,<br>                pos_fraction=0.25,<br>                neg_pos_ub=-1,<br>                add_gt_as_proposals=True),<br>            mask_size=28,<br>            pos_weight=-1,<br>            debug=False)),<br>    test_cfg=dict(<br>        rpn=dict(<br>            nms_pre=1000,<br>            max_per_img=1000,<br>            nms=dict(type=â€™nmsâ€™, iou_threshold=0.7),<br>            min_bbox_size=0),<br>        rcnn=dict(<br>            score_thr=0.05,<br>            nms=dict(type=â€™nmsâ€™, iou_threshold=0.5),<br>            max_per_img=100,<br>            mask_thr_binary=0.5)))<br>dataset_type = â€˜COCODatasetâ€™<br>data_root = â€˜data/coco/â€˜<br>img_norm_cfg = dict(<br>    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)<br>train_pipeline = [<br>    dict(type=â€™LoadImageFromFileâ€™),<br>    dict(<br>        type=â€™LoadAnnotationsâ€™,<br>        with_bbox=True,<br>        with_mask=True,<br>        poly2mask=False),<br>    dict(<br>        type=â€™Resizeâ€™,<br>        img_scale=[(1333, 640), (1333, 672), (1333, 704), (1333, 736),<br>                   (1333, 768), (1333, 800)],<br>        multiscale_mode=â€™valueâ€™,<br>        keep_ratio=True),<br>    dict(type=â€™RandomFlipâ€™, flip_ratio=0.5),<br>    dict(<br>        type=â€™Normalizeâ€™,<br>        mean=[103.53, 116.28, 123.675],<br>        std=[1.0, 1.0, 1.0],<br>        to_rgb=False),<br>    dict(type=â€™Padâ€™, size_divisor=32),<br>    dict(type=â€™DefaultFormatBundleâ€™),<br>    dict(type=â€™Collectâ€™, keys=[â€˜imgâ€™, â€˜gt_bboxesâ€™, â€˜gt_labelsâ€™, â€˜gt_masksâ€™])<br>]<br>test_pipeline = [<br>    dict(type=â€™LoadImageFromFileâ€™),<br>    dict(<br>        type=â€™MultiScaleFlipAugâ€™,<br>        img_scale=(1333, 800),<br>        flip=False,<br>        transforms=[<br>            dict(type=â€™Resizeâ€™, keep_ratio=True),<br>            dict(type=â€™RandomFlipâ€™),<br>            dict(<br>                type=â€™Normalizeâ€™,<br>                mean=[103.53, 116.28, 123.675],<br>                std=[1.0, 1.0, 1.0],<br>                to_rgb=False),<br>            dict(type=â€™Padâ€™, size_divisor=32),<br>            dict(type=â€™ImageToTensorâ€™, keys=[â€˜imgâ€™]),<br>            dict(type=â€™Collectâ€™, keys=[â€˜imgâ€™])<br>        ])<br>]<br>data = dict(<br>    samples_per_gpu=2,<br>    workers_per_gpu=2,<br>    train=dict(<br>        type=â€™CocoDatasetâ€™,<br>        ann_file=<br>        â€˜/home/gyf/projects/mmdetection/data/sockets/train/annotation_coco.jsonâ€™,<br>        img_prefix=â€™/home/gyf/projects/mmdetection/data/sockets/train/â€˜,<br>        pipeline=[<br>            dict(type=â€™LoadImageFromFileâ€™),<br>            dict(<br>                type=â€™LoadAnnotationsâ€™,<br>                with_bbox=True,<br>                with_mask=True,<br>                poly2mask=False),<br>            dict(<br>                type=â€™Resizeâ€™,<br>                img_scale=[(1333, 640), (1333, 672), (1333, 704), (1333, 736),<br>                           (1333, 768), (1333, 800)],<br>                multiscale_mode=â€™valueâ€™,<br>                keep_ratio=True),<br>            dict(type=â€™RandomFlipâ€™, flip_ratio=0.5),<br>            dict(<br>                type=â€™Normalizeâ€™,<br>                mean=[103.53, 116.28, 123.675],<br>                std=[1.0, 1.0, 1.0],<br>                to_rgb=False),<br>            dict(type=â€™Padâ€™, size_divisor=32),<br>            dict(type=â€™DefaultFormatBundleâ€™),<br>            dict(<br>                type=â€™Collectâ€™,<br>                keys=[â€˜imgâ€™, â€˜gt_bboxesâ€™, â€˜gt_labelsâ€™, â€˜gt_masksâ€™])<br>        ],<br>        classes=(â€˜out1â€™, â€˜out2â€™, â€˜out3â€™, â€˜in1â€™, â€˜in2â€™, â€˜in3â€™, â€˜2â€™, â€˜â€™)),<br>    val=dict(<br>        type=â€™CocoDatasetâ€™,<br>        ann_file=<br>        â€˜/home/gyf/projects/mmdetection/data/sockets/val/annotation_coco.jsonâ€™,<br>        img_prefix=â€™/home/gyf/projects/mmdetection/data/sockets/val/â€˜,<br>        pipeline=[<br>            dict(type=â€™LoadImageFromFileâ€™),<br>            dict(<br>                type=â€™MultiScaleFlipAugâ€™,<br>                img_scale=(1333, 800),<br>                flip=False,<br>                transforms=[<br>                    dict(type=â€™Resizeâ€™, keep_ratio=True),<br>                    dict(type=â€™RandomFlipâ€™),<br>                    dict(<br>                        type=â€™Normalizeâ€™,<br>                        mean=[103.53, 116.28, 123.675],<br>                        std=[1.0, 1.0, 1.0],<br>                        to_rgb=False),<br>                    dict(type=â€™Padâ€™, size_divisor=32),<br>                    dict(type=â€™ImageToTensorâ€™, keys=[â€˜imgâ€™]),<br>                    dict(type=â€™Collectâ€™, keys=[â€˜imgâ€™])<br>                ])<br>        ],<br>        classes=(â€˜out1â€™, â€˜out2â€™, â€˜out3â€™, â€˜in1â€™, â€˜in2â€™, â€˜in3â€™, â€˜2â€™, â€˜â€™)),<br>    test=dict(<br>        type=â€™CocoDatasetâ€™,<br>        ann_file=<br>        â€˜/home/gyf/projects/mmdetection/data/sockets/val/annotation_coco.jsonâ€™,<br>        img_prefix=â€™/home/gyf/projects/mmdetection/data/sockets/val/â€˜,<br>        pipeline=[<br>            dict(type=â€™LoadImageFromFileâ€™),<br>            dict(<br>                type=â€™MultiScaleFlipAugâ€™,<br>                img_scale=(1333, 800),<br>                flip=False,<br>                transforms=[<br>                    dict(type=â€™Resizeâ€™, keep_ratio=True),<br>                    dict(type=â€™RandomFlipâ€™),<br>                    dict(<br>                        type=â€™Normalizeâ€™,<br>                        mean=[103.53, 116.28, 123.675],<br>                        std=[1.0, 1.0, 1.0],<br>                        to_rgb=False),<br>                    dict(type=â€™Padâ€™, size_divisor=32),<br>                    dict(type=â€™ImageToTensorâ€™, keys=[â€˜imgâ€™]),<br>                    dict(type=â€™Collectâ€™, keys=[â€˜imgâ€™])<br>                ])<br>        ],<br>        classes=(â€˜out1â€™, â€˜out2â€™, â€˜out3â€™, â€˜in1â€™, â€˜in2â€™, â€˜in3â€™, â€˜2â€™, â€˜â€™)))<br>evaluation = dict(metric=[â€˜bboxâ€™, â€˜segmâ€™])<br>optimizer = dict(type=â€™SGDâ€™, lr=0.02, momentum=0.9, weight_decay=0.0001)<br>optimizer_config = dict(grad_clip=None)<br>lr_config = dict(<br>    policy=â€™stepâ€™,<br>    warmup=â€™linearâ€™,<br>    warmup_iters=500,<br>    warmup_ratio=0.001,<br>    step=[8, 11])<br>runner = dict(type=â€™EpochBasedRunnerâ€™, max_epochs=12)<br>checkpoint_config = dict(interval=1)<br>log_config = dict(interval=50, hooks=[dict(type=â€™TextLoggerHookâ€™)])<br>custom_hooks = [dict(type=â€™NumClassCheckHookâ€™)]<br>dist_params = dict(backend=â€™ncclâ€™)<br>log_level = â€˜INFOâ€™<br>load_from = â€˜/home/gyf/projects/mmdetection/checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pthâ€™<br>resume_from = None<br>workflow = [(â€˜trainâ€™, 1)]<br>classes = (â€˜out1â€™, â€˜out2â€™, â€˜out3â€™, â€˜in1â€™, â€˜in2â€™, â€˜in3â€™, â€˜2â€™, â€˜â€™)<br>work_dir = â€˜./work_dirs/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_socketsâ€™<br>gpu_ids = range(0, 1)</p><p>2021-12-21 21:51:11,751 - mmdet - INFO - Set random seed to 1229834670, deterministic: False<br>2021-12-21 21:51:12,198 - mmdet - INFO - initialize ResNet with init_cfg {â€˜typeâ€™: â€˜Pretrainedâ€™, â€˜checkpointâ€™: â€˜open-mmlab://detectron2/resnet50_caffeâ€™}<br>2021-12-21 21:51:12,198 - mmcv - INFO - load model from: open-mmlab://detectron2/resnet50_caffe<br>2021-12-21 21:51:12,199 - mmcv - INFO - load checkpoint from openmmlab path: open-mmlab://detectron2/resnet50_caffe<br>2021-12-21 21:51:12,307 - mmcv - WARNING - The model and loaded state dict do not match exactly</p><p>unexpected key in source state_dict: conv1.bias</p><p>2021-12-21 21:51:12,340 - mmdet - INFO - initialize FPN with init_cfg {â€˜typeâ€™: â€˜Xavierâ€™, â€˜layerâ€™: â€˜Conv2dâ€™, â€˜distributionâ€™: â€˜uniformâ€™}<br>2021-12-21 21:51:12,383 - mmdet - INFO - initialize RPNHead with init_cfg {â€˜typeâ€™: â€˜Normalâ€™, â€˜layerâ€™: â€˜Conv2dâ€™, â€˜stdâ€™: 0.01}<br>2021-12-21 21:51:12,391 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{â€˜typeâ€™: â€˜Normalâ€™, â€˜stdâ€™: 0.01, â€˜overrideâ€™: {â€˜nameâ€™: â€˜fc_clsâ€™}}, {â€˜typeâ€™: â€˜Normalâ€™, â€˜stdâ€™: 0.001, â€˜overrideâ€™: {â€˜nameâ€™: â€˜fc_regâ€™}}, {â€˜typeâ€™: â€˜Xavierâ€™, â€˜overrideâ€™: [{â€˜nameâ€™: â€˜shared_fcsâ€™}, {â€˜nameâ€™: â€˜cls_fcsâ€™}, {â€˜nameâ€™: â€˜reg_fcsâ€™}]}]<br>loading annotations into memoryâ€¦<br>Done (t=0.02s)<br>creating indexâ€¦<br>index created!<br>loading annotations into memoryâ€¦<br>Done (t=0.01s)<br>creating indexâ€¦<br>index created!<br>2021-12-21 21:51:15,458 - mmdet - INFO - load checkpoint from local path: /home/gyf/projects/mmdetection/checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth<br>2021-12-21 21:51:15,617 - mmdet - WARNING - The model and loaded state dict do not match exactly</p><p>size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([9, 1024]).<br>size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([9]).<br>size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([32, 1024]).<br>size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([32]).<br>size mismatch for roi_head.mask_head.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([8, 256, 1, 1]).<br>size mismatch for roi_head.mask_head.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([8]).<br>2021-12-21 21:51:15,623 - mmdet - INFO - Start running, host: gyf@ubuntu, work_dir: /mnt/data01/home/gyf/projects/mmdetection/work_dirs/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets<br>2021-12-21 21:51:15,623 - mmdet - INFO - Hooks will be executed in the following order:<br>before_run:<br>(VERY_HIGH   ) StepLrUpdaterHook<br>(NORMAL      ) CheckpointHook<br>(LOW         ) EvalHook<br>(VERY_LOW    ) TextLoggerHook</p><hr><p>before_train_epoch:<br>(VERY_HIGH   ) StepLrUpdaterHook<br>(NORMAL      ) NumClassCheckHook<br>(LOW         ) IterTimerHook<br>(LOW         ) EvalHook<br>(VERY_LOW    ) TextLoggerHook</p><p>before_train_iter:<br>(VERY_HIGH   ) StepLrUpdaterHook<br>(LOW         ) IterTimerHook<br>(LOW         ) EvalHook</p><hr><p>after_train_iter:<br>(ABOVE_NORMAL) OptimizerHook<br>(NORMAL      ) CheckpointHook<br>(LOW         ) IterTimerHook<br>(LOW         ) EvalHook<br>(VERY_LOW    ) TextLoggerHook</p><hr><p>after_train_epoch:<br>(NORMAL      ) CheckpointHook<br>(LOW         ) EvalHook<br>(VERY_LOW    ) TextLoggerHook</p><hr><p>before_val_epoch:<br>(NORMAL      ) NumClassCheckHook<br>(LOW         ) IterTimerHook<br>(VERY_LOW    ) TextLoggerHook</p><hr><p>before_val_iter:<br>(LOW         ) IterTimerHook</p><hr><p>after_val_iter:<br>(LOW         ) IterTimerHook</p><hr><p>after_val_epoch:<br>(VERY_LOW    ) TextLoggerHook</p><hr><p>after_run:<br>(VERY_LOW    ) TextLoggerHook</p><hr><p><strong>epochï¼š1</strong></p><pre class="line-numbers language-pyhon"><code class="language-pyhon">2021-12-21 21:51:15,623 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs2021-12-21 21:51:15,623 - mmdet - INFO - Checkpoints will be saved to /mnt/data01/home/gyf/projects/mmdetection/work_dirs/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets by HardDiskBackend.2021-12-21 21:51:30,877 - mmdet - INFO - Epoch [1][50/930]      lr: 1.978e-03, eta: 0:56:09, time: 0.303, data_time: 0.051, memory: 3050, loss_rpn_cls: 0.0593, loss_rpn_bbox: 0.0060, loss_cls: 0.4836, acc: 88.0762, loss_bbox: 0.0283, loss_mask: 0.5316, loss: 1.10882021-12-21 21:51:42,944 - mmdet - INFO - Epoch [1][100/930]     lr: 3.976e-03, eta: 0:50:09, time: 0.241, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0324, loss_rpn_bbox: 0.0057, loss_cls: 0.1005, acc: 98.5547, loss_bbox: 0.0447, loss_mask: 0.3602, loss: 0.54342021-12-21 21:51:54,878 - mmdet - INFO - Epoch [1][150/930]     lr: 5.974e-03, eta: 0:47:54, time: 0.239, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0336, loss_rpn_bbox: 0.0059, loss_cls: 0.0944, acc: 98.4277, loss_bbox: 0.0476, loss_mask: 0.3338, loss: 0.51542021-12-21 21:52:07,173 - mmdet - INFO - Epoch [1][200/930]     lr: 7.972e-03, eta: 0:46:59, time: 0.246, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0321, loss_rpn_bbox: 0.0064, loss_cls: 0.0856, acc: 98.5020, loss_bbox: 0.0430, loss_mask: 0.3231, loss: 0.49022021-12-21 21:52:19,585 - mmdet - INFO - Epoch [1][250/930]     lr: 9.970e-03, eta: 0:46:27, time: 0.248, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0250, loss_rpn_bbox: 0.0052, loss_cls: 0.1124, acc: 97.8770, loss_bbox: 0.0575, loss_mask: 0.3223, loss: 0.52242021-12-21 21:52:31,916 - mmdet - INFO - Epoch [1][300/930]     lr: 1.197e-02, eta: 0:45:58, time: 0.247, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0263, loss_rpn_bbox: 0.0057, loss_cls: 0.1151, acc: 97.8320, loss_bbox: 0.0521, loss_mask: 0.2696, loss: 0.46872021-12-21 21:52:44,130 - mmdet - INFO - Epoch [1][350/930]     lr: 1.397e-02, eta: 0:45:30, time: 0.244, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0306, loss_rpn_bbox: 0.0071, loss_cls: 0.1030, acc: 98.2188, loss_bbox: 0.0496, loss_mask: 0.3332, loss: 0.52352021-12-21 21:52:56,471 - mmdet - INFO - Epoch [1][400/930]     lr: 1.596e-02, eta: 0:45:10, time: 0.247, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0308, loss_rpn_bbox: 0.0069, loss_cls: 0.0996, acc: 98.3027, loss_bbox: 0.0423, loss_mask: 0.3790, loss: 0.55872021-12-21 21:53:09,135 - mmdet - INFO - Epoch [1][450/930]     lr: 1.796e-02, eta: 0:44:59, time: 0.254, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0285, loss_rpn_bbox: 0.0061, loss_cls: 0.1043, acc: 98.0840, loss_bbox: 0.0431, loss_mask: 0.3195, loss: 0.50142021-12-21 21:53:21,833 - mmdet - INFO - Epoch [1][500/930]     lr: 1.996e-02, eta: 0:44:48, time: 0.254, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0290, loss_rpn_bbox: 0.0080, loss_cls: 0.1086, acc: 97.9746, loss_bbox: 0.0502, loss_mask: 0.3295, loss: 0.52522021-12-21 21:53:34,545 - mmdet - INFO - Epoch [1][550/930]     lr: 2.000e-02, eta: 0:44:38, time: 0.254, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0294, loss_rpn_bbox: 0.0069, loss_cls: 0.1129, acc: 97.9414, loss_bbox: 0.0471, loss_mask: 0.3062, loss: 0.50252021-12-21 21:53:46,741 - mmdet - INFO - Epoch [1][600/930]     lr: 2.000e-02, eta: 0:44:18, time: 0.244, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0271, loss_rpn_bbox: 0.0074, loss_cls: 0.1000, acc: 98.1562, loss_bbox: 0.0464, loss_mask: 0.3042, loss: 0.48502021-12-21 21:53:59,443 - mmdet - INFO - Epoch [1][650/930]     lr: 2.000e-02, eta: 0:44:07, time: 0.254, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0268, loss_rpn_bbox: 0.0074, loss_cls: 0.1002, acc: 98.0684, loss_bbox: 0.0420, loss_mask: 0.2872, loss: 0.46362021-12-21 21:54:12,305 - mmdet - INFO - Epoch [1][700/930]     lr: 2.000e-02, eta: 0:43:58, time: 0.257, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0260, loss_rpn_bbox: 0.0057, loss_cls: 0.1047, acc: 97.9590, loss_bbox: 0.0429, loss_mask: 0.2588, loss: 0.43812021-12-21 21:54:24,763 - mmdet - INFO - Epoch [1][750/930]     lr: 2.000e-02, eta: 0:43:43, time: 0.249, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0194, loss_rpn_bbox: 0.0061, loss_cls: 0.0993, acc: 97.9316, loss_bbox: 0.0438, loss_mask: 0.2568, loss: 0.42552021-12-21 21:54:37,189 - mmdet - INFO - Epoch [1][800/930]     lr: 2.000e-02, eta: 0:43:28, time: 0.249, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0247, loss_rpn_bbox: 0.0069, loss_cls: 0.0980, acc: 98.0312, loss_bbox: 0.0462, loss_mask: 0.2838, loss: 0.45962021-12-21 21:54:49,453 - mmdet - INFO - Epoch [1][850/930]     lr: 2.000e-02, eta: 0:43:12, time: 0.245, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0281, loss_rpn_bbox: 0.0059, loss_cls: 0.1013, acc: 98.1250, loss_bbox: 0.0431, loss_mask: 0.2680, loss: 0.44632021-12-21 21:55:02,245 - mmdet - INFO - Epoch [1][900/930]     lr: 2.000e-02, eta: 0:43:02, time: 0.256, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0243, loss_rpn_bbox: 0.0065, loss_cls: 0.1063, acc: 98.0195, loss_bbox: 0.0462, loss_mask: 0.2775, loss: 0.46072021-12-21 21:55:09,711 - mmdet - INFO - Saving checkpoint at 1 epochs[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 764/764, 10.9 task/s, elapsed: 70s, ETA:     0s2021-12-21 21:56:22,062 - mmdet - INFO - Evaluating bbox...Loading and preparing results...DONE (t=0.01s)creating index...index created!Running per image evaluation...Evaluate annotation type *bbox*DONE (t=0.69s).Accumulating evaluation results...DONE (t=0.26s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.017 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.013 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.150 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.013 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.013 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.177 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.177 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.177 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.150 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.213 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.1972021-12-21 21:56:23,045 - mmdet - INFO - Evaluating segm.../mnt/data01/home/gyf/projects/mmdetection/mmdet/datasets/coco.py:450: UserWarning: The key "bbox" is deleted for more accurate mask AP of small/medium/large instances since v2.12.0. This does not change the overall mAP calculation.  warnings.warn(Loading and preparing results...DONE (t=0.06s)creating index...index created!Running per image evaluation...Evaluate annotation type *segm*DONE (t=0.70s).Accumulating evaluation results.../home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/pycocotools/cocoeval.py:378: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)DONE (t=0.27s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.011 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.017 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.012 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.050 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.013 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.013 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.177 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.177 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.177 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.150 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.214 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.1972021-12-21 21:56:24,155 - mmdet - INFO - Exp name: mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py2021-12-21 21:56:24,156 - mmdet - INFO - Epoch(val) [1][764]    bbox_mAP: 0.0110, bbox_mAP_50: 0.0170, bbox_mAP_75: 0.0130, bbox_mAP_s: 0.1500, bbox_mAP_m: 0.0130, bbox_mAP_l: 0.0130, bbox_mAP_copypaste: 0.011 0.017 0.013 0.150 0.013 0.013, segm_mAP: 0.0110, segm_mAP_50: 0.0170, segm_mAP_75: 0.0120, segm_mAP_s: 0.0500, segm_mAP_m: 0.0130, segm_mAP_l: 0.0130, segm_mAP_copypaste: 0.011 0.017 0.012 0.050 0.013 0.013/mnt/data01/home/gyf/projects/mmdetection/mmdet/core/mask/structures.py:1070: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  bitmap_mask = maskUtils.decode(rle).astype(np.bool)/home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/mmcv/runner/hooks/logger/text.py:112: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>Epoch 2:</strong></p><pre><code>2021-12-21 21:56:39,033 - mmdet - INFO - Epoch [2][50/930]      lr: 2.000e-02, eta: 0:41:46, time: 0.296, data_time: 0.052, memory: 3050, loss_rpn_cls: 0.0272, loss_rpn_bbox: 0.0066, loss_cls: 0.0903, acc: 98.1641, loss_bbox: 0.0372, loss_mask: 0.2521, loss: 0.41352021-12-21 21:56:51,349 - mmdet - INFO - Epoch [2][100/930]     lr: 2.000e-02, eta: 0:41:34, time: 0.246, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0257, loss_rpn_bbox: 0.0061, loss_cls: 0.0883, acc: 98.2012, loss_bbox: 0.0378, loss_mask: 0.2791, loss: 0.43692021-12-21 21:57:03,682 - mmdet - INFO - Epoch [2][150/930]     lr: 2.000e-02, eta: 0:41:22, time: 0.246, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0273, loss_rpn_bbox: 0.0063, loss_cls: 0.0983, acc: 98.0742, loss_bbox: 0.0396, loss_mask: 0.2770, loss: 0.44852021-12-21 21:57:16,379 - mmdet - INFO - Epoch [2][200/930]     lr: 2.000e-02, eta: 0:41:13, time: 0.254, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0150, loss_rpn_bbox: 0.0047, loss_cls: 0.1047, acc: 97.8418, loss_bbox: 0.0442, loss_mask: 0.2601, loss: 0.42872021-12-21 21:57:28,914 - mmdet - INFO - Epoch [2][250/930]     lr: 2.000e-02, eta: 0:41:02, time: 0.251, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0230, loss_rpn_bbox: 0.0060, loss_cls: 0.1007, acc: 97.8574, loss_bbox: 0.0425, loss_mask: 0.2352, loss: 0.40742021-12-21 21:57:41,438 - mmdet - INFO - Epoch [2][300/930]     lr: 2.000e-02, eta: 0:40:51, time: 0.250, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0236, loss_rpn_bbox: 0.0066, loss_cls: 0.0974, acc: 97.9766, loss_bbox: 0.0441, loss_mask: 0.2576, loss: 0.42932021-12-21 21:57:53,713 - mmdet - INFO - Epoch [2][350/930]     lr: 2.000e-02, eta: 0:40:38, time: 0.245, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0220, loss_rpn_bbox: 0.0067, loss_cls: 0.0966, acc: 97.9609, loss_bbox: 0.0380, loss_mask: 0.2470, loss: 0.41022021-12-21 21:58:06,207 - mmdet - INFO - Epoch [2][400/930]     lr: 2.000e-02, eta: 0:40:27, time: 0.250, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0248, loss_rpn_bbox: 0.0070, loss_cls: 0.0962, acc: 98.0918, loss_bbox: 0.0447, loss_mask: 0.2851, loss: 0.45782021-12-21 21:58:18,727 - mmdet - INFO - Epoch [2][450/930]     lr: 2.000e-02, eta: 0:40:16, time: 0.251, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0262, loss_rpn_bbox: 0.0078, loss_cls: 0.1020, acc: 97.9570, loss_bbox: 0.0420, loss_mask: 0.2593, loss: 0.43742021-12-21 21:58:31,463 - mmdet - INFO - Epoch [2][500/930]     lr: 2.000e-02, eta: 0:40:06, time: 0.255, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0200, loss_rpn_bbox: 0.0056, loss_cls: 0.1004, acc: 97.9414, loss_bbox: 0.0438, loss_mask: 0.2607, loss: 0.43052021-12-21 21:58:44,207 - mmdet - INFO - Epoch [2][550/930]     lr: 2.000e-02, eta: 0:39:57, time: 0.255, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0206, loss_rpn_bbox: 0.0061, loss_cls: 0.0948, acc: 97.9629, loss_bbox: 0.0432, loss_mask: 0.2799, loss: 0.44452021-12-21 21:58:56,856 - mmdet - INFO - Epoch [2][600/930]     lr: 2.000e-02, eta: 0:39:46, time: 0.253, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0226, loss_rpn_bbox: 0.0078, loss_cls: 0.1000, acc: 97.8359, loss_bbox: 0.0479, loss_mask: 0.2761, loss: 0.45442021-12-21 21:59:09,542 - mmdet - INFO - Epoch [2][650/930]     lr: 2.000e-02, eta: 0:39:35, time: 0.253, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0218, loss_rpn_bbox: 0.0067, loss_cls: 0.1068, acc: 97.7031, loss_bbox: 0.0465, loss_mask: 0.2699, loss: 0.45172021-12-21 21:59:22,348 - mmdet - INFO - Epoch [2][700/930]     lr: 2.000e-02, eta: 0:39:25, time: 0.256, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0189, loss_rpn_bbox: 0.0057, loss_cls: 0.1085, acc: 97.7012, loss_bbox: 0.0498, loss_mask: 0.2500, loss: 0.43292021-12-21 21:59:34,816 - mmdet - INFO - Epoch [2][750/930]     lr: 2.000e-02, eta: 0:39:13, time: 0.250, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0232, loss_rpn_bbox: 0.0063, loss_cls: 0.0955, acc: 97.9648, loss_bbox: 0.0437, loss_mask: 0.2768, loss: 0.44542021-12-21 21:59:47,408 - mmdet - INFO - Epoch [2][800/930]     lr: 2.000e-02, eta: 0:39:02, time: 0.252, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0229, loss_rpn_bbox: 0.0062, loss_cls: 0.0971, acc: 97.8750, loss_bbox: 0.0437, loss_mask: 0.2533, loss: 0.42322021-12-21 21:59:59,688 - mmdet - INFO - Epoch [2][850/930]     lr: 2.000e-02, eta: 0:38:49, time: 0.246, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0183, loss_rpn_bbox: 0.0052, loss_cls: 0.0937, acc: 97.9336, loss_bbox: 0.0432, loss_mask: 0.2523, loss: 0.41272021-12-21 22:00:12,573 - mmdet - INFO - Epoch [2][900/930]     lr: 2.000e-02, eta: 0:38:38, time: 0.258, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0199, loss_rpn_bbox: 0.0059, loss_cls: 0.0975, acc: 97.9297, loss_bbox: 0.0428, loss_mask: 0.2603, loss: 0.42642021-12-21 22:00:20,323 - mmdet - INFO - Saving checkpoint at 2 epochs[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;] 764/764, 9.4 task/s, elapsed: 81s, ETA:     0s2021-12-21 22:01:43,823 - mmdet - INFO - Evaluating bbox...Loading and preparing results...DONE (t=0.11s)creating index...index created!Running per image evaluation...Evaluate annotation type *bbox*DONE (t=0.86s).Accumulating evaluation results...DONE (t=0.34s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.019 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.013 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.150 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.016 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.012 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.201 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.201 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.201 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.150 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.258 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.1942021-12-21 22:01:45,162 - mmdet - INFO - Evaluating segm.../mnt/data01/home/gyf/projects/mmdetection/mmdet/datasets/coco.py:450: UserWarning: The key "bbox" is deleted for more accurate mask AP of small/medium/large instances since v2.12.0. This does not change the overall mAP calculation.  warnings.warn(Loading and preparing results...DONE (t=0.11s)creating index...index created!Running per image evaluation...Evaluate annotation type *segm*DONE (t=0.92s).Accumulating evaluation results.../home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/pycocotools/cocoeval.py:378: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)DONE (t=0.35s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.012 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.019 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.014 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.175 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.015 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.013 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.204 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.204 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.175 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.262 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.1922021-12-21 22:01:46,746 - mmdet - INFO - Exp name: mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py2021-12-21 22:01:46,747 - mmdet - INFO - Epoch(val) [2][764]    bbox_mAP: 0.0120, bbox_mAP_50: 0.0190, bbox_mAP_75: 0.0130, bbox_mAP_s: 0.1500, bbox_mAP_m: 0.0160, bbox_mAP_l: 0.0120, bbox_mAP_copypaste: 0.012 0.019 0.013 0.150 0.016 0.012, segm_mAP: 0.0120, segm_mAP_50: 0.0190, segm_mAP_75: 0.0140, segm_mAP_s: 0.1750, segm_mAP_m: 0.0150, segm_mAP_l: 0.0130, segm_mAP_copypaste: 0.012 0.019 0.014 0.175 0.015 0.013/mnt/data01/home/gyf/projects/mmdetection/mmdet/core/mask/structures.py:1070: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  bitmap_mask = maskUtils.decode(rle).astype(np.bool)/home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/mmcv/runner/hooks/logger/text.py:112: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],</code></pre><p><strong>Epoch 3:</strong></p><pre><code>2021-12-21 22:02:01,913 - mmdet - INFO - Epoch [3][50/930]      lr: 2.000e-02, eta: 0:37:55, time: 0.302, data_time: 0.052, memory: 3050, loss_rpn_cls: 0.0186, loss_rpn_bbox: 0.0054, loss_cls: 0.1044, acc: 97.7559, loss_bbox: 0.0450, loss_mask: 0.2723, loss: 0.44582021-12-21 22:02:14,295 - mmdet - INFO - Epoch [3][100/930]     lr: 2.000e-02, eta: 0:37:43, time: 0.247, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0204, loss_rpn_bbox: 0.0063, loss_cls: 0.0861, acc: 98.1270, loss_bbox: 0.0395, loss_mask: 0.2726, loss: 0.42502021-12-21 22:02:26,634 - mmdet - INFO - Epoch [3][150/930]     lr: 2.000e-02, eta: 0:37:31, time: 0.247, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0221, loss_rpn_bbox: 0.0065, loss_cls: 0.1039, acc: 97.6504, loss_bbox: 0.0467, loss_mask: 0.2384, loss: 0.41772021-12-21 22:02:39,182 - mmdet - INFO - Epoch [3][200/930]     lr: 2.000e-02, eta: 0:37:20, time: 0.251, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0207, loss_rpn_bbox: 0.0058, loss_cls: 0.0923, acc: 97.8906, loss_bbox: 0.0387, loss_mask: 0.2276, loss: 0.38522021-12-21 22:02:51,689 - mmdet - INFO - Epoch [3][250/930]     lr: 2.000e-02, eta: 0:37:08, time: 0.250, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0196, loss_rpn_bbox: 0.0055, loss_cls: 0.0865, acc: 97.9414, loss_bbox: 0.0354, loss_mask: 0.2145, loss: 0.36152021-12-21 22:03:04,108 - mmdet - INFO - Epoch [3][300/930]     lr: 2.000e-02, eta: 0:36:57, time: 0.248, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0237, loss_rpn_bbox: 0.0052, loss_cls: 0.0947, acc: 97.9160, loss_bbox: 0.0409, loss_mask: 0.2321, loss: 0.39662021-12-21 22:03:16,446 - mmdet - INFO - Epoch [3][350/930]     lr: 2.000e-02, eta: 0:36:44, time: 0.247, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0189, loss_rpn_bbox: 0.0056, loss_cls: 0.1081, acc: 97.5762, loss_bbox: 0.0484, loss_mask: 0.2318, loss: 0.41272021-12-21 22:03:28,923 - mmdet - INFO - Epoch [3][400/930]     lr: 2.000e-02, eta: 0:36:33, time: 0.250, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0248, loss_rpn_bbox: 0.0056, loss_cls: 0.1074, acc: 97.6680, loss_bbox: 0.0509, loss_mask: 0.2603, loss: 0.44902021-12-21 22:03:41,569 - mmdet - INFO - Epoch [3][450/930]     lr: 2.000e-02, eta: 0:36:22, time: 0.253, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0211, loss_rpn_bbox: 0.0058, loss_cls: 0.0928, acc: 97.9746, loss_bbox: 0.0404, loss_mask: 0.2682, loss: 0.42832021-12-21 22:03:54,270 - mmdet - INFO - Epoch [3][500/930]     lr: 2.000e-02, eta: 0:36:11, time: 0.254, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0180, loss_rpn_bbox: 0.0053, loss_cls: 0.1024, acc: 97.9609, loss_bbox: 0.0469, loss_mask: 0.2769, loss: 0.44952021-12-21 22:04:07,070 - mmdet - INFO - Epoch [3][550/930]     lr: 2.000e-02, eta: 0:36:00, time: 0.256, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0230, loss_rpn_bbox: 0.0068, loss_cls: 0.1004, acc: 97.8984, loss_bbox: 0.0437, loss_mask: 0.2519, loss: 0.42592021-12-21 22:04:19,619 - mmdet - INFO - Epoch [3][600/930]     lr: 2.000e-02, eta: 0:35:48, time: 0.251, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0226, loss_rpn_bbox: 0.0058, loss_cls: 0.1000, acc: 97.7598, loss_bbox: 0.0415, loss_mask: 0.2337, loss: 0.40362021-12-21 22:04:32,238 - mmdet - INFO - Epoch [3][650/930]     lr: 2.000e-02, eta: 0:35:37, time: 0.252, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0202, loss_rpn_bbox: 0.0061, loss_cls: 0.1085, acc: 97.5664, loss_bbox: 0.0453, loss_mask: 0.2252, loss: 0.40522021-12-21 22:04:45,017 - mmdet - INFO - Epoch [3][700/930]     lr: 2.000e-02, eta: 0:35:26, time: 0.256, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0219, loss_rpn_bbox: 0.0058, loss_cls: 0.1043, acc: 97.6836, loss_bbox: 0.0450, loss_mask: 0.2512, loss: 0.42832021-12-21 22:04:57,497 - mmdet - INFO - Epoch [3][750/930]     lr: 2.000e-02, eta: 0:35:14, time: 0.250, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0217, loss_rpn_bbox: 0.0069, loss_cls: 0.1021, acc: 97.8457, loss_bbox: 0.0493, loss_mask: 0.2673, loss: 0.44732021-12-21 22:05:10,218 - mmdet - INFO - Epoch [3][800/930]     lr: 2.000e-02, eta: 0:35:03, time: 0.254, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0188, loss_rpn_bbox: 0.0059, loss_cls: 0.0950, acc: 97.8027, loss_bbox: 0.0392, loss_mask: 0.2219, loss: 0.38082021-12-21 22:05:22,822 - mmdet - INFO - Epoch [3][850/930]     lr: 2.000e-02, eta: 0:34:51, time: 0.252, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0224, loss_rpn_bbox: 0.0066, loss_cls: 0.0955, acc: 97.7891, loss_bbox: 0.0423, loss_mask: 0.2192, loss: 0.38602021-12-21 22:05:35,648 - mmdet - INFO - Epoch [3][900/930]     lr: 2.000e-02, eta: 0:34:40, time: 0.257, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0281, loss_rpn_bbox: 0.0079, loss_cls: 0.0920, acc: 97.9434, loss_bbox: 0.0442, loss_mask: 0.2602, loss: 0.43242021-12-21 22:05:43,204 - mmdet - INFO - Saving checkpoint at 3 epochs[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;] 764/764, 8.8 task/s, elapsed: 87s, ETA:     0s2021-12-21 22:07:12,110 - mmdet - INFO - Evaluating bbox...Loading and preparing results...DONE (t=0.12s)creating index...index created!Running per image evaluation...Evaluate annotation type *bbox*DONE (t=0.78s).Accumulating evaluation results...DONE (t=0.37s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.016 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.027 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.018 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.200 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.021 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.019 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.252 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.252 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.252 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.200 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.310 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.2382021-12-21 22:07:13,405 - mmdet - INFO - Evaluating segm.../mnt/data01/home/gyf/projects/mmdetection/mmdet/datasets/coco.py:450: UserWarning: The key "bbox" is deleted for more accurate mask AP of small/medium/large instances since v2.12.0. This does not change the overall mAP calculation.  warnings.warn(Loading and preparing results...DONE (t=0.12s)creating index...index created!Running per image evaluation...Evaluate annotation type *segm*DONE (t=0.92s).Accumulating evaluation results.../home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/pycocotools/cocoeval.py:378: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)DONE (t=0.37s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.017 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.027 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.019 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.304 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.020 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.021 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.255 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.255 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.255 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.304 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.321 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.2262021-12-21 22:07:15,042 - mmdet - INFO - Exp name: mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py2021-12-21 22:07:15,042 - mmdet - INFO - Epoch(val) [3][764]    bbox_mAP: 0.0160, bbox_mAP_50: 0.0270, bbox_mAP_75: 0.0180, bbox_mAP_s: 0.2000, bbox_mAP_m: 0.0210, bbox_mAP_l: 0.0190, bbox_mAP_copypaste: 0.016 0.027 0.018 0.200 0.021 0.019, segm_mAP: 0.0170, segm_mAP_50: 0.0270, segm_mAP_75: 0.0190, segm_mAP_s: 0.3040, segm_mAP_m: 0.0200, segm_mAP_l: 0.0210, segm_mAP_copypaste: 0.017 0.027 0.019 0.304 0.020 0.021/mnt/data01/home/gyf/projects/mmdetection/mmdet/core/mask/structures.py:1070: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  bitmap_mask = maskUtils.decode(rle).astype(np.bool)/home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/mmcv/runner/hooks/logger/text.py:112: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],</code></pre><p><strong>Epoch 4:</strong></p><pre><code>2021-12-21 22:07:29,912 - mmdet - INFO - Epoch [4][50/930]      lr: 2.000e-02, eta: 0:34:06, time: 0.295, data_time: 0.052, memory: 3050, loss_rpn_cls: 0.0219, loss_rpn_bbox: 0.0059, loss_cls: 0.0995, acc: 97.8066, loss_bbox: 0.0444, loss_mask: 0.2479, loss: 0.41962021-12-21 22:07:42,387 - mmdet - INFO - Epoch [4][100/930]     lr: 2.000e-02, eta: 0:33:54, time: 0.249, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0207, loss_rpn_bbox: 0.0064, loss_cls: 0.1056, acc: 97.5508, loss_bbox: 0.0485, loss_mask: 0.2601, loss: 0.44132021-12-21 22:07:55,251 - mmdet - INFO - Epoch [4][150/930]     lr: 2.000e-02, eta: 0:33:43, time: 0.258, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0237, loss_rpn_bbox: 0.0062, loss_cls: 0.1223, acc: 97.2949, loss_bbox: 0.0547, loss_mask: 0.2307, loss: 0.43762021-12-21 22:08:07,899 - mmdet - INFO - Epoch [4][200/930]     lr: 2.000e-02, eta: 0:33:32, time: 0.253, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0178, loss_rpn_bbox: 0.0056, loss_cls: 0.1065, acc: 97.6113, loss_bbox: 0.0489, loss_mask: 0.2554, loss: 0.43422021-12-21 22:08:20,486 - mmdet - INFO - Epoch [4][250/930]     lr: 2.000e-02, eta: 0:33:20, time: 0.252, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0219, loss_rpn_bbox: 0.0059, loss_cls: 0.1035, acc: 97.5879, loss_bbox: 0.0446, loss_mask: 0.2369, loss: 0.41282021-12-21 22:08:32,865 - mmdet - INFO - Epoch [4][300/930]     lr: 2.000e-02, eta: 0:33:08, time: 0.248, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0170, loss_rpn_bbox: 0.0064, loss_cls: 0.0853, acc: 98.1484, loss_bbox: 0.0361, loss_mask: 0.2394, loss: 0.38422021-12-21 22:08:45,194 - mmdet - INFO - Epoch [4][350/930]     lr: 2.000e-02, eta: 0:32:56, time: 0.246, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0150, loss_rpn_bbox: 0.0055, loss_cls: 0.1072, acc: 97.4766, loss_bbox: 0.0466, loss_mask: 0.2238, loss: 0.39812021-12-21 22:08:57,715 - mmdet - INFO - Epoch [4][400/930]     lr: 2.000e-02, eta: 0:32:44, time: 0.250, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0186, loss_rpn_bbox: 0.0059, loss_cls: 0.0992, acc: 97.7129, loss_bbox: 0.0450, loss_mask: 0.2251, loss: 0.39382021-12-21 22:09:10,325 - mmdet - INFO - Epoch [4][450/930]     lr: 2.000e-02, eta: 0:32:32, time: 0.253, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0191, loss_rpn_bbox: 0.0057, loss_cls: 0.0976, acc: 97.5684, loss_bbox: 0.0424, loss_mask: 0.2057, loss: 0.37052021-12-21 22:09:23,173 - mmdet - INFO - Epoch [4][500/930]     lr: 2.000e-02, eta: 0:32:21, time: 0.257, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0171, loss_rpn_bbox: 0.0052, loss_cls: 0.1065, acc: 97.6270, loss_bbox: 0.0464, loss_mask: 0.2253, loss: 0.40052021-12-21 22:09:35,986 - mmdet - INFO - Epoch [4][550/930]     lr: 2.000e-02, eta: 0:32:10, time: 0.256, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0180, loss_rpn_bbox: 0.0055, loss_cls: 0.0964, acc: 97.7637, loss_bbox: 0.0405, loss_mask: 0.2360, loss: 0.39642021-12-21 22:09:48,288 - mmdet - INFO - Epoch [4][600/930]     lr: 2.000e-02, eta: 0:31:58, time: 0.246, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0169, loss_rpn_bbox: 0.0061, loss_cls: 0.0825, acc: 97.9883, loss_bbox: 0.0356, loss_mask: 0.2219, loss: 0.36302021-12-21 22:10:00,893 - mmdet - INFO - Epoch [4][650/930]     lr: 2.000e-02, eta: 0:31:46, time: 0.251, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0152, loss_rpn_bbox: 0.0055, loss_cls: 0.0949, acc: 97.8418, loss_bbox: 0.0399, loss_mask: 0.2404, loss: 0.39592021-12-21 22:10:13,555 - mmdet - INFO - Epoch [4][700/930]     lr: 2.000e-02, eta: 0:31:34, time: 0.253, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0132, loss_rpn_bbox: 0.0054, loss_cls: 0.1011, acc: 97.6289, loss_bbox: 0.0451, loss_mask: 0.2521, loss: 0.41682021-12-21 22:10:25,970 - mmdet - INFO - Epoch [4][750/930]     lr: 2.000e-02, eta: 0:31:22, time: 0.249, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0166, loss_rpn_bbox: 0.0056, loss_cls: 0.1006, acc: 97.7383, loss_bbox: 0.0450, loss_mask: 0.2427, loss: 0.41052021-12-21 22:10:38,441 - mmdet - INFO - Epoch [4][800/930]     lr: 2.000e-02, eta: 0:31:10, time: 0.249, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0166, loss_rpn_bbox: 0.0064, loss_cls: 0.0940, acc: 97.9082, loss_bbox: 0.0398, loss_mask: 0.2325, loss: 0.38932021-12-21 22:10:50,866 - mmdet - INFO - Epoch [4][850/930]     lr: 2.000e-02, eta: 0:30:58, time: 0.249, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0187, loss_rpn_bbox: 0.0051, loss_cls: 0.0936, acc: 97.8340, loss_bbox: 0.0418, loss_mask: 0.2227, loss: 0.38182021-12-21 22:11:03,546 - mmdet - INFO - Epoch [4][900/930]     lr: 2.000e-02, eta: 0:30:46, time: 0.253, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0182, loss_rpn_bbox: 0.0060, loss_cls: 0.0890, acc: 97.9160, loss_bbox: 0.0399, loss_mask: 0.2405, loss: 0.39362021-12-21 22:11:11,150 - mmdet - INFO - Saving checkpoint at 4 epochs[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;] 764/764, 8.6 task/s, elapsed: 89s, ETA:     0s2021-12-21 22:12:41,740 - mmdet - INFO - Evaluating bbox...Loading and preparing results...DONE (t=0.02s)creating index...index created!Running per image evaluation...Evaluate annotation type *bbox*DONE (t=0.60s).Accumulating evaluation results...DONE (t=0.37s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.014 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.010 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.210 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.011 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.010 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.130 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.130 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.130 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.343 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.161 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.1302021-12-21 22:12:42,887 - mmdet - INFO - Evaluating segm.../mnt/data01/home/gyf/projects/mmdetection/mmdet/datasets/coco.py:450: UserWarning: The key "bbox" is deleted for more accurate mask AP of small/medium/large instances since v2.12.0. This does not change the overall mAP calculation.  warnings.warn(Loading and preparing results...DONE (t=0.10s)creating index...index created!Running per image evaluation...Evaluate annotation type *segm*DONE (t=0.76s).Accumulating evaluation results.../home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/pycocotools/cocoeval.py:378: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)DONE (t=0.37s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.009 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.014 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.010 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.235 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.011 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.010 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.132 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.132 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.132 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.368 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.163 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.1302021-12-21 22:12:44,367 - mmdet - INFO - Exp name: mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py2021-12-21 22:12:44,368 - mmdet - INFO - Epoch(val) [4][764]    bbox_mAP: 0.0090, bbox_mAP_50: 0.0140, bbox_mAP_75: 0.0100, bbox_mAP_s: 0.2100, bbox_mAP_m: 0.0110, bbox_mAP_l: 0.0100, bbox_mAP_copypaste: 0.009 0.014 0.010 0.210 0.011 0.010, segm_mAP: 0.0090, segm_mAP_50: 0.0140, segm_mAP_75: 0.0100, segm_mAP_s: 0.2350, segm_mAP_m: 0.0110, segm_mAP_l: 0.0100, segm_mAP_copypaste: 0.009 0.014 0.010 0.235 0.011 0.010/mnt/data01/home/gyf/projects/mmdetection/mmdet/core/mask/structures.py:1070: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  bitmap_mask = maskUtils.decode(rle).astype(np.bool)/home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/mmcv/runner/hooks/logger/text.py:112: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],</code></pre><p><strong>Epoch:5</strong></p><pre><code>2021-12-21 22:12:59,256 - mmdet - INFO - Epoch [5][50/930]      lr: 2.000e-02, eta: 0:30:16, time: 0.296, data_time: 0.052, memory: 3050, loss_rpn_cls: 0.0191, loss_rpn_bbox: 0.0051, loss_cls: 0.0997, acc: 97.7422, loss_bbox: 0.0452, loss_mask: 0.2399, loss: 0.40902021-12-21 22:13:11,650 - mmdet - INFO - Epoch [5][100/930]     lr: 2.000e-02, eta: 0:30:04, time: 0.248, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0164, loss_rpn_bbox: 0.0057, loss_cls: 0.0967, acc: 97.7012, loss_bbox: 0.0424, loss_mask: 0.2309, loss: 0.39212021-12-21 22:13:23,842 - mmdet - INFO - Epoch [5][150/930]     lr: 2.000e-02, eta: 0:29:52, time: 0.244, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0144, loss_rpn_bbox: 0.0050, loss_cls: 0.0992, acc: 97.5312, loss_bbox: 0.0472, loss_mask: 0.2333, loss: 0.39912021-12-21 22:13:36,225 - mmdet - INFO - Epoch [5][200/930]     lr: 2.000e-02, eta: 0:29:40, time: 0.247, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0183, loss_rpn_bbox: 0.0059, loss_cls: 0.0865, acc: 97.9922, loss_bbox: 0.0403, loss_mask: 0.2443, loss: 0.39532021-12-21 22:13:48,706 - mmdet - INFO - Epoch [5][250/930]     lr: 2.000e-02, eta: 0:29:28, time: 0.250, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0185, loss_rpn_bbox: 0.0049, loss_cls: 0.1027, acc: 97.5312, loss_bbox: 0.0468, loss_mask: 0.2309, loss: 0.40382021-12-21 22:14:01,050 - mmdet - INFO - Epoch [5][300/930]     lr: 2.000e-02, eta: 0:29:15, time: 0.247, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0196, loss_rpn_bbox: 0.0060, loss_cls: 0.1024, acc: 97.5898, loss_bbox: 0.0477, loss_mask: 0.2306, loss: 0.40632021-12-21 22:14:13,427 - mmdet - INFO - Epoch [5][350/930]     lr: 2.000e-02, eta: 0:29:03, time: 0.247, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0252, loss_rpn_bbox: 0.0060, loss_cls: 0.0962, acc: 97.8164, loss_bbox: 0.0426, loss_mask: 0.2425, loss: 0.41272021-12-21 22:14:25,975 - mmdet - INFO - Epoch [5][400/930]     lr: 2.000e-02, eta: 0:28:51, time: 0.251, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0195, loss_rpn_bbox: 0.0056, loss_cls: 0.0958, acc: 97.7402, loss_bbox: 0.0417, loss_mask: 0.2165, loss: 0.37912021-12-21 22:14:38,588 - mmdet - INFO - Epoch [5][450/930]     lr: 2.000e-02, eta: 0:28:40, time: 0.253, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0205, loss_rpn_bbox: 0.0056, loss_cls: 0.0856, acc: 98.0000, loss_bbox: 0.0375, loss_mask: 0.2246, loss: 0.37382021-12-21 22:14:51,315 - mmdet - INFO - Epoch [5][500/930]     lr: 2.000e-02, eta: 0:28:28, time: 0.254, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0171, loss_rpn_bbox: 0.0055, loss_cls: 0.1020, acc: 97.4434, loss_bbox: 0.0452, loss_mask: 0.2212, loss: 0.39102021-12-21 22:15:04,086 - mmdet - INFO - Epoch [5][550/930]     lr: 2.000e-02, eta: 0:28:16, time: 0.256, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0148, loss_rpn_bbox: 0.0048, loss_cls: 0.0919, acc: 97.7285, loss_bbox: 0.0394, loss_mask: 0.2166, loss: 0.36742021-12-21 22:15:16,677 - mmdet - INFO - Epoch [5][600/930]     lr: 2.000e-02, eta: 0:28:05, time: 0.252, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0147, loss_rpn_bbox: 0.0055, loss_cls: 0.1034, acc: 97.4531, loss_bbox: 0.0476, loss_mask: 0.2292, loss: 0.40042021-12-21 22:15:29,072 - mmdet - INFO - Epoch [5][650/930]     lr: 2.000e-02, eta: 0:27:52, time: 0.247, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0323, loss_rpn_bbox: 0.0074, loss_cls: 0.0825, acc: 98.0957, loss_bbox: 0.0370, loss_mask: 0.2301, loss: 0.38932021-12-21 22:15:41,725 - mmdet - INFO - Epoch [5][700/930]     lr: 2.000e-02, eta: 0:27:41, time: 0.253, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0182, loss_rpn_bbox: 0.0059, loss_cls: 0.0942, acc: 97.8145, loss_bbox: 0.0419, loss_mask: 0.2305, loss: 0.39062021-12-21 22:15:54,314 - mmdet - INFO - Epoch [5][750/930]     lr: 2.000e-02, eta: 0:27:29, time: 0.252, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0152, loss_rpn_bbox: 0.0053, loss_cls: 0.1061, acc: 97.5020, loss_bbox: 0.0461, loss_mask: 0.2203, loss: 0.39302021-12-21 22:16:07,084 - mmdet - INFO - Epoch [5][800/930]     lr: 2.000e-02, eta: 0:27:17, time: 0.255, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0148, loss_rpn_bbox: 0.0046, loss_cls: 0.1110, acc: 97.2949, loss_bbox: 0.0472, loss_mask: 0.2044, loss: 0.38202021-12-21 22:16:19,554 - mmdet - INFO - Epoch [5][850/930]     lr: 2.000e-02, eta: 0:27:05, time: 0.250, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0184, loss_rpn_bbox: 0.0056, loss_cls: 0.0883, acc: 97.8887, loss_bbox: 0.0375, loss_mask: 0.2192, loss: 0.36902021-12-21 22:16:32,420 - mmdet - INFO - Epoch [5][900/930]     lr: 2.000e-02, eta: 0:26:53, time: 0.257, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0165, loss_rpn_bbox: 0.0050, loss_cls: 0.0910, acc: 97.7402, loss_bbox: 0.0391, loss_mask: 0.2234, loss: 0.37512021-12-21 22:16:40,002 - mmdet - INFO - Saving checkpoint at 5 epochs[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;] 764/764, 7.0 task/s, elapsed: 109s, ETA:     0s2021-12-21 22:18:31,847 - mmdet - INFO - Evaluating bbox...Loading and preparing results...DONE (t=0.02s)creating index...index created!Running per image evaluation...Evaluate annotation type *bbox*DONE (t=1.16s).Accumulating evaluation results...DONE (t=0.54s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.024 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.038 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.030 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.300 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.029 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.021 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.340 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.340 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.300 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.412 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.2482021-12-21 22:18:33,623 - mmdet - INFO - Evaluating segm.../mnt/data01/home/gyf/projects/mmdetection/mmdet/datasets/coco.py:450: UserWarning: The key "bbox" is deleted for more accurate mask AP of small/medium/large instances since v2.12.0. This does not change the overall mAP calculation.  warnings.warn(Loading and preparing results...DONE (t=0.19s)creating index...index created!Running per image evaluation...Evaluate annotation type *segm*DONE (t=1.40s).Accumulating evaluation results.../home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/pycocotools/cocoeval.py:378: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)DONE (t=0.57s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.025 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.038 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.030 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.150 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.030 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.024 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.344 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.344 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.300 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.419 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.2472021-12-21 22:18:35,971 - mmdet - INFO - Exp name: mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py2021-12-21 22:18:35,972 - mmdet - INFO - Epoch(val) [5][764]    bbox_mAP: 0.0240, bbox_mAP_50: 0.0380, bbox_mAP_75: 0.0300, bbox_mAP_s: 0.3000, bbox_mAP_m: 0.0290, bbox_mAP_l: 0.0210, bbox_mAP_copypaste: 0.024 0.038 0.030 0.300 0.029 0.021, segm_mAP: 0.0250, segm_mAP_50: 0.0380, segm_mAP_75: 0.0300, segm_mAP_s: 0.1500, segm_mAP_m: 0.0300, segm_mAP_l: 0.0240, segm_mAP_copypaste: 0.025 0.038 0.030 0.150 0.030 0.024/mnt/data01/home/gyf/projects/mmdetection/mmdet/core/mask/structures.py:1070: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  bitmap_mask = maskUtils.decode(rle).astype(np.bool)/home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/mmcv/runner/hooks/logger/text.py:112: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],</code></pre><p><strong>Epoch:6</strong></p><pre><code>2021-12-21 22:18:50,938 - mmdet - INFO - Epoch [6][50/930]      lr: 2.000e-02, eta: 0:26:27, time: 0.297, data_time: 0.052, memory: 3050, loss_rpn_cls: 0.0178, loss_rpn_bbox: 0.0054, loss_cls: 0.1046, acc: 97.5000, loss_bbox: 0.0465, loss_mask: 0.2345, loss: 0.40882021-12-21 22:19:03,455 - mmdet - INFO - Epoch [6][100/930]     lr: 2.000e-02, eta: 0:26:15, time: 0.250, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0148, loss_rpn_bbox: 0.0056, loss_cls: 0.1022, acc: 97.3965, loss_bbox: 0.0459, loss_mask: 0.2005, loss: 0.36902021-12-21 22:19:15,698 - mmdet - INFO - Epoch [6][150/930]     lr: 2.000e-02, eta: 0:26:03, time: 0.245, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0158, loss_rpn_bbox: 0.0057, loss_cls: 0.1035, acc: 97.5293, loss_bbox: 0.0461, loss_mask: 0.2172, loss: 0.38832021-12-21 22:19:28,317 - mmdet - INFO - Epoch [6][200/930]     lr: 2.000e-02, eta: 0:25:51, time: 0.252, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0150, loss_rpn_bbox: 0.0048, loss_cls: 0.1070, acc: 97.3379, loss_bbox: 0.0469, loss_mask: 0.2191, loss: 0.39272021-12-21 22:19:40,845 - mmdet - INFO - Epoch [6][250/930]     lr: 2.000e-02, eta: 0:25:39, time: 0.251, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0171, loss_rpn_bbox: 0.0060, loss_cls: 0.1022, acc: 97.5742, loss_bbox: 0.0461, loss_mask: 0.2306, loss: 0.40212021-12-21 22:19:53,236 - mmdet - INFO - Epoch [6][300/930]     lr: 2.000e-02, eta: 0:25:27, time: 0.248, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0138, loss_rpn_bbox: 0.0058, loss_cls: 0.1038, acc: 97.3652, loss_bbox: 0.0478, loss_mask: 0.2204, loss: 0.39162021-12-21 22:20:05,691 - mmdet - INFO - Exp name: mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py2021-12-21 22:20:05,691 - mmdet - INFO - Epoch [6][350/930]     lr: 2.000e-02, eta: 0:25:14, time: 0.249, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0131, loss_rpn_bbox: 0.0051, loss_cls: 0.1020, acc: 97.5039, loss_bbox: 0.0435, loss_mask: 0.2195, loss: 0.38322021-12-21 22:20:18,199 - mmdet - INFO - Epoch [6][400/930]     lr: 2.000e-02, eta: 0:25:02, time: 0.250, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0154, loss_rpn_bbox: 0.0054, loss_cls: 0.1036, acc: 97.5762, loss_bbox: 0.0446, loss_mask: 0.2225, loss: 0.39142021-12-21 22:20:30,960 - mmdet - INFO - Epoch [6][450/930]     lr: 2.000e-02, eta: 0:24:51, time: 0.256, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0144, loss_rpn_bbox: 0.0055, loss_cls: 0.1124, acc: 97.2754, loss_bbox: 0.0479, loss_mask: 0.2055, loss: 0.38572021-12-21 22:20:43,766 - mmdet - INFO - Epoch [6][500/930]     lr: 2.000e-02, eta: 0:24:39, time: 0.256, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0148, loss_rpn_bbox: 0.0054, loss_cls: 0.1029, acc: 97.3730, loss_bbox: 0.0492, loss_mask: 0.2205, loss: 0.39282021-12-21 22:20:56,749 - mmdet - INFO - Epoch [6][550/930]     lr: 2.000e-02, eta: 0:24:27, time: 0.260, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0124, loss_rpn_bbox: 0.0046, loss_cls: 0.0929, acc: 97.6836, loss_bbox: 0.0393, loss_mask: 0.1980, loss: 0.34722021-12-21 22:21:09,394 - mmdet - INFO - Epoch [6][600/930]     lr: 2.000e-02, eta: 0:24:15, time: 0.253, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0213, loss_rpn_bbox: 0.0058, loss_cls: 0.0870, acc: 97.9023, loss_bbox: 0.0394, loss_mask: 0.2481, loss: 0.40162021-12-21 22:21:22,201 - mmdet - INFO - Epoch [6][650/930]     lr: 2.000e-02, eta: 0:24:04, time: 0.255, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0195, loss_rpn_bbox: 0.0059, loss_cls: 0.0910, acc: 97.8125, loss_bbox: 0.0392, loss_mask: 0.2169, loss: 0.37242021-12-21 22:21:35,154 - mmdet - INFO - Epoch [6][700/930]     lr: 2.000e-02, eta: 0:23:52, time: 0.259, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0177, loss_rpn_bbox: 0.0054, loss_cls: 0.0969, acc: 97.6523, loss_bbox: 0.0422, loss_mask: 0.2331, loss: 0.39532021-12-21 22:21:47,639 - mmdet - INFO - Epoch [6][750/930]     lr: 2.000e-02, eta: 0:23:40, time: 0.250, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0160, loss_rpn_bbox: 0.0051, loss_cls: 0.0972, acc: 97.6855, loss_bbox: 0.0432, loss_mask: 0.2231, loss: 0.38452021-12-21 22:22:00,345 - mmdet - INFO - Epoch [6][800/930]     lr: 2.000e-02, eta: 0:23:28, time: 0.254, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0175, loss_rpn_bbox: 0.0054, loss_cls: 0.0903, acc: 97.8496, loss_bbox: 0.0404, loss_mask: 0.2247, loss: 0.37842021-12-21 22:22:12,650 - mmdet - INFO - Epoch [6][850/930]     lr: 2.000e-02, eta: 0:23:16, time: 0.246, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0190, loss_rpn_bbox: 0.0052, loss_cls: 0.1004, acc: 97.7363, loss_bbox: 0.0446, loss_mask: 0.2377, loss: 0.40692021-12-21 22:22:25,443 - mmdet - INFO - Epoch [6][900/930]     lr: 2.000e-02, eta: 0:23:04, time: 0.256, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0171, loss_rpn_bbox: 0.0066, loss_cls: 0.1083, acc: 97.2910, loss_bbox: 0.0480, loss_mask: 0.2230, loss: 0.40312021-12-21 22:22:33,073 - mmdet - INFO - Saving checkpoint at 6 epochs[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;] 764/764, 6.7 task/s, elapsed: 114s, ETA:     0s2021-12-21 22:24:29,284 - mmdet - INFO - Evaluating bbox...Loading and preparing results...DONE (t=0.02s)creating index...index created!Running per image evaluation...Evaluate annotation type *bbox*DONE (t=0.92s).Accumulating evaluation results...DONE (t=0.50s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.019 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.029 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.022 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.304 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.024 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.017 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.285 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.285 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.285 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.304 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.335 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.2732021-12-21 22:24:30,872 - mmdet - INFO - Evaluating segm.../mnt/data01/home/gyf/projects/mmdetection/mmdet/datasets/coco.py:450: UserWarning: The key "bbox" is deleted for more accurate mask AP of small/medium/large instances since v2.12.0. This does not change the overall mAP calculation.  warnings.warn(Loading and preparing results...DONE (t=0.17s)creating index...index created!Running per image evaluation...Evaluate annotation type *segm*DONE (t=1.11s).Accumulating evaluation results.../home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/pycocotools/cocoeval.py:378: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)DONE (t=0.52s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.029 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.021 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.237 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.023 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.026 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.282 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.282 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.282 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.354 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.335 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.2682021-12-21 22:24:32,890 - mmdet - INFO - Exp name: mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py2021-12-21 22:24:32,890 - mmdet - INFO - Epoch(val) [6][764]    bbox_mAP: 0.0190, bbox_mAP_50: 0.0290, bbox_mAP_75: 0.0220, bbox_mAP_s: 0.3040, bbox_mAP_m: 0.0240, bbox_mAP_l: 0.0170, bbox_mAP_copypaste: 0.019 0.029 0.022 0.304 0.024 0.017, segm_mAP: 0.0180, segm_mAP_50: 0.0290, segm_mAP_75: 0.0210, segm_mAP_s: 0.2370, segm_mAP_m: 0.0230, segm_mAP_l: 0.0260, segm_mAP_copypaste: 0.018 0.029 0.021 0.237 0.023 0.026/mnt/data01/home/gyf/projects/mmdetection/mmdet/core/mask/structures.py:1070: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  bitmap_mask = maskUtils.decode(rle).astype(np.bool)/home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/mmcv/runner/hooks/logger/text.py:112: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],</code></pre><p><strong>Epoch:7</strong></p><pre><code>2021-12-21 22:24:47,860 - mmdet - INFO - Epoch [7][50/930]      lr: 2.000e-02, eta: 0:22:39, time: 0.298, data_time: 0.052, memory: 3050, loss_rpn_cls: 0.0132, loss_rpn_bbox: 0.0048, loss_cls: 0.0987, acc: 97.4902, loss_bbox: 0.0436, loss_mask: 0.1922, loss: 0.35252021-12-21 22:25:00,237 - mmdet - INFO - Epoch [7][100/930]     lr: 2.000e-02, eta: 0:22:27, time: 0.247, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0168, loss_rpn_bbox: 0.0047, loss_cls: 0.1023, acc: 97.5000, loss_bbox: 0.0438, loss_mask: 0.1922, loss: 0.35972021-12-21 22:25:12,577 - mmdet - INFO - Epoch [7][150/930]     lr: 2.000e-02, eta: 0:22:15, time: 0.247, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0161, loss_rpn_bbox: 0.0059, loss_cls: 0.1027, acc: 97.3711, loss_bbox: 0.0461, loss_mask: 0.2093, loss: 0.38022021-12-21 22:25:25,143 - mmdet - INFO - Epoch [7][200/930]     lr: 2.000e-02, eta: 0:22:03, time: 0.251, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0154, loss_rpn_bbox: 0.0055, loss_cls: 0.0967, acc: 97.5684, loss_bbox: 0.0439, loss_mask: 0.2139, loss: 0.37552021-12-21 22:25:37,946 - mmdet - INFO - Epoch [7][250/930]     lr: 2.000e-02, eta: 0:21:51, time: 0.256, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0185, loss_rpn_bbox: 0.0056, loss_cls: 0.0965, acc: 97.6582, loss_bbox: 0.0438, loss_mask: 0.2308, loss: 0.39522021-12-21 22:25:50,514 - mmdet - INFO - Epoch [7][300/930]     lr: 2.000e-02, eta: 0:21:39, time: 0.251, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0155, loss_rpn_bbox: 0.0049, loss_cls: 0.0956, acc: 97.6973, loss_bbox: 0.0410, loss_mask: 0.2051, loss: 0.36202021-12-21 22:26:02,964 - mmdet - INFO - Epoch [7][350/930]     lr: 2.000e-02, eta: 0:21:27, time: 0.249, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0135, loss_rpn_bbox: 0.0045, loss_cls: 0.1103, acc: 97.3008, loss_bbox: 0.0486, loss_mask: 0.2142, loss: 0.39112021-12-21 22:26:15,469 - mmdet - INFO - Epoch [7][400/930]     lr: 2.000e-02, eta: 0:21:14, time: 0.250, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0161, loss_rpn_bbox: 0.0047, loss_cls: 0.0951, acc: 97.5859, loss_bbox: 0.0372, loss_mask: 0.1893, loss: 0.34242021-12-21 22:26:27,994 - mmdet - INFO - Epoch [7][450/930]     lr: 2.000e-02, eta: 0:21:02, time: 0.251, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0165, loss_rpn_bbox: 0.0055, loss_cls: 0.0944, acc: 97.6973, loss_bbox: 0.0428, loss_mask: 0.2330, loss: 0.39222021-12-21 22:26:40,694 - mmdet - INFO - Epoch [7][500/930]     lr: 2.000e-02, eta: 0:20:50, time: 0.254, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0161, loss_rpn_bbox: 0.0053, loss_cls: 0.1006, acc: 97.6211, loss_bbox: 0.0455, loss_mask: 0.2200, loss: 0.38742021-12-21 22:26:53,652 - mmdet - INFO - Epoch [7][550/930]     lr: 2.000e-02, eta: 0:20:39, time: 0.259, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0139, loss_rpn_bbox: 0.0049, loss_cls: 0.1103, acc: 97.2812, loss_bbox: 0.0500, loss_mask: 0.2271, loss: 0.40622021-12-21 22:27:06,094 - mmdet - INFO - Epoch [7][600/930]     lr: 2.000e-02, eta: 0:20:26, time: 0.249, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0208, loss_rpn_bbox: 0.0063, loss_cls: 0.0957, acc: 97.6699, loss_bbox: 0.0418, loss_mask: 0.2276, loss: 0.39222021-12-21 22:27:18,668 - mmdet - INFO - Epoch [7][650/930]     lr: 2.000e-02, eta: 0:20:14, time: 0.251, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0135, loss_rpn_bbox: 0.0044, loss_cls: 0.1073, acc: 97.1836, loss_bbox: 0.0506, loss_mask: 0.2022, loss: 0.37792021-12-21 22:27:31,451 - mmdet - INFO - Epoch [7][700/930]     lr: 2.000e-02, eta: 0:20:02, time: 0.256, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0118, loss_rpn_bbox: 0.0051, loss_cls: 0.1092, acc: 97.3652, loss_bbox: 0.0532, loss_mask: 0.2371, loss: 0.41652021-12-21 22:27:44,188 - mmdet - INFO - Epoch [7][750/930]     lr: 2.000e-02, eta: 0:19:50, time: 0.255, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0148, loss_rpn_bbox: 0.0054, loss_cls: 0.1016, acc: 97.6230, loss_bbox: 0.0465, loss_mask: 0.2316, loss: 0.39982021-12-21 22:27:57,153 - mmdet - INFO - Epoch [7][800/930]     lr: 2.000e-02, eta: 0:19:38, time: 0.259, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0135, loss_rpn_bbox: 0.0053, loss_cls: 0.1181, acc: 97.0820, loss_bbox: 0.0499, loss_mask: 0.2011, loss: 0.38792021-12-21 22:28:09,665 - mmdet - INFO - Epoch [7][850/930]     lr: 2.000e-02, eta: 0:19:26, time: 0.250, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0173, loss_rpn_bbox: 0.0054, loss_cls: 0.1087, acc: 97.3691, loss_bbox: 0.0463, loss_mask: 0.2208, loss: 0.39852021-12-21 22:28:22,625 - mmdet - INFO - Epoch [7][900/930]     lr: 2.000e-02, eta: 0:19:14, time: 0.259, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0161, loss_rpn_bbox: 0.0058, loss_cls: 0.0965, acc: 97.6387, loss_bbox: 0.0439, loss_mask: 0.2280, loss: 0.39032021-12-21 22:28:30,260 - mmdet - INFO - Saving checkpoint at 7 epochs[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;] 764/764, 8.5 task/s, elapsed: 90s, ETA:     0s2021-12-21 22:30:02,842 - mmdet - INFO - Evaluating bbox...Loading and preparing results...DONE (t=0.01s)creating index...index created!Running per image evaluation...Evaluate annotation type *bbox*DONE (t=0.89s).Accumulating evaluation results...DONE (t=0.39s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.027 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.039 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.031 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.225 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.032 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.023 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.363 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.363 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.363 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.375 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.435 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.2702021-12-21 22:30:04,167 - mmdet - INFO - Evaluating segm.../mnt/data01/home/gyf/projects/mmdetection/mmdet/datasets/coco.py:450: UserWarning: The key "bbox" is deleted for more accurate mask AP of small/medium/large instances since v2.12.0. This does not change the overall mAP calculation.  warnings.warn(Loading and preparing results...DONE (t=0.12s)creating index...index created!Running per image evaluation...Evaluate annotation type *segm*DONE (t=0.97s).Accumulating evaluation results.../home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/pycocotools/cocoeval.py:378: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)DONE (t=0.40s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.027 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.038 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.030 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.087 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.032 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.023 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.364 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.364 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.364 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.375 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.438 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.2692021-12-21 22:30:05,919 - mmdet - INFO - Exp name: mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py2021-12-21 22:30:05,919 - mmdet - INFO - Epoch(val) [7][764]    bbox_mAP: 0.0270, bbox_mAP_50: 0.0390, bbox_mAP_75: 0.0310, bbox_mAP_s: 0.2250, bbox_mAP_m: 0.0320, bbox_mAP_l: 0.0230, bbox_mAP_copypaste: 0.027 0.039 0.031 0.225 0.032 0.023, segm_mAP: 0.0270, segm_mAP_50: 0.0380, segm_mAP_75: 0.0300, segm_mAP_s: 0.0870, segm_mAP_m: 0.0320, segm_mAP_l: 0.0230, segm_mAP_copypaste: 0.027 0.038 0.030 0.087 0.032 0.023/mnt/data01/home/gyf/projects/mmdetection/mmdet/core/mask/structures.py:1070: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  bitmap_mask = maskUtils.decode(rle).astype(np.bool)/home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/mmcv/runner/hooks/logger/text.py:112: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],</code></pre><p><strong>Epoch:8</strong></p><pre><code>2021-12-21 22:30:20,980 - mmdet - INFO - Epoch [8][50/930]      lr: 2.000e-02, eta: 0:18:51, time: 0.299, data_time: 0.053, memory: 3050, loss_rpn_cls: 0.0149, loss_rpn_bbox: 0.0053, loss_cls: 0.1021, acc: 97.3457, loss_bbox: 0.0456, loss_mask: 0.2128, loss: 0.38072021-12-21 22:30:33,420 - mmdet - INFO - Epoch [8][100/930]     lr: 2.000e-02, eta: 0:18:39, time: 0.249, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0140, loss_rpn_bbox: 0.0049, loss_cls: 0.1059, acc: 97.4062, loss_bbox: 0.0445, loss_mask: 0.2078, loss: 0.37712021-12-21 22:30:45,825 - mmdet - INFO - Epoch [8][150/930]     lr: 2.000e-02, eta: 0:18:27, time: 0.248, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0140, loss_rpn_bbox: 0.0050, loss_cls: 0.1086, acc: 97.1602, loss_bbox: 0.0465, loss_mask: 0.1993, loss: 0.37342021-12-21 22:30:58,505 - mmdet - INFO - Epoch [8][200/930]     lr: 2.000e-02, eta: 0:18:15, time: 0.253, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0141, loss_rpn_bbox: 0.0044, loss_cls: 0.1020, acc: 97.5938, loss_bbox: 0.0430, loss_mask: 0.2114, loss: 0.37502021-12-21 22:31:11,166 - mmdet - INFO - Epoch [8][250/930]     lr: 2.000e-02, eta: 0:18:03, time: 0.254, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0137, loss_rpn_bbox: 0.0051, loss_cls: 0.0938, acc: 97.5723, loss_bbox: 0.0396, loss_mask: 0.2014, loss: 0.35352021-12-21 22:31:23,590 - mmdet - INFO - Epoch [8][300/930]     lr: 2.000e-02, eta: 0:17:50, time: 0.248, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0191, loss_rpn_bbox: 0.0052, loss_cls: 0.0983, acc: 97.6641, loss_bbox: 0.0435, loss_mask: 0.2367, loss: 0.40282021-12-21 22:31:35,945 - mmdet - INFO - Epoch [8][350/930]     lr: 2.000e-02, eta: 0:17:38, time: 0.247, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0154, loss_rpn_bbox: 0.0056, loss_cls: 0.0983, acc: 97.5098, loss_bbox: 0.0455, loss_mask: 0.2168, loss: 0.38172021-12-21 22:31:48,742 - mmdet - INFO - Epoch [8][400/930]     lr: 2.000e-02, eta: 0:17:26, time: 0.256, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0136, loss_rpn_bbox: 0.0049, loss_cls: 0.0988, acc: 97.6621, loss_bbox: 0.0427, loss_mask: 0.2272, loss: 0.38722021-12-21 22:32:01,347 - mmdet - INFO - Epoch [8][450/930]     lr: 2.000e-02, eta: 0:17:14, time: 0.252, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0167, loss_rpn_bbox: 0.0052, loss_cls: 0.1032, acc: 97.4922, loss_bbox: 0.0453, loss_mask: 0.2312, loss: 0.40172021-12-21 22:32:14,070 - mmdet - INFO - Epoch [8][500/930]     lr: 2.000e-02, eta: 0:17:02, time: 0.254, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0184, loss_rpn_bbox: 0.0049, loss_cls: 0.1044, acc: 97.5000, loss_bbox: 0.0508, loss_mask: 0.2461, loss: 0.42462021-12-21 22:32:27,022 - mmdet - INFO - Epoch [8][550/930]     lr: 2.000e-02, eta: 0:16:50, time: 0.259, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0159, loss_rpn_bbox: 0.0043, loss_cls: 0.1045, acc: 97.3262, loss_bbox: 0.0462, loss_mask: 0.1941, loss: 0.36502021-12-21 22:32:39,525 - mmdet - INFO - Epoch [8][600/930]     lr: 2.000e-02, eta: 0:16:38, time: 0.250, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0160, loss_rpn_bbox: 0.0050, loss_cls: 0.1025, acc: 97.5410, loss_bbox: 0.0443, loss_mask: 0.2055, loss: 0.37322021-12-21 22:32:52,152 - mmdet - INFO - Epoch [8][650/930]     lr: 2.000e-02, eta: 0:16:26, time: 0.252, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0211, loss_rpn_bbox: 0.0059, loss_cls: 0.0970, acc: 97.6543, loss_bbox: 0.0429, loss_mask: 0.2143, loss: 0.38132021-12-21 22:33:05,200 - mmdet - INFO - Epoch [8][700/930]     lr: 2.000e-02, eta: 0:16:14, time: 0.261, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0137, loss_rpn_bbox: 0.0056, loss_cls: 0.0976, acc: 97.5801, loss_bbox: 0.0459, loss_mask: 0.2218, loss: 0.38472021-12-21 22:33:17,732 - mmdet - INFO - Epoch [8][750/930]     lr: 2.000e-02, eta: 0:16:01, time: 0.251, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0142, loss_rpn_bbox: 0.0052, loss_cls: 0.0913, acc: 97.7148, loss_bbox: 0.0369, loss_mask: 0.1966, loss: 0.34422021-12-21 22:33:30,221 - mmdet - INFO - Epoch [8][800/930]     lr: 2.000e-02, eta: 0:15:49, time: 0.249, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0129, loss_rpn_bbox: 0.0051, loss_cls: 0.0923, acc: 97.6328, loss_bbox: 0.0396, loss_mask: 0.2022, loss: 0.35212021-12-21 22:33:42,702 - mmdet - INFO - Epoch [8][850/930]     lr: 2.000e-02, eta: 0:15:37, time: 0.250, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0190, loss_rpn_bbox: 0.0061, loss_cls: 0.0884, acc: 97.8340, loss_bbox: 0.0392, loss_mask: 0.2294, loss: 0.38212021-12-21 22:33:55,612 - mmdet - INFO - Epoch [8][900/930]     lr: 2.000e-02, eta: 0:15:25, time: 0.258, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0150, loss_rpn_bbox: 0.0057, loss_cls: 0.0916, acc: 97.5996, loss_bbox: 0.0394, loss_mask: 0.2000, loss: 0.35172021-12-21 22:34:03,423 - mmdet - INFO - Saving checkpoint at 8 epochs[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;] 764/764, 8.1 task/s, elapsed: 94s, ETA:     0s2021-12-21 22:35:39,499 - mmdet - INFO - Evaluating bbox...Loading and preparing results...DONE (t=0.11s)creating index...index created!Running per image evaluation...Evaluate annotation type *bbox*DONE (t=0.80s).Accumulating evaluation results...DONE (t=0.42s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.025 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.040 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.030 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.237 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.031 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.017 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.344 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.344 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.344 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.375 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.407 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.2682021-12-21 22:35:40,870 - mmdet - INFO - Evaluating segm.../mnt/data01/home/gyf/projects/mmdetection/mmdet/datasets/coco.py:450: UserWarning: The key "bbox" is deleted for more accurate mask AP of small/medium/large instances since v2.12.0. This does not change the overall mAP calculation.  warnings.warn(Loading and preparing results...DONE (t=0.12s)creating index...index created!Running per image evaluation...Evaluate annotation type *segm*DONE (t=0.98s).Accumulating evaluation results.../home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/pycocotools/cocoeval.py:378: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)DONE (t=0.42s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.040 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.032 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.237 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.033 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.020 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.366 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.366 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.366 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.375 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.437 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.2742021-12-21 22:35:42,635 - mmdet - INFO - Exp name: mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py2021-12-21 22:35:42,635 - mmdet - INFO - Epoch(val) [8][764]    bbox_mAP: 0.0250, bbox_mAP_50: 0.0400, bbox_mAP_75: 0.0300, bbox_mAP_s: 0.2370, bbox_mAP_m: 0.0310, bbox_mAP_l: 0.0170, bbox_mAP_copypaste: 0.025 0.040 0.030 0.237 0.031 0.017, segm_mAP: 0.0280, segm_mAP_50: 0.0400, segm_mAP_75: 0.0320, segm_mAP_s: 0.2370, segm_mAP_m: 0.0330, segm_mAP_l: 0.0200, segm_mAP_copypaste: 0.028 0.040 0.032 0.237 0.033 0.020/mnt/data01/home/gyf/projects/mmdetection/mmdet/core/mask/structures.py:1070: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  bitmap_mask = maskUtils.decode(rle).astype(np.bool)/home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/mmcv/runner/hooks/logger/text.py:112: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],</code></pre><p><strong>Epoch:9</strong></p><pre><code>2021-12-21 22:35:57,522 - mmdet - INFO - Epoch [9][50/930]      lr: 2.000e-03, eta: 0:15:03, time: 0.296, data_time: 0.052, memory: 3050, loss_rpn_cls: 0.0110, loss_rpn_bbox: 0.0041, loss_cls: 0.0940, acc: 97.5781, loss_bbox: 0.0395, loss_mask: 0.2024, loss: 0.35092021-12-21 22:36:10,052 - mmdet - INFO - Epoch [9][100/930]     lr: 2.000e-03, eta: 0:14:51, time: 0.250, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0112, loss_rpn_bbox: 0.0045, loss_cls: 0.0944, acc: 97.4043, loss_bbox: 0.0372, loss_mask: 0.1804, loss: 0.32762021-12-21 22:36:22,360 - mmdet - INFO - Epoch [9][150/930]     lr: 2.000e-03, eta: 0:14:38, time: 0.246, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0122, loss_rpn_bbox: 0.0049, loss_cls: 0.1019, acc: 97.2656, loss_bbox: 0.0443, loss_mask: 0.1931, loss: 0.35652021-12-21 22:36:35,031 - mmdet - INFO - Epoch [9][200/930]     lr: 2.000e-03, eta: 0:14:26, time: 0.253, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0094, loss_rpn_bbox: 0.0036, loss_cls: 0.1023, acc: 97.1973, loss_bbox: 0.0423, loss_mask: 0.1790, loss: 0.33652021-12-21 22:36:47,660 - mmdet - INFO - Epoch [9][250/930]     lr: 2.000e-03, eta: 0:14:14, time: 0.253, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0099, loss_rpn_bbox: 0.0034, loss_cls: 0.1083, acc: 97.0371, loss_bbox: 0.0428, loss_mask: 0.1858, loss: 0.35012021-12-21 22:37:00,234 - mmdet - INFO - Epoch [9][300/930]     lr: 2.000e-03, eta: 0:14:02, time: 0.251, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0104, loss_rpn_bbox: 0.0041, loss_cls: 0.1063, acc: 97.1562, loss_bbox: 0.0428, loss_mask: 0.1814, loss: 0.34492021-12-21 22:37:12,716 - mmdet - INFO - Epoch [9][350/930]     lr: 2.000e-03, eta: 0:13:50, time: 0.249, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0100, loss_rpn_bbox: 0.0038, loss_cls: 0.1042, acc: 97.1699, loss_bbox: 0.0424, loss_mask: 0.1854, loss: 0.34582021-12-21 22:37:25,292 - mmdet - INFO - Epoch [9][400/930]     lr: 2.000e-03, eta: 0:13:37, time: 0.251, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0124, loss_rpn_bbox: 0.0038, loss_cls: 0.1036, acc: 97.1895, loss_bbox: 0.0423, loss_mask: 0.1971, loss: 0.35922021-12-21 22:37:37,947 - mmdet - INFO - Epoch [9][450/930]     lr: 2.000e-03, eta: 0:13:25, time: 0.254, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0123, loss_rpn_bbox: 0.0039, loss_cls: 0.0996, acc: 97.1641, loss_bbox: 0.0381, loss_mask: 0.1716, loss: 0.32572021-12-21 22:37:50,760 - mmdet - INFO - Epoch [9][500/930]     lr: 2.000e-03, eta: 0:13:13, time: 0.256, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0097, loss_rpn_bbox: 0.0036, loss_cls: 0.1028, acc: 97.1270, loss_bbox: 0.0434, loss_mask: 0.1839, loss: 0.34342021-12-21 22:38:03,627 - mmdet - INFO - Epoch [9][550/930]     lr: 2.000e-03, eta: 0:13:01, time: 0.257, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0114, loss_rpn_bbox: 0.0043, loss_cls: 0.1081, acc: 97.1582, loss_bbox: 0.0454, loss_mask: 0.2013, loss: 0.37042021-12-21 22:38:16,229 - mmdet - INFO - Epoch [9][600/930]     lr: 2.000e-03, eta: 0:12:49, time: 0.252, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0095, loss_rpn_bbox: 0.0042, loss_cls: 0.1063, acc: 97.0156, loss_bbox: 0.0430, loss_mask: 0.1809, loss: 0.34382021-12-21 22:38:29,096 - mmdet - INFO - Epoch [9][650/930]     lr: 2.000e-03, eta: 0:12:37, time: 0.257, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0095, loss_rpn_bbox: 0.0041, loss_cls: 0.1046, acc: 97.1211, loss_bbox: 0.0427, loss_mask: 0.1833, loss: 0.34422021-12-21 22:38:42,033 - mmdet - INFO - Epoch [9][700/930]     lr: 2.000e-03, eta: 0:12:24, time: 0.259, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0108, loss_rpn_bbox: 0.0038, loss_cls: 0.0982, acc: 97.1562, loss_bbox: 0.0386, loss_mask: 0.1743, loss: 0.32572021-12-21 22:38:54,590 - mmdet - INFO - Epoch [9][750/930]     lr: 2.000e-03, eta: 0:12:12, time: 0.251, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0109, loss_rpn_bbox: 0.0037, loss_cls: 0.0991, acc: 97.3496, loss_bbox: 0.0420, loss_mask: 0.2050, loss: 0.36072021-12-21 22:39:07,131 - mmdet - INFO - Epoch [9][800/930]     lr: 2.000e-03, eta: 0:12:00, time: 0.251, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0106, loss_rpn_bbox: 0.0037, loss_cls: 0.0944, acc: 97.4316, loss_bbox: 0.0374, loss_mask: 0.1850, loss: 0.33112021-12-21 22:39:19,558 - mmdet - INFO - Epoch [9][850/930]     lr: 2.000e-03, eta: 0:11:48, time: 0.249, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0103, loss_rpn_bbox: 0.0038, loss_cls: 0.1005, acc: 97.2676, loss_bbox: 0.0445, loss_mask: 0.1911, loss: 0.35012021-12-21 22:39:32,365 - mmdet - INFO - Epoch [9][900/930]     lr: 2.000e-03, eta: 0:11:35, time: 0.256, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0133, loss_rpn_bbox: 0.0044, loss_cls: 0.0947, acc: 97.3730, loss_bbox: 0.0408, loss_mask: 0.2005, loss: 0.35362021-12-21 22:39:39,984 - mmdet - INFO - Saving checkpoint at 9 epochs[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;] 764/764, 8.6 task/s, elapsed: 89s, ETA:     0s2021-12-21 22:41:10,973 - mmdet - INFO - Evaluating bbox...Loading and preparing results...DONE (t=0.13s)creating index...index created!Running per image evaluation...Evaluate annotation type *bbox*DONE (t=0.81s).Accumulating evaluation results...DONE (t=0.41s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.027 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.040 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.031 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.240 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.032 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.022 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.375 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.375 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.375 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.400 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.451 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.2912021-12-21 22:41:12,357 - mmdet - INFO - Evaluating segm.../mnt/data01/home/gyf/projects/mmdetection/mmdet/datasets/coco.py:450: UserWarning: The key "bbox" is deleted for more accurate mask AP of small/medium/large instances since v2.12.0. This does not change the overall mAP calculation.  warnings.warn(Loading and preparing results...DONE (t=0.11s)creating index...index created!Running per image evaluation...Evaluate annotation type *segm*DONE (t=0.92s).Accumulating evaluation results.../home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/pycocotools/cocoeval.py:378: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)DONE (t=0.44s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.027 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.039 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.032 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.030 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.031 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.022 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.377 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.377 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.377 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.400 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.454 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.2872021-12-21 22:41:14,077 - mmdet - INFO - Exp name: mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py2021-12-21 22:41:14,077 - mmdet - INFO - Epoch(val) [9][764]    bbox_mAP: 0.0270, bbox_mAP_50: 0.0400, bbox_mAP_75: 0.0310, bbox_mAP_s: 0.2400, bbox_mAP_m: 0.0320, bbox_mAP_l: 0.0220, bbox_mAP_copypaste: 0.027 0.040 0.031 0.240 0.032 0.022, segm_mAP: 0.0270, segm_mAP_50: 0.0390, segm_mAP_75: 0.0320, segm_mAP_s: 0.0300, segm_mAP_m: 0.0310, segm_mAP_l: 0.0220, segm_mAP_copypaste: 0.027 0.039 0.032 0.030 0.031 0.022/mnt/data01/home/gyf/projects/mmdetection/mmdet/core/mask/structures.py:1070: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  bitmap_mask = maskUtils.decode(rle).astype(np.bool)/home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/mmcv/runner/hooks/logger/text.py:112: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],</code></pre><p><strong>Epoch:10</strong></p><pre><code>2021-12-21 22:41:29,152 - mmdet - INFO - Epoch [10][50/930]     lr: 2.000e-03, eta: 0:11:14, time: 0.300, data_time: 0.053, memory: 3050, loss_rpn_cls: 0.0075, loss_rpn_bbox: 0.0030, loss_cls: 0.0960, acc: 97.2598, loss_bbox: 0.0366, loss_mask: 0.1699, loss: 0.31302021-12-21 22:41:41,578 - mmdet - INFO - Epoch [10][100/930]    lr: 2.000e-03, eta: 0:11:02, time: 0.248, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0105, loss_rpn_bbox: 0.0038, loss_cls: 0.1017, acc: 97.1523, loss_bbox: 0.0430, loss_mask: 0.1848, loss: 0.34382021-12-21 22:41:54,089 - mmdet - INFO - Epoch [10][150/930]    lr: 2.000e-03, eta: 0:10:50, time: 0.250, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0078, loss_rpn_bbox: 0.0036, loss_cls: 0.1023, acc: 97.1797, loss_bbox: 0.0415, loss_mask: 0.1804, loss: 0.33562021-12-21 22:42:06,712 - mmdet - INFO - Epoch [10][200/930]    lr: 2.000e-03, eta: 0:10:37, time: 0.252, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0098, loss_rpn_bbox: 0.0033, loss_cls: 0.1024, acc: 97.0781, loss_bbox: 0.0405, loss_mask: 0.1844, loss: 0.34042021-12-21 22:42:19,179 - mmdet - INFO - Epoch [10][250/930]    lr: 2.000e-03, eta: 0:10:25, time: 0.249, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0086, loss_rpn_bbox: 0.0037, loss_cls: 0.0980, acc: 97.2031, loss_bbox: 0.0381, loss_mask: 0.1739, loss: 0.32232021-12-21 22:42:31,738 - mmdet - INFO - Epoch [10][300/930]    lr: 2.000e-03, eta: 0:10:13, time: 0.251, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0092, loss_rpn_bbox: 0.0031, loss_cls: 0.0971, acc: 97.3457, loss_bbox: 0.0364, loss_mask: 0.1638, loss: 0.30962021-12-21 22:42:44,209 - mmdet - INFO - Epoch [10][350/930]    lr: 2.000e-03, eta: 0:10:01, time: 0.250, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0083, loss_rpn_bbox: 0.0029, loss_cls: 0.0985, acc: 97.1777, loss_bbox: 0.0406, loss_mask: 0.1747, loss: 0.32492021-12-21 22:42:56,786 - mmdet - INFO - Epoch [10][400/930]    lr: 2.000e-03, eta: 0:09:48, time: 0.251, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0098, loss_rpn_bbox: 0.0035, loss_cls: 0.0984, acc: 97.2188, loss_bbox: 0.0427, loss_mask: 0.1837, loss: 0.33812021-12-21 22:43:09,539 - mmdet - INFO - Epoch [10][450/930]    lr: 2.000e-03, eta: 0:09:36, time: 0.255, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0080, loss_rpn_bbox: 0.0028, loss_cls: 0.1045, acc: 97.0723, loss_bbox: 0.0432, loss_mask: 0.1843, loss: 0.34282021-12-21 22:43:22,275 - mmdet - INFO - Epoch [10][500/930]    lr: 2.000e-03, eta: 0:09:24, time: 0.255, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0089, loss_rpn_bbox: 0.0035, loss_cls: 0.1032, acc: 97.1406, loss_bbox: 0.0420, loss_mask: 0.1768, loss: 0.33442021-12-21 22:43:35,294 - mmdet - INFO - Epoch [10][550/930]    lr: 2.000e-03, eta: 0:09:12, time: 0.261, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0099, loss_rpn_bbox: 0.0033, loss_cls: 0.0964, acc: 97.3281, loss_bbox: 0.0342, loss_mask: 0.1658, loss: 0.30962021-12-21 22:43:47,783 - mmdet - INFO - Epoch [10][600/930]    lr: 2.000e-03, eta: 0:09:00, time: 0.250, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0104, loss_rpn_bbox: 0.0031, loss_cls: 0.0975, acc: 97.2461, loss_bbox: 0.0424, loss_mask: 0.1929, loss: 0.34632021-12-21 22:44:00,380 - mmdet - INFO - Epoch [10][650/930]    lr: 2.000e-03, eta: 0:08:47, time: 0.251, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0079, loss_rpn_bbox: 0.0038, loss_cls: 0.0927, acc: 97.3418, loss_bbox: 0.0327, loss_mask: 0.1578, loss: 0.29492021-12-21 22:44:13,144 - mmdet - INFO - Epoch [10][700/930]    lr: 2.000e-03, eta: 0:08:35, time: 0.255, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0116, loss_rpn_bbox: 0.0036, loss_cls: 0.0974, acc: 97.3184, loss_bbox: 0.0369, loss_mask: 0.1717, loss: 0.32122021-12-21 22:44:25,743 - mmdet - INFO - Epoch [10][750/930]    lr: 2.000e-03, eta: 0:08:23, time: 0.252, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0117, loss_rpn_bbox: 0.0037, loss_cls: 0.0926, acc: 97.3027, loss_bbox: 0.0367, loss_mask: 0.1694, loss: 0.31422021-12-21 22:44:38,273 - mmdet - INFO - Epoch [10][800/930]    lr: 2.000e-03, eta: 0:08:10, time: 0.251, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0098, loss_rpn_bbox: 0.0037, loss_cls: 0.1000, acc: 97.1914, loss_bbox: 0.0355, loss_mask: 0.1715, loss: 0.32052021-12-21 22:44:50,699 - mmdet - INFO - Epoch [10][850/930]    lr: 2.000e-03, eta: 0:07:58, time: 0.249, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0122, loss_rpn_bbox: 0.0038, loss_cls: 0.0987, acc: 97.2422, loss_bbox: 0.0386, loss_mask: 0.1738, loss: 0.32712021-12-21 22:45:03,582 - mmdet - INFO - Epoch [10][900/930]    lr: 2.000e-03, eta: 0:07:46, time: 0.258, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0108, loss_rpn_bbox: 0.0039, loss_cls: 0.0902, acc: 97.4922, loss_bbox: 0.0346, loss_mask: 0.1881, loss: 0.32772021-12-21 22:45:11,144 - mmdet - INFO - Saving checkpoint at 10 epochs[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;] 764/764, 8.7 task/s, elapsed: 88s, ETA:     0s2021-12-21 22:46:41,036 - mmdet - INFO - Evaluating bbox...Loading and preparing results...DONE (t=0.01s)creating index...index created!Running per image evaluation...Evaluate annotation type *bbox*DONE (t=1.03s).Accumulating evaluation results...DONE (t=0.41s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.040 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.032 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.375 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.034 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.026 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.388 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.388 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.375 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.467 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.2922021-12-21 22:46:42,629 - mmdet - INFO - Evaluating segm.../mnt/data01/home/gyf/projects/mmdetection/mmdet/datasets/coco.py:450: UserWarning: The key "bbox" is deleted for more accurate mask AP of small/medium/large instances since v2.12.0. This does not change the overall mAP calculation.  warnings.warn(Loading and preparing results...DONE (t=0.12s)creating index...index created!Running per image evaluation...Evaluate annotation type *segm*DONE (t=1.16s).Accumulating evaluation results.../home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/pycocotools/cocoeval.py:378: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)DONE (t=0.41s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.040 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.032 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.215 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.034 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.029 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.396 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.396 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.375 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.479 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.2902021-12-21 22:46:44,436 - mmdet - INFO - Exp name: mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py2021-12-21 22:46:44,437 - mmdet - INFO - Epoch(val) [10][764]   bbox_mAP: 0.0280, bbox_mAP_50: 0.0400, bbox_mAP_75: 0.0320, bbox_mAP_s: 0.3750, bbox_mAP_m: 0.0340, bbox_mAP_l: 0.0260, bbox_mAP_copypaste: 0.028 0.040 0.032 0.375 0.034 0.026, segm_mAP: 0.0290, segm_mAP_50: 0.0400, segm_mAP_75: 0.0320, segm_mAP_s: 0.2150, segm_mAP_m: 0.0340, segm_mAP_l: 0.0290, segm_mAP_copypaste: 0.029 0.040 0.032 0.215 0.034 0.029/mnt/data01/home/gyf/projects/mmdetection/mmdet/core/mask/structures.py:1070: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  bitmap_mask = maskUtils.decode(rle).astype(np.bool)/home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/mmcv/runner/hooks/logger/text.py:112: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],</code></pre><p><strong>Epoch:11</strong></p><pre><code>2021-12-21 22:46:59,408 - mmdet - INFO - Epoch [11][50/930]     lr: 2.000e-03, eta: 0:07:25, time: 0.298, data_time: 0.052, memory: 3050, loss_rpn_cls: 0.0089, loss_rpn_bbox: 0.0034, loss_cls: 0.0933, acc: 97.3789, loss_bbox: 0.0343, loss_mask: 0.1670, loss: 0.30692021-12-21 22:47:11,794 - mmdet - INFO - Epoch [11][100/930]    lr: 2.000e-03, eta: 0:07:13, time: 0.247, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0111, loss_rpn_bbox: 0.0031, loss_cls: 0.0959, acc: 97.3809, loss_bbox: 0.0396, loss_mask: 0.1914, loss: 0.34102021-12-21 22:47:24,298 - mmdet - INFO - Epoch [11][150/930]    lr: 2.000e-03, eta: 0:07:01, time: 0.250, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0093, loss_rpn_bbox: 0.0035, loss_cls: 0.0974, acc: 97.1621, loss_bbox: 0.0396, loss_mask: 0.1836, loss: 0.33352021-12-21 22:47:37,263 - mmdet - INFO - Epoch [11][200/930]    lr: 2.000e-03, eta: 0:06:48, time: 0.259, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0078, loss_rpn_bbox: 0.0036, loss_cls: 0.0989, acc: 97.1270, loss_bbox: 0.0365, loss_mask: 0.1588, loss: 0.30562021-12-21 22:47:49,826 - mmdet - INFO - Epoch [11][250/930]    lr: 2.000e-03, eta: 0:06:36, time: 0.251, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0082, loss_rpn_bbox: 0.0032, loss_cls: 0.0950, acc: 97.2344, loss_bbox: 0.0390, loss_mask: 0.1812, loss: 0.32662021-12-21 22:48:02,369 - mmdet - INFO - Epoch [11][300/930]    lr: 2.000e-03, eta: 0:06:24, time: 0.251, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0088, loss_rpn_bbox: 0.0035, loss_cls: 0.0988, acc: 97.1758, loss_bbox: 0.0386, loss_mask: 0.1627, loss: 0.31242021-12-21 22:48:14,901 - mmdet - INFO - Epoch [11][350/930]    lr: 2.000e-03, eta: 0:06:12, time: 0.251, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0089, loss_rpn_bbox: 0.0034, loss_cls: 0.1009, acc: 97.1836, loss_bbox: 0.0401, loss_mask: 0.1852, loss: 0.33862021-12-21 22:48:27,535 - mmdet - INFO - Epoch [11][400/930]    lr: 2.000e-03, eta: 0:05:59, time: 0.253, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0107, loss_rpn_bbox: 0.0038, loss_cls: 0.0946, acc: 97.3086, loss_bbox: 0.0403, loss_mask: 0.1866, loss: 0.33592021-12-21 22:48:40,439 - mmdet - INFO - Epoch [11][450/930]    lr: 2.000e-03, eta: 0:05:47, time: 0.258, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0113, loss_rpn_bbox: 0.0035, loss_cls: 0.0928, acc: 97.2500, loss_bbox: 0.0379, loss_mask: 0.1665, loss: 0.31212021-12-21 22:48:53,302 - mmdet - INFO - Epoch [11][500/930]    lr: 2.000e-03, eta: 0:05:35, time: 0.257, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0081, loss_rpn_bbox: 0.0029, loss_cls: 0.0917, acc: 97.2832, loss_bbox: 0.0348, loss_mask: 0.1564, loss: 0.29392021-12-21 22:49:06,198 - mmdet - INFO - Epoch [11][550/930]    lr: 2.000e-03, eta: 0:05:23, time: 0.258, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0108, loss_rpn_bbox: 0.0032, loss_cls: 0.0909, acc: 97.4531, loss_bbox: 0.0354, loss_mask: 0.1742, loss: 0.31452021-12-21 22:49:18,938 - mmdet - INFO - Epoch [11][600/930]    lr: 2.000e-03, eta: 0:05:10, time: 0.255, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0103, loss_rpn_bbox: 0.0033, loss_cls: 0.0920, acc: 97.3613, loss_bbox: 0.0343, loss_mask: 0.1648, loss: 0.30472021-12-21 22:49:31,515 - mmdet - INFO - Epoch [11][650/930]    lr: 2.000e-03, eta: 0:04:58, time: 0.251, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0099, loss_rpn_bbox: 0.0034, loss_cls: 0.0949, acc: 97.3184, loss_bbox: 0.0361, loss_mask: 0.1822, loss: 0.32642021-12-21 22:49:44,211 - mmdet - INFO - Exp name: mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py2021-12-21 22:49:44,211 - mmdet - INFO - Epoch [11][700/930]    lr: 2.000e-03, eta: 0:04:46, time: 0.254, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0080, loss_rpn_bbox: 0.0032, loss_cls: 0.0963, acc: 97.1973, loss_bbox: 0.0364, loss_mask: 0.1638, loss: 0.30772021-12-21 22:49:56,887 - mmdet - INFO - Epoch [11][750/930]    lr: 2.000e-03, eta: 0:04:33, time: 0.254, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0094, loss_rpn_bbox: 0.0036, loss_cls: 0.0973, acc: 97.2891, loss_bbox: 0.0380, loss_mask: 0.1839, loss: 0.33222021-12-21 22:50:09,618 - mmdet - INFO - Epoch [11][800/930]    lr: 2.000e-03, eta: 0:04:21, time: 0.255, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0095, loss_rpn_bbox: 0.0027, loss_cls: 0.0944, acc: 97.2871, loss_bbox: 0.0328, loss_mask: 0.1534, loss: 0.29292021-12-21 22:50:22,074 - mmdet - INFO - Epoch [11][850/930]    lr: 2.000e-03, eta: 0:04:09, time: 0.249, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0081, loss_rpn_bbox: 0.0032, loss_cls: 0.0865, acc: 97.5176, loss_bbox: 0.0299, loss_mask: 0.1504, loss: 0.27812021-12-21 22:50:35,180 - mmdet - INFO - Epoch [11][900/930]    lr: 2.000e-03, eta: 0:03:57, time: 0.262, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0074, loss_rpn_bbox: 0.0034, loss_cls: 0.0934, acc: 97.2832, loss_bbox: 0.0353, loss_mask: 0.1628, loss: 0.30222021-12-21 22:50:42,718 - mmdet - INFO - Saving checkpoint at 11 epochs[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;] 764/764, 8.9 task/s, elapsed: 86s, ETA:     0s2021-12-21 22:52:10,927 - mmdet - INFO - Evaluating bbox...Loading and preparing results...DONE (t=0.12s)creating index...index created!Running per image evaluation...Evaluate annotation type *bbox*DONE (t=0.79s).Accumulating evaluation results...DONE (t=0.39s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.040 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.032 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.375 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.033 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.027 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.392 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.392 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.392 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.375 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.466 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.3062021-12-21 22:52:12,261 - mmdet - INFO - Evaluating segm.../mnt/data01/home/gyf/projects/mmdetection/mmdet/datasets/coco.py:450: UserWarning: The key "bbox" is deleted for more accurate mask AP of small/medium/large instances since v2.12.0. This does not change the overall mAP calculation.  warnings.warn(Loading and preparing results...DONE (t=0.15s)creating index...index created!Running per image evaluation...Evaluate annotation type *segm*DONE (t=0.93s).Accumulating evaluation results.../home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/pycocotools/cocoeval.py:378: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)DONE (t=0.40s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.040 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.034 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.096 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.032 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.026 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.386 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.386 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.386 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.400 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.461 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.2992021-12-21 22:52:13,960 - mmdet - INFO - Exp name: mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py2021-12-21 22:52:13,960 - mmdet - INFO - Epoch(val) [11][764]   bbox_mAP: 0.0280, bbox_mAP_50: 0.0400, bbox_mAP_75: 0.0320, bbox_mAP_s: 0.3750, bbox_mAP_m: 0.0330, bbox_mAP_l: 0.0270, bbox_mAP_copypaste: 0.028 0.040 0.032 0.375 0.033 0.027, segm_mAP: 0.0280, segm_mAP_50: 0.0400, segm_mAP_75: 0.0340, segm_mAP_s: 0.0960, segm_mAP_m: 0.0320, segm_mAP_l: 0.0260, segm_mAP_copypaste: 0.028 0.040 0.034 0.096 0.032 0.026/mnt/data01/home/gyf/projects/mmdetection/mmdet/core/mask/structures.py:1070: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  bitmap_mask = maskUtils.decode(rle).astype(np.bool)/home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/mmcv/runner/hooks/logger/text.py:112: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.  mem_mb = torch.tensor([mem / (1024 * 1024)],</code></pre><p><strong>Epoch 12:</strong></p><pre><code>2021-12-21 22:52:29,174 - mmdet - INFO - Epoch [12][50/930]     lr: 2.000e-04, eta: 0:03:36, time: 0.302, data_time: 0.053, memory: 3050, loss_rpn_cls: 0.0076, loss_rpn_bbox: 0.0029, loss_cls: 0.0989, acc: 97.1406, loss_bbox: 0.0379, loss_mask: 0.1692, loss: 0.31662021-12-21 22:52:41,662 - mmdet - INFO - Epoch [12][100/930]    lr: 2.000e-04, eta: 0:03:24, time: 0.250, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0107, loss_rpn_bbox: 0.0033, loss_cls: 0.0990, acc: 97.1719, loss_bbox: 0.0346, loss_mask: 0.1512, loss: 0.29882021-12-21 22:52:53,884 - mmdet - INFO - Epoch [12][150/930]    lr: 2.000e-04, eta: 0:03:12, time: 0.245, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0110, loss_rpn_bbox: 0.0032, loss_cls: 0.0933, acc: 97.4023, loss_bbox: 0.0318, loss_mask: 0.1617, loss: 0.30102021-12-21 22:53:06,489 - mmdet - INFO - Epoch [12][200/930]    lr: 2.000e-04, eta: 0:02:59, time: 0.252, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0078, loss_rpn_bbox: 0.0031, loss_cls: 0.0940, acc: 97.2930, loss_bbox: 0.0370, loss_mask: 0.1674, loss: 0.30942021-12-21 22:53:19,043 - mmdet - INFO - Epoch [12][250/930]    lr: 2.000e-04, eta: 0:02:47, time: 0.251, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0087, loss_rpn_bbox: 0.0031, loss_cls: 0.0910, acc: 97.3789, loss_bbox: 0.0323, loss_mask: 0.1516, loss: 0.28662021-12-21 22:53:31,721 - mmdet - INFO - Epoch [12][300/930]    lr: 2.000e-04, eta: 0:02:35, time: 0.254, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0063, loss_rpn_bbox: 0.0025, loss_cls: 0.0947, acc: 97.1328, loss_bbox: 0.0337, loss_mask: 0.1471, loss: 0.28422021-12-21 22:53:44,582 - mmdet - INFO - Epoch [12][350/930]    lr: 2.000e-04, eta: 0:02:23, time: 0.257, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0076, loss_rpn_bbox: 0.0030, loss_cls: 0.0960, acc: 97.2754, loss_bbox: 0.0382, loss_mask: 0.1741, loss: 0.31892021-12-21 22:53:57,471 - mmdet - INFO - Epoch [12][400/930]    lr: 2.000e-04, eta: 0:02:10, time: 0.258, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0073, loss_rpn_bbox: 0.0026, loss_cls: 0.0936, acc: 97.2344, loss_bbox: 0.0371, loss_mask: 0.1654, loss: 0.30612021-12-21 22:54:10,132 - mmdet - INFO - Epoch [12][450/930]    lr: 2.000e-04, eta: 0:01:58, time: 0.253, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0068, loss_rpn_bbox: 0.0029, loss_cls: 0.0916, acc: 97.3145, loss_bbox: 0.0337, loss_mask: 0.1552, loss: 0.29012021-12-21 22:54:22,944 - mmdet - INFO - Epoch [12][500/930]    lr: 2.000e-04, eta: 0:01:46, time: 0.256, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0082, loss_rpn_bbox: 0.0030, loss_cls: 0.0963, acc: 97.2285, loss_bbox: 0.0353, loss_mask: 0.1573, loss: 0.30032021-12-21 22:54:36,039 - mmdet - INFO - Epoch [12][550/930]    lr: 2.000e-04, eta: 0:01:33, time: 0.262, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0083, loss_rpn_bbox: 0.0033, loss_cls: 0.0970, acc: 97.1484, loss_bbox: 0.0365, loss_mask: 0.1605, loss: 0.30572021-12-21 22:54:48,906 - mmdet - INFO - Epoch [12][600/930]    lr: 2.000e-04, eta: 0:01:21, time: 0.258, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0089, loss_rpn_bbox: 0.0029, loss_cls: 0.0917, acc: 97.2832, loss_bbox: 0.0325, loss_mask: 0.1583, loss: 0.29432021-12-21 22:55:01,618 - mmdet - INFO - Epoch [12][650/930]    lr: 2.000e-04, eta: 0:01:09, time: 0.254, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0088, loss_rpn_bbox: 0.0028, loss_cls: 0.0936, acc: 97.2559, loss_bbox: 0.0377, loss_mask: 0.1702, loss: 0.31322021-12-21 22:55:14,380 - mmdet - INFO - Epoch [12][700/930]    lr: 2.000e-04, eta: 0:00:56, time: 0.255, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0078, loss_rpn_bbox: 0.0029, loss_cls: 0.0920, acc: 97.3027, loss_bbox: 0.0343, loss_mask: 0.1618, loss: 0.29892021-12-21 22:55:26,737 - mmdet - INFO - Epoch [12][750/930]    lr: 2.000e-04, eta: 0:00:44, time: 0.247, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0101, loss_rpn_bbox: 0.0035, loss_cls: 0.0991, acc: 97.2461, loss_bbox: 0.0384, loss_mask: 0.1784, loss: 0.32952021-12-21 22:55:39,582 - mmdet - INFO - Epoch [12][800/930]    lr: 2.000e-04, eta: 0:00:32, time: 0.257, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0098, loss_rpn_bbox: 0.0029, loss_cls: 0.0934, acc: 97.3809, loss_bbox: 0.0344, loss_mask: 0.1634, loss: 0.30402021-12-21 22:55:51,856 - mmdet - INFO - Epoch [12][850/930]    lr: 2.000e-04, eta: 0:00:19, time: 0.246, data_time: 0.009, memory: 3050, loss_rpn_cls: 0.0090, loss_rpn_bbox: 0.0030, loss_cls: 0.0897, acc: 97.3887, loss_bbox: 0.0317, loss_mask: 0.1532, loss: 0.28652021-12-21 22:56:04,717 - mmdet - INFO - Epoch [12][900/930]    lr: 2.000e-04, eta: 0:00:07, time: 0.257, data_time: 0.008, memory: 3050, loss_rpn_cls: 0.0092, loss_rpn_bbox: 0.0027, loss_cls: 0.0912, acc: 97.3066, loss_bbox: 0.0355, loss_mask: 0.1518, loss: 0.29042021-12-21 22:56:12,185 - mmdet - INFO - Saving checkpoint at 12 epochs[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;] 764/764, 8.9 task/s, elapsed: 86s, ETA:     0s2021-12-21 22:57:40,254 - mmdet - INFO - Evaluating bbox...Loading and preparing results...DONE (t=0.13s)creating index...index created!Running per image evaluation...Evaluate annotation type *bbox*DONE (t=0.92s).Accumulating evaluation results...DONE (t=0.40s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.041 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.034 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.400 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.034 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.028 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.394 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.394 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.400 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.471 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.3042021-12-21 22:57:41,738 - mmdet - INFO - Evaluating segm.../mnt/data01/home/gyf/projects/mmdetection/mmdet/datasets/coco.py:450: UserWarning: The key "bbox" is deleted for more accurate mask AP of small/medium/large instances since v2.12.0. This does not change the overall mAP calculation.  warnings.warn(Loading and preparing results...DONE (t=0.17s)creating index...index created!Running per image evaluation...Evaluate annotation type *segm*DONE (t=1.08s).Accumulating evaluation results.../home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/pycocotools/cocoeval.py:378: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)DONE (t=0.42s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.040 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.034 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.237 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.034 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.028 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.394 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.394 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.375 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.471 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.3022021-12-21 22:57:43,654 - mmdet - INFO - Exp name: mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py2021-12-21 22:57:43,654 - mmdet - INFO - Epoch(val) [12][764]   bbox_mAP: 0.0290, bbox_mAP_50: 0.0410, bbox_mAP_75: 0.0340, bbox_mAP_s: 0.4000, bbox_mAP_m: 0.0340, bbox_mAP_l: 0.0280, bbox_mAP_copypaste: 0.029 0.041 0.034 0.400 0.034 0.028, segm_mAP: 0.0290, segm_mAP_50: 0.0400, segm_mAP_75: 0.0340, segm_mAP_s: 0.2370, segm_mAP_m: 0.0340, segm_mAP_l: 0.0280, segm_mAP_copypaste: 0.029 0.040 0.034 0.237 0.034 0.028</code></pre><h4 id="sockets-bbox-æµ‹è¯•"><a href="#sockets-bbox-æµ‹è¯•" class="headerlink" title="sockets bbox æµ‹è¯•"></a>sockets bbox æµ‹è¯•</h4><blockquote><p>2021.12.21æ™š 706</p></blockquote><p><strong>gyf@ubuntu ~/projects/mmdetection</strong></p><p><code>% python tools/test.py configs/fenghuo/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py          work_dirs/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets/latest.pth --eval bbox</code></p><pre><code>loading annotations into memory...Done (t=0.01s)creating index...index created!load checkpoint from local path: work_dirs/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets/latest.pth[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;] 764/764, 8.9 task/s, elapsed: 86s, ETA:     0sEvaluating bbox...Loading and preparing results...DONE (t=0.01s)creating index...index created!Running per image evaluation...Evaluate annotation type *bbox*DONE (t=0.84s).Accumulating evaluation results...DONE (t=0.38s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.041 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.034 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.400 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.034 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.028 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.394 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.394 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.400 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.471 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.304OrderedDict([('bbox_mAP', 0.029), ('bbox_mAP_50', 0.041), ('bbox_mAP_75', 0.034), ('bbox_mAP_s', 0.4), ('bbox_mAP_m', 0.034), ('bbox_mAP_l', 0.028), ('bbox_mAP_copypaste', '0.029 0.041 0.034 0.400 0.034 0.028')])</code></pre><h4 id="sockets-bbox-segm-test"><a href="#sockets-bbox-segm-test" class="headerlink" title="sockets bbox segm test"></a>sockets bbox segm test</h4><p><strong>gyf@ubuntu ~/projects/mmdetection</strong><br><code> % python tools/test.py configs/fenghuo/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets.py work_dirs/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets/latest.pth --eval bbox segm</code> </p><p>(åœ¨ä¸Šè¿°è·¯å¾„ä¸‹æ‰§è¡Œå‘½ä»¤)</p><pre><code>loading annotations into memory...Done (t=0.01s)creating index...index created!load checkpoint from local path: work_dirs/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_sockets/latest.pth[&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;] 764/764, 8.9 task/s, elapsed: 86s, ETA:     0sEvaluating bbox...Loading and preparing results...DONE (t=0.01s)creating index...index created!Running per image evaluation...Evaluate annotation type *bbox*DONE (t=0.87s).Accumulating evaluation results...DONE (t=0.39s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.041 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.034 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.400 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.034 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.028 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.394 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.394 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.400 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.471 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.304Evaluating segm.../mnt/data01/home/gyf/projects/mmdetection/mmdet/datasets/coco.py:450: UserWarning: The key "bbox" is deleted for more accurate mask AP of small/medium/large instances since v2.12.0. This does not change the overall mAP calculation.  warnings.warn(Loading and preparing results...DONE (t=0.10s)creating index...index created!Running per image evaluation...Evaluate annotation type *segm*DONE (t=0.95s).Accumulating evaluation results.../home/gyf/envs/miniconda3/envs/mmlab/lib/python3.9/site-packages/pycocotools/cocoeval.py:378: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations  tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)DONE (t=0.42s). Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.040 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.034 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.237 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.034 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.028 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.394 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.394 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.375 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.471 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.302OrderedDict([('bbox_mAP', 0.029), ('bbox_mAP_50', 0.041), ('bbox_mAP_75', 0.034), ('bbox_mAP_s', 0.4), ('bbox_mAP_m', 0.034), ('bbox_mAP_l', 0.028), ('bbox_mAP_copypaste', '0.029 0.041 0.034 0.400 0.034 0.028'), ('segm_mAP', 0.029), ('segm_mAP_50', 0.04), ('segm_mAP_75', 0.034), ('segm_mAP_s', 0.237), ('segm_mAP_m', 0.034), ('segm_mAP_l', 0.028), ('segm_mAP_copypaste', '0.029 0.040 0.034 0.237 0.034 0.028')])</code></pre>]]></content>
      
      
      <categories>
          
          <category> projects </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mmdetection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>look Transformer</title>
      <link href="/year/01/20/look-Transformer/"/>
      <url>/year/01/20/look-Transformer/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>take tensorboard</title>
      <link href="/year/12/30/take-tensorboard/"/>
      <url>/year/12/30/take-tensorboard/</url>
      
        <content type="html"><![CDATA[<h5 id="Perface"><a href="#Perface" class="headerlink" title="Perface:"></a>Perface:</h5><ul><li><a href="https://blog.csdn.net/weixin_56728251/article/details/116322383">https://blog.csdn.net/weixin_56728251/article/details/116322383</a></li><li><a href="https://blog.csdn.net/shenfuli/article/details/108436423">https://blog.csdn.net/shenfuli/article/details/108436423</a></li><li><a href="https://blog.csdn.net/bigbennyguo/article/details/87956434">https://blog.csdn.net/bigbennyguo/article/details/87956434</a></li></ul><h5 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h5><p><strong>Tensorboard</strong>æ˜¯tensorflowå†…ç½®çš„ä¸€ä¸ªå¯è§†åŒ–å·¥å…·ï¼Œå®ƒé€šè¿‡å°†tensorflowç¨‹åºè¾“å‡ºçš„æ—¥å¿—æ–‡ä»¶çš„ä¿¡æ¯å¯è§†åŒ–ä½¿å¾—tensorflowç¨‹åºçš„ç†è§£ã€è°ƒè¯•å’Œä¼˜åŒ–æ›´åŠ ç®€å•é«˜æ•ˆã€‚<br>Tensorboardçš„å¯è§†åŒ–ä¾èµ–äºtensorflowç¨‹åºè¿è¡Œè¾“å‡ºçš„æ—¥å¿—æ–‡ä»¶ï¼Œå› è€Œtensorboardå’Œtensorflowç¨‹åºåœ¨ä¸åŒçš„è¿›ç¨‹ä¸­è¿è¡Œã€‚<br>TensorBoardç»™æˆ‘ä»¬æä¾›äº†æå…¶æ–¹ä¾¿è€Œå¼ºå¤§çš„å¯è§†åŒ–ç¯å¢ƒã€‚å®ƒå¯ä»¥å¸®åŠ©æˆ‘ä»¬ç†è§£æ•´ä¸ªç¥ç»ç½‘ç»œçš„å­¦ä¹ è¿‡ç¨‹ã€æ•°æ®çš„åˆ†å¸ƒã€æ€§èƒ½ç“¶é¢ˆç­‰ç­‰ã€‚</p><p>å¯æ˜¯å¯¹äº PyTorch ç­‰å…¶ä»–ç¥ç»ç½‘ç»œè®­ç»ƒæ¡†æ¶å¹¶æ²¡æœ‰åŠŸèƒ½åƒ Tensorboard ä¸€æ ·å…¨é¢çš„ç±»ä¼¼å·¥å…·ï¼Œä¸€äº›å·²æœ‰çš„å·¥å…·åŠŸèƒ½æœ‰é™æˆ–ä½¿ç”¨èµ·æ¥æ¯”è¾ƒå›°éš¾ (tensorboard_logger, visdomç­‰) ã€‚TensorboardX è¿™ä¸ªå·¥å…·ä½¿å¾— TensorFlow å¤–çš„å…¶ä»–ç¥ç»ç½‘ç»œæ¡†æ¶ä¹Ÿå¯ä»¥ä½¿ç”¨åˆ° Tensorboard çš„ä¾¿æ·åŠŸèƒ½ã€‚githubä¸Šå·²ç»æœ‰å¤§ç¥å°†tensorboardåº”ç”¨åˆ°pytorchä¸­,<a href="https://github.com/lanpa/tensorboardX">ä»“åº“</a>åœ¨è¿™é‡Œ</p><p>è¯´ç™½äº†ï¼ŒtensorboardåŸæœ¬æ˜¯åœ¨tensoflowæ¡†æ¶ä¸Šåº”ç”¨çš„ï¼Œåæ¥æœ‰å¤§ç¥åœ¨pytorchä¹Ÿå¼€å‘å‡ºäº†è¿™æ ·çš„æ¡†æ¶ã€‚Pytorchå®‰è£…Tensorboardå¯ä»¥å‚è€ƒTensorboardXçš„<a href="https://github.com/lanpa/tensorboardX/blob/master/README.md">readme</a>æ–‡ä»¶.</p><h5 id="Use-Tensorboard"><a href="#Use-Tensorboard" class="headerlink" title="Use Tensorboard"></a>Use Tensorboard</h5><p>1.åˆ›å»ºä¸€ä¸ªSummaryWiterç¤ºä¾‹</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> tensorboardX <span class="token keyword">import</span> SummaryWriter<span class="token comment" spellcheck="true"># Creates writer1 object.</span><span class="token comment" spellcheck="true"># The log will be saved in 'runs/exp'</span>writer1 <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">'runs/exp'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Creates writer2 object with auto generated file name</span><span class="token comment" spellcheck="true"># The log directory will be something like 'runs/Aug20-17-20-33'</span>writer2 <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Creates writer3 object with auto generated file name, the comment will be appended to the filename.</span><span class="token comment" spellcheck="true"># The log directory will be something like 'runs/Aug20-17-20-33-resnet'</span>writer3 <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span>comment<span class="token operator">=</span><span class="token string">'resnet'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>ä»¥ä¸Šæœ‰ä¸‰ç§åˆå§‹åŒ–åˆ›å»ºSummaryWriterçš„æ–¹æ³•</p><ol><li>æä¾›ä¸€ä¸ªè·¯å¾„,ä½¿ç”¨è¯¥è·¯å¾„æ¥ä¿å­˜æ—¥å¿—</li><li>æ— å‚æ•°ï¼Œé»˜è®¤ä½¿ç”¨<strong>runs/æ—¥æœŸæ—¶é—´</strong>è·¯å¾„ä¿å­˜æ—¥å¿—</li><li>æä¾›ä¸€ä¸ªcommentå‚æ•°ï¼Œå°†ä½¿ç”¨<strong>runs/æ—¥æœŸæ—¶é—´-comment</strong>è·¯å¾„ä¿å­˜æ—¥å¿—</li></ol><p>ä¸€èˆ¬æ¥è®²ï¼Œæˆ‘ä»¬å¯¹äºæ¯æ¬¡å®éªŒæ–°å»ºä¸€ä¸ªè·¯å¾„ä¸åŒçš„ SummaryWriterï¼Œä¹Ÿå«ä¸€ä¸ª runï¼Œå¦‚ runs/exp1ã€runs/exp2ã€‚</p><p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°±å¯ä»¥è°ƒç”¨ SummaryWriter å®ä¾‹çš„å„ç§ add_something æ–¹æ³•å‘æ—¥å¿—ä¸­å†™å…¥ä¸åŒç±»å‹çš„æ•°æ®äº†ã€‚æƒ³è¦åœ¨æµè§ˆå™¨ä¸­æŸ¥çœ‹å¯è§†åŒ–è¿™äº›æ•°æ®ï¼Œåªè¦åœ¨å‘½ä»¤è¡Œä¸­å¼€å¯ tensorboard å³å¯ï¼š</p><pre class="line-numbers language-python"><code class="language-python">tensorboard <span class="token operator">-</span><span class="token operator">-</span>logdir<span class="token operator">=</span><span class="token operator">&lt;</span>your_log_dir<span class="token operator">></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>å…¶ä¸­çš„ <your_log_dir> æ—¢å¯ä»¥æ˜¯å•ä¸ª run çš„è·¯å¾„ï¼Œå¦‚ä¸Šé¢ writer1 ç”Ÿæˆçš„ runs/expï¼›ä¹Ÿå¯ä»¥æ˜¯å¤šä¸ª run çš„çˆ¶ç›®å½•ï¼Œå¦‚ runs/ ä¸‹é¢å¯èƒ½ä¼šæœ‰å¾ˆå¤šçš„å­æ–‡ä»¶å¤¹ï¼Œæ¯ä¸ªæ–‡ä»¶å¤¹éƒ½ä»£è¡¨äº†ä¸€æ¬¡å®éªŒï¼Œæˆ‘ä»¬ä»¤ <code>--logdir=runs/</code> å°±å¯ä»¥åœ¨ tensorboard å¯è§†åŒ–ç•Œé¢ä¸­æ–¹ä¾¿åœ°æ¨ªå‘æ¯”è¾ƒ runs/ ä¸‹ä¸åŒæ¬¡å®éªŒæ‰€å¾—æ•°æ®çš„å·®å¼‚ã€‚</your_log_dir></p><h5 id="ä½¿ç”¨addæ–¹æ³•è®°å½•æ•°æ®"><a href="#ä½¿ç”¨addæ–¹æ³•è®°å½•æ•°æ®" class="headerlink" title="ä½¿ç”¨addæ–¹æ³•è®°å½•æ•°æ®"></a>ä½¿ç”¨addæ–¹æ³•è®°å½•æ•°æ®</h5><p>tensorboardé’ˆå¯¹ä¸åŒçš„ç±»å‹äººä¸ºçš„åŒºåˆ†å¤šä¸ªæ ‡ç­¾ï¼Œæ¯ä¸€ä¸ªæ ‡ç­¾é¡µé¢ä»£è¡¨ä¸åŒçš„ç±»å‹ï¼Œä¸‹é¢è¯¦ç»†ä»‹ç» SummaryWriter å®ä¾‹çš„å„ç§æ•°æ®è®°å½•æ–¹æ³•</p><h6 id="scalar"><a href="#scalar" class="headerlink" title="scalar"></a>scalar</h6><p>å¯¹æ ‡é‡æ•°æ®è¿›è¡Œæ±‡æ€»å’Œè®°å½•ï¼Œé€šå¸¸ç”¨æ¥å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ä¸­éšç€è¿­ä»£æ¬¡æ•°å‡†ç¡®ç‡(val acc)ã€æŸå¤±å€¼(train/test loss)ã€å­¦ä¹ ç‡(learning rate)ã€æ¯ä¸€å±‚çš„æƒé‡å’Œåç½®çš„ç»Ÿè®¡é‡(meanã€stdã€max/min)ç­‰çš„å˜åŒ–æ›²çº¿ï¼Œä½¿ç”¨ <code>add_scalar</code> æ–¹æ³•æ¥è®°å½•æ•°å­—å¸¸é‡ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> tensorboard </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SA Study</title>
      <link href="/year/12/16/SA-Study/"/>
      <url>/year/12/16/SA-Study/</url>
      
        <content type="html"><![CDATA[<h4 id="Perface"><a href="#Perface" class="headerlink" title="Perface"></a>Perface</h4><p>Sentiment Analysisæ˜¯nlpé¢†åŸŸä¸€ä¸ªé«˜é˜¶çš„taskä¹‹ä¸€ï¼Œè¿™ä¸ªä»»åŠ¡ç›®æ ‡æ˜¯è®©è®¡ç®—æœºç†è§£äººç±»çš„æƒ…æ„Ÿä¸–ç•Œï¼Œè€Œåœ¨æœºå™¨å­¦ä¹ çš„è®¤çŸ¥æ™ºèƒ½é˜¶æ®µ(ä¸‰ä¸ªé˜¶æ®µï¼šè®¡ç®—æ™ºèƒ½ï¼Œæ„ŸçŸ¥æ™ºèƒ½ï¼Œè®¤çŸ¥æ™ºèƒ½)ã€‚</p><p>â€‹    è€Œæƒ…æ„Ÿåˆ†æä»»åŠ¡ä¹Ÿç®—æ˜¯ä¸ªåˆ†ç±»ä»»åŠ¡ï¼Œç»™æ¨¡å‹è¾“å…¥ä¸€å¥è¯ï¼Œè®©å®ƒåˆ¤æ–­è¿™å¥è¯çš„æƒ…æ„Ÿæ˜¯ç§¯æçš„è¿˜æ˜¯æ¶ˆæçš„è¿˜æ˜¯ä¸­æ€§çš„ï¼Œå½“ç„¶è¿™åªæ˜¯SAä»»åŠ¡å…¶ä¸­æ¯”è¾ƒç®€å•çš„å¤„ç†ç›®æ ‡ï¼Œè€Œæ›´åŠ é«˜é˜¶çš„ä»»åŠ¡æ˜¯<strong>ç»†ç²’åº¦çš„æƒ…æ„Ÿåˆ†æ</strong>ï¼šå¸Œæœ›æ¨¡å‹ä¸ä»…èƒ½è¯†åˆ«å‡ºæƒ…æ„Ÿçš„å¥½åï¼Œè€Œä¸”è¿˜å¸Œæœ›æ¨¡å‹èƒ½è¯†åˆ«å‡ºæ˜¯ç”±äºä»€ä¹ˆåŸå› å¯¼è‡´è¿™ç§æƒ…æ„Ÿå‘ç”Ÿã€‚ä¸¾ä¸ªä¾‹å­,â€è¿™å®¶é¤å…çš„åœ°ç†ä½ç½®ä¸é”™ï¼Œå¯æƒœèœä¸æ€ä¹ˆå¥½åƒâ€ï¼Œæˆ‘ä»¬å°±éœ€è¦è¯†åˆ«å‡ºï¼Œåœ¨åœ°ç†ä½ç½®è¿™ä¸ªaspectä¸Šæƒ…æ„Ÿæ˜¯ç§¯æçš„ï¼Œè€Œåœ¨èœçš„å‘³é“è¿™ä¸ªaspectä¸Šæƒ…æ„Ÿæ˜¯æ¶ˆæçš„ã€‚</p><p>â€‹    æ¶‰åŠåˆ°åˆ†ç±»çš„ä»»åŠ¡çš„ç®—æ³•ï¼Œä¼šæœ‰LVMï¼ŒLogisticï¼ŒD-Treeç­‰ç»å…¸æ¨¡å‹ï¼Œè€Œå¯¹äºæ–‡æœ¬åˆ†ç±»æ¥è¯´æœ€é‡è¦çš„æ˜¯è®²ä¸€å¥è¯æ˜ å°„åˆ°å‘é‡ç©ºé—´åŒæ—¶ä¸å¤±å»è¯­ä¹‰ç‰¹å¾ã€‚æ–‡æœ¬çš„å‘é‡åŒ–æ¶‰åŠåˆ°<strong>Word Embedding</strong>æŠ€æœ¯å’ŒDLæŠ€æœ¯ã€‚<strong>Word Embedding</strong>æŒ‡çš„æ˜¯æŠŠæ–‡æœ¬è½¬æ¢æˆè®¡ç®—æœºèƒ½å¤„ç†çš„å‘é‡ï¼Œè€Œå…¶ä¸­éš¾ç‚¹çš„æ˜¯ï¼šå°†æ–‡æœ¬å‘é‡åŒ–æ—¶å¦‚ä½•ä¿æŒå¥å­åŸæœ‰çš„è¯­ä¹‰ã€‚æ—©æœŸword embeddingä½¿ç”¨çš„æ˜¯Bag of Wordsï¼ŒTF-IDFç­‰ï¼Œè¿™äº›ç®—æ³•æœ‰ä¸ªå…±åŒçš„ç‰¹ç‚¹ï¼šå°±æ˜¯æ²¡æœ‰è€ƒè™‘è¯­åºä»¥åŠä¸Šä¸‹æ–‡å…³ç³»ã€‚è€Œåæ¥å‡ºç°äº†æ›´ä¸ºå…ˆè¿›<strong>Word2Vector ï¼ŒGlove</strong>ç­‰è€ƒè™‘ä¸Šä¸‹æ–‡å…³ç³»çš„ï¼Œ19å¹´NLPé¢†åŸŸå¤§æ”¾å¼‚å½©çš„<strong>BERT</strong>å°±æ˜¯åœ¨æ–‡æœ¬å‘é‡åŒ–ä¸Šåšå‡ºäº†å¾ˆå¤§çš„çªç ´ã€‚<strong>æ·±åº¦å­¦ä¹ </strong>æ¨¡å‹å¯ä»¥å°†ç‰¹å¾å·¥ç¨‹è‡ªåŠ¨åŒ–ï¼Œæ¨¡å‹è‡ªåŠ¨å¯»æ‰¾ç‰¹å¾ï¼Œæ¯•ç«Ÿäººå·¥ç‰¹å¾æ˜¯ä¸ªè´¹è„‘è´¹æ—¶çš„è¿‡ç¨‹ã€‚åœ¨NLPå½“ä¸­çš„è¿ç”¨ä¹Ÿå¸ç©ºè§æƒ¯äº†,<strong>RNN</strong>(LSTM,GRU)ï¼Œ<strong>CNN</strong>ï¼Œ<strong>Transformer</strong>ç­‰å„è·¯ç¥ä»™ä¹Ÿåœ¨å„æ˜¾ç¥é€šã€‚æ·±åº¦å­¦ä¹ æ¨¡å‹å‡­å€Ÿå…¶å¼ºå¤§çš„è¡¨ç¤ºèƒ½åŠ›ï¼Œåœ¨å¾ˆå¤šä»»åŠ¡ä¸­éƒ½åŠæ‰“äººå·¥ç‰¹å¾ã€‚</p><p>ä¸‹é¢åˆ©ç”¨transformerå¯¹ä¸‹æ¸¸nlpä»»åŠ¡è¿›è¡Œ<strong>fine tune</strong>ã€‚Per-trainingæ¨¡å‹çš„èŒƒå¼å°±æ˜¯åœ¨å¤§æ•°æ®é›†ä¸Šè®©æ¨¡å‹å­¦ä¹ åˆ°é€šç”¨çš„è¯­è¨€çŸ¥è¯†ï¼Œåœ¨æ­¤åŸºç¡€ä¸Šå¯¹ç›®æ ‡ä»»åŠ¡è¿›è¡Œå°è§„æ¨¡çš„å¾®è°ƒè¾¾åˆ°çŸ¥è¯†è¿ç§»ï¼Œç®—åŠ›å…±äº«å’Œä¸“é¡¹é«˜ç²¾ç­‰å¤šèµ¢çš„ç›®æ ‡ï¼Œ<strong>Huggingface Transformers</strong>æ•´åˆäº†ç±»Bertæ¨¡å‹çš„æ¥å£æä¾›Pre-trainingåº“ï¼Œæ‰€ä»¥æˆ‘ä»¬è¿›è¡Œå¾®è°ƒæ¥è¾¾åˆ°è‡ªå·±çš„ç›®æ ‡ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> nlp </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Sentiment Analysis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>notes of huggingface transformer</title>
      <link href="/year/11/25/notes-of-huggingface-transformer/"/>
      <url>/year/11/25/notes-of-huggingface-transformer/</url>
      
        <content type="html"><![CDATA[<h4 id="Perface"><a href="#Perface" class="headerlink" title="Perface"></a>Perface</h4><blockquote><p>åšæ–‡å‚è€ƒäº†huggingfaceå®˜ç½‘æ•™ç¨‹(<del>åœ¨åŸæ–‡æ¬è¿çš„åŸºç¡€ä¸ŠåŠ äº†ç¬”è®°</del>)</p></blockquote><p>HuggingFace-Transformersæ‰‹å†Œæ˜¯å¼€æºå…¬å¸HuggingFaceå¼€å‘çš„æ¶µç›–å¾ˆå¤šæ¨¡å‹çš„æ¡†æ¶ã€‚</p><p>Transformers(å‰èº«æ˜¯ç§°ä¸ºpytorch Transformerså’Œpytorch pretrained bert)ä¸ºè‡ªç„¶è¯­è¨€ç†è§£(NLU)å’Œè‡ªç„¶è¯­è¨€ç”Ÿæˆ(NLG)æä¾›äº†æœ€å…ˆè¿›çš„é€šç”¨æ¶æ„(bert,GPT-2,RoBERTTa,XLM,DistileBert,XLNet,CTRLâ€¦..),å…¶ä¸­è¶…è¿‡32ä¸ª100å¤šç§è¯­è¨€çš„é¢„è®­ç»ƒæ¨¡å‹å¹¶åŒæ—¶æ”¯æŒTensorflow 2.0å’ŒPytorchä¸¤å¤§æ·±åº¦å­¦ä¹ æ¡†æ¶.</p><p>The library was designed with two strong goals in mind:</p><ul><li><p>Be as easy and fast to use as possible:</p><blockquote><ul><li>We strongly limited the number of user-facing abstractions to learn, in fact, there are almost no abstractions, just three standard classes required to use each model: <a href="https://huggingface.co/transformers/main_classes/configuration.html">configuration</a>, <a href="https://huggingface.co/transformers/main_classes/model.html">models</a> and <a href="https://huggingface.co/transformers/main_classes/tokenizer.html">tokenizer</a>.</li><li>All of these classes can be initialized in a simple and unified way from pretrained instances by using a common <code>from_pretrained()</code> instantiation method which will take care of downloading (if needed), caching and loading the related class instance and associated data (configurationsâ€™ hyper-parameters, tokenizersâ€™ vocabulary, and modelsâ€™ weights) from a pretrained checkpoint provided on <a href="https://huggingface.co/models">Hugging Face Hub</a> or your own saved checkpoint.</li><li>On top of those three base classes, the library provides two APIs: <a href="https://huggingface.co/transformers/main_classes/pipelines.html#transformers.pipeline"><code>pipeline()</code></a> for quickly using a model (plus its associated tokenizer and configuration) on a given task and <a href="https://huggingface.co/transformers/main_classes/trainer.html#transformers.Trainer"><code>Trainer()</code></a>/<a href="https://huggingface.co/transformers/main_classes/trainer.html#transformers.TFTrainer"><code>TFTrainer()</code></a> to quickly train or fine-tune a given model.</li><li>As a consequence, this library is NOT a modular toolbox of building blocks for neural nets. If you want to extend/build-upon the library, just use regular Python/PyTorch/TensorFlow/Keras modules and inherit from the base classes of the library to reuse functionalities like model loading/saving.</li></ul></blockquote></li><li><p>Provide state-of-the-art models with performances as close as possible to the original models:</p><blockquote><ul><li>We provide at least one example for each architecture which reproduces a result provided by the official authors of said architecture.</li><li>The code is usually as close to the original code base as possible which means some PyTorch code may be not as <em>pytorchic</em> as it could be as a result of being converted TensorFlow code and vice versa.</li></ul></blockquote></li></ul><p>è¿™æ˜¯<a href="https://huggingface.co/transformers/philosophy.html%E5%AE%98%E7%BD%91%E7%BB%99%E5%87%BA%E7%9A%84%E8%A7%A3%E9%87%8A%EF%BC%9A">https://huggingface.co/transformers/philosophy.htmlå®˜ç½‘ç»™å‡ºçš„è§£é‡Šï¼š</a></p><ul><li>æ¶æ„<ul><li>ä½¿ç”¨æ¯ä¸ªæ¨¡å‹éƒ½éœ€è¦ä¸‰ä¸ªæ ‡å‡†ç±»:<strong>configuration</strong>,<strong>models</strong>,<strong>tokenizer</strong>.modelç”¨äºæŒ‡å®šä½¿ç”¨çš„æ¨¡å‹,ä¾‹å¦‚modelä¸ºbertï¼Œé‚£ä¹ˆç›¸åº”çš„ç½‘ç»œç»“æ„æ˜¯bertçš„ç½‘ç»œç»“æ„ï¼›configurationæ˜¯æ¨¡å‹å…·ä½“çš„æ¶æ„é…ç½®ï¼Œä¾‹å¦‚å¯ä»¥é…ç½®å¤šå¤´çš„æ•°é‡ç­‰ç­‰,è¿™é‡Œé…ç½®éœ€è¦æ³¨æ„çš„åœ°æ–¹å°±æ˜¯ï¼Œå¦‚æœè‡ªå®šä¹‰é…ç½®ä¸æ”¹å˜æ ¸å¿ƒç½‘ç»œç»“æ„çš„åˆ™ä»æ—§å¯ä»¥ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æƒé‡ï¼Œå¦‚æœé…ç½®æ¶‰åŠåˆ°æ ¸å¿ƒç»“æ„çš„ä¿®æ”¹ï¼Œä¾‹å¦‚å‰é¦ˆç½‘ç»œçš„éšå±‚ç¥ç»å…ƒçš„ä¸ªæ•°ï¼Œåˆ™æ— æ³•ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æƒé‡ï¼Œè¿™ä¸ªæ—¶å€™transformersä¼šé»˜è®¤ä½ è¦é‡æ–°è‡ªå·±é¢„è®­ç»ƒä¸€ä¸ªæ¨¡å‹ä»è€Œéšæœºåˆå§‹åŒ–æ•´ä¸ªæ¨¡å‹çš„æƒé‡ï¼Œè¿™æ˜¯æ˜¯ä¸€ç§åŠçµæ´»æ€§çš„è®¾è®¡.</li><li>æ‰€æœ‰è¿™äº›ç±»éƒ½å¯ä»¥ä½¿ç”¨é€šç”¨çš„from_pretrained()å®ä¾‹åŒ–æ–¹æ³•ï¼Œä»¥ç®€å•ç»Ÿä¸€çš„æ–¹å¼ä»å—è¿‡è®­ç»ƒçš„å®ä¾‹ä¸­åˆå§‹åŒ–ï¼Œè¯¥æ–¹æ³•å°†è´Ÿè´£ä¸‹è½½ï¼ˆå¦‚æœéœ€è¦ï¼‰ï¼Œç¼“å­˜å’ŒåŠ è½½ç›¸å…³çš„ç±»å®ä¾‹ä»¥åŠç›¸å…³çš„æ•°æ®(configçš„çš„è¶…å‚æ•°ï¼Œtokenizerç”Ÿæˆå™¨çš„è¯æ±‡è¡¨å’Œæ¨¡å‹çš„æƒé‡)åœ¨ <a href="https://link.zhihu.com/?target=https://huggingface.co/models">Hugging Face Hub</a> ä¸Šæä¾›çš„é¢„å…ˆè®­ç»ƒçš„æ£€æŸ¥ç‚¹æˆ–æ‚¨è‡ªå·±ä¿å­˜çš„æ£€æŸ¥ç‚¹</li><li>åœ¨è¿™ä¸‰ä¸ªåŸºæœ¬ç±»çš„åŸºç¡€ä¸Šï¼Œè¯¥åº“æä¾›äº†ä¸¤ä¸ªAPIï¼š<ul><li><a href="https://link.zhihu.com/?target=https://huggingface.co/transformers/main_classes/pipelines.html%23transformers.pipeline">pipeline()</a>ç”¨äºåœ¨ç»™å®šä»»åŠ¡ä¸Šå¿«é€Ÿä½¿ç”¨æ¨¡å‹ï¼ˆåŠå…¶å…³è”çš„tokenizerå’Œconfigurationï¼‰å’Œ </li><li>Traineræˆ–è€…<a href="https://link.zhihu.com/?target=https://huggingface.co/transformers/main_classes/trainer.html%23transformers.TFTrainer">TF</a>trainer å¿«é€Ÿè®­ç»ƒæˆ–å¾®è°ƒç»™å®šæ¨¡å‹</li></ul></li></ul></li></ul><p>å› æ­¤<strong>Transformers</strong>ä¸æ˜¯ç¥ç»ç½‘ç»œæ„å»ºæ¨¡å—åŒ–çš„æ¨¡å—å·¥å…·ç®±ã€‚å¦‚æœè¦æ‰©å±•/æ„å»ºåº“ï¼Œåªéœ€ä½¿ç”¨å¸¸è§„çš„Python / PyTorch / TensorFlow / Kerasæ¨¡å—å¹¶ä»åº“çš„åŸºç±»ç»§æ‰¿å³å¯é‡ç”¨æ¨¡å‹åŠ è½½/ä¿å­˜ä¹‹ç±»çš„åŠŸèƒ½ã€‚</p><p>ç°æœ‰çš„é¢„è®­ç»ƒæ¨¡å‹æ•´ä½“ä¸Šéƒ½å±äºä¸‹é¢çš„äº”ä¸ªç±»åˆ«ï¼š</p><h5 id="Decoders-or-autoregressive-models"><a href="#Decoders-or-autoregressive-models" class="headerlink" title="Decoders or autoregressive models"></a>Decoders or autoregressive models</h5><p>è‡ªå›å½’æ¨¡å‹åœ¨ç»å…¸è¯­è¨€å»ºæ¨¡ä»»åŠ¡ä¸Šè¿›è¡Œäº†é¢„è®­ç»ƒï¼šçŒœæµ‹ä¸‹ä¸€ä¸ªå·²è¯»å®Œæ‰€æœ‰å…ˆå‰tokençš„tokenã€‚å®ƒä»¬å¯¹åº”äºtransformeræ¨¡å‹çš„è§£ç å™¨éƒ¨åˆ†ï¼Œå¹¶ä¸”åœ¨æ•´ä¸ªå¥å­çš„é¡¶éƒ¨ä½¿ç”¨äº†ä¸€ä¸ªæ©ç ï¼Œä»¥ä¾¿æ³¨æ„å¤´åªèƒ½çœ‹åˆ°æ–‡æœ¬ä¸­çš„ä¹‹å‰å†…å®¹ï¼Œè€Œä¸èƒ½çœ‹åˆ°å…¶åçš„å†…å®¹ã€‚å°½ç®¡å¯ä»¥å¯¹è¿™äº›æ¨¡å‹è¿›è¡Œå¾®è°ƒå¹¶åœ¨è®¸å¤šä»»åŠ¡ä¸Šå–å¾—å‡ºè‰²çš„ç»“æœï¼Œä½†å…¶æœ€è‡ªç„¶çš„åº”ç”¨æ˜¯æ–‡æœ¬ç”Ÿæˆã€‚æ­¤ç±»æ¨¡å‹çš„å…¸å‹ä¾‹å­æ˜¯GPT</p><h5 id="Encoders-or-autoencoding-models"><a href="#Encoders-or-autoencoding-models" class="headerlink" title="Encoders or autoencoding models"></a>Encoders or autoencoding models</h5><p>é€šè¿‡ä»¥æŸç§æ–¹å¼ç ´åè¾“å…¥tokenå¹¶å°è¯•é‡å»ºåŸå§‹å¥å­æ¥å¯¹è‡ªç¼–ç æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒã€‚ä»æŸç§æ„ä¹‰ä¸Šè¯´ï¼Œå®ƒä»¬ä¸transformerä¸­çš„çš„ç¼–ç å™¨ç›¸å¯¹åº”ï¼Œå› ä¸ºå®ƒä»¬æ— éœ€ä»»ä½•æ©ç å³å¯è®¿é—®å®Œæ•´çš„è¾“å…¥ã€‚è¿™äº›æ¨¡å‹é€šå¸¸å»ºç«‹æ•´ä¸ªå¥å­çš„åŒå‘è¡¨ç¤ºã€‚å¯ä»¥å¯¹å®ƒä»¬è¿›è¡Œå¾®è°ƒå¹¶åœ¨è®¸å¤šä»»åŠ¡ï¼ˆä¾‹å¦‚æ–‡æœ¬ç”Ÿæˆï¼‰ä¸Šå–å¾—å‡ºè‰²çš„ç»“æœï¼Œä½†æ˜¯å®ƒä»¬æœ€è‡ªç„¶çš„åº”ç”¨æ˜¯æ–‡æœ¬åˆ†ç±»æˆ–tokenåˆ†ç±»ï¼ˆæ¯”å¦‚è¯æ€§æ ‡æ³¨ï¼‰ã€‚æ­¤ç±»æ¨¡å‹çš„å…¸å‹ä¾‹å­æ˜¯BERT</p><p>è‡ªåŠ¨å›å½’æ¨¡å‹å’Œè‡ªåŠ¨ç¼–ç æ¨¡å‹ä¹‹é—´çš„å”¯ä¸€åŒºåˆ«åœ¨äºæ¨¡å‹çš„é¢„è®­ç»ƒæ–¹å¼ã€‚å› æ­¤ï¼Œç›¸åŒçš„ä½“ç³»ç»“æ„æ—¢å¯ä»¥ç”¨äºè‡ªåŠ¨å›å½’æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥ç”¨äºè‡ªåŠ¨ç¼–ç æ¨¡å‹.</p><h5 id="Sequence-to-Sequence-models"><a href="#Sequence-to-Sequence-models" class="headerlink" title="Sequence-to-Sequence models"></a>Sequence-to-Sequence models</h5><p>åºåˆ—åˆ°åºåˆ—æ¨¡å‹å°†transformersçš„ç¼–ç å™¨å’Œè§£ç å™¨åŒæ—¶ç”¨äºç¿»è¯‘ä»»åŠ¡æˆ–é€šè¿‡å°†å…¶ä»–ä»»åŠ¡è½¬æ¢ä¸ºåºåˆ—åˆ°åºåˆ—é—®é¢˜æ¥è®­ç»ƒå¾—åˆ°çš„ã€‚å¯ä»¥å°†å®ƒä»¬å¾®è°ƒæ¥é€‚åº”è®¸å¤šä»»åŠ¡ï¼ˆè¿™é‡Œåº”è¯¥æ˜¯è¯´æŠŠsequence to sequenceçš„é¢„è®­ç»ƒæ¨¡å‹çš„encoderæˆ–è€…decoderå•ç‹¬æŠ½å–å‡ºæ¥ï¼Œç„¶åç”¨æ³•å°±å’Œä¸Šé¢ä¸¤ç§æ¨¡å‹çš„ç”¨æ³•ä¸€è‡´ï¼‰ï¼Œä½†æœ€è‡ªç„¶çš„åº”ç”¨æ˜¯ç¿»è¯‘ï¼Œæ‘˜è¦å’Œé—®é¢˜è§£ç­”ã€‚T5æ˜¯ä¸€ä¸ªå…¸å‹çš„ä¾‹å­.</p><h5 id="Multimodal-models"><a href="#Multimodal-models" class="headerlink" title="Multimodal models"></a>Multimodal models</h5><p>å¤šæ¨¡æ€æ¨¡å‹å°†æ–‡æœ¬è¾“å…¥ä¸å…¶ä»–ç±»å‹çš„è¾“å…¥ï¼ˆä¾‹å¦‚å›¾åƒï¼‰æ··åˆåœ¨ä¸€èµ·ï¼Œå¹¶ä¸”æ›´ç‰¹å®šäºç»™å®šä»»åŠ¡.</p><p><img src="https://s2.loli.net/2021/12/23/zu7FbaZfjXMVUyG.png" alt="image-20211125193439861.png"></p><p>è¿™ç§æ¨¡å‹æ²¡æœ‰æä¾›ä»»ä½•é¢„è®­ç»ƒæƒé‡åªæ˜¯å®šä¹‰äº†æ¨¡å‹çš„ç»“æ„.</p><h5 id="Retrieval-based-models"><a href="#Retrieval-based-models" class="headerlink" title="Retrieval-based models"></a>Retrieval-based models</h5><p><img src="https://s2.loli.net/2021/12/23/aqH4X5ikoGsVjDp.png" alt="image-20211125193530708.png"></p><h4 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h4><p>  The most basic object in the ğŸ¤— Transformers library is the <code>pipeline()</code> function. It connects a model with its necessary preprocessing and postprocessing steps, allowing us to directly input any text and get an intelligible answer:</p><p>  There are three main steps involved when you pass some text to a pipeline:</p><ol><li>The text is preprocessed into a format the model can understand.</li><li>The preprocessed inputs are passde to the model .</li><li>The predictions of the model are post-processed,so you can make sense of them.</li></ol><p>Some of the currently <strong>available pipelines</strong> are:</p><ul><li>feature-extraction(get the vector representation of a text)</li><li>file-mask</li><li>ner(named entity recogniton)</li><li>question-answering</li><li>sentiment-analysis</li><li>summarization</li><li>text-generation</li><li>translation</li><li>zero-shot-classification</li></ul><h4 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h4><h5 id="Transformer-history"><a href="#Transformer-history" class="headerlink" title="Transformer history"></a>Transformer history</h5><p><img src="https://s6.jpg.cm/2021/12/23/Lbta92.png" alt="Lbta92.png"></p><p>The <a href="https://arxiv.org/abs/1706.03762">Transformer architecture</a> was introduced in June 2017. The focus of the original research was on translation tasks. This was followed by the introduction of several influential models, including:</p><ul><li><strong>June 2018</strong>: <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">GPT</a>, the first pretrained Transformer model, used for fine-tuning on various NLP tasks and obtained state-of-the-art results</li><li><strong>October 2018</strong>: <a href="https://arxiv.org/abs/1810.04805">BERT</a>, another large pretrained model, this one designed to produce better summaries of sentences (more on this in the next chapter!)</li><li><strong>February 2019</strong>: <a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">GPT-2</a>, an improved (and bigger) version of GPT that was not immediately publicly released due to ethical concerns</li><li><strong>October 2019</strong>: <a href="https://arxiv.org/abs/1910.01108">DistilBERT</a>, a distilled version of BERT that is 60% faster, 40% lighter in memory, and still retains 97% of BERTâ€™s performance</li><li><strong>October 2019</strong>: <a href="https://arxiv.org/abs/1910.13461">BART</a> and <a href="https://arxiv.org/abs/1910.10683">T5</a>, two large pretrained models using the same architecture as the original Transformer model (the first to do so)</li><li><strong>May 2020</strong>, <a href="https://arxiv.org/abs/2005.14165">GPT-3</a>, an even bigger version of GPT-2 that is able to perform well on a variety of tasks without the need for fine-tuning (called <em>zero-shot learning</em>)</li></ul><p>This list is far from comprehensive, and is just meant to highlight a few of the different kinds of Transformer models. Broadly, they can be grouped into three categories:</p><ul><li>GPT-like (also called <em>auto-regressive</em> Transformer models)</li><li>BERT-like (also called <em>auto-encoding</em> Transformer models)</li><li>BART/T5-like (also called <em>sequence-to-sequence</em> Transformer models)</li></ul><p>We will dive into these families in more depth later on.</p><h5 id="Transformers-are-language-models"><a href="#Transformers-are-language-models" class="headerlink" title="Transformers are language models"></a>Transformers are language models</h5><p>All the Transformer models mentioned above (GPT, BERT, BART, T5, etc.) have been trained as <em>language models</em>. This means they have been trained on large amounts of raw text in a self-supervised fashion. <strong>Self-supervised</strong> learning is a type of training in which the objective is automatically computed from the inputs of the model. That means that humans are not needed to label the data!</p><p>æ‰€æœ‰ä¸Šè¿°æåˆ°çš„æ¨¡å‹éƒ½å·²ç»è¢«è®­ç»ƒæˆäº†å¯¹åº”çš„è¯­è¨€æ¨¡å‹ã€‚è¿™ä¹Ÿå°±æ˜¯è¯´è¿™äº›æ¨¡å‹ä»¥è‡ªæˆ‘ç›‘ç£çš„æ–¹å¼æ¥å—äº†å¤§é‡åŸå§‹æ–‡æœ¬çš„è®­ç»ƒã€‚è‡ªç›‘ç£å­¦ä¹ æ˜¯ä¸€ç§è®­ç»ƒç±»å‹ï¼Œç›®æ ‡æ˜¯æ ¹æ®æ¨¡å‹çš„è¾“å…¥è‡ªåŠ¨è®¡ç®—çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ä¸éœ€è¦äººç±»æ‰‹åŠ¨æ ‡è®°æ•°æ®ã€‚</p><hr><p>This type of model develops a statistical understanding of the language it has been trained on, but itâ€™s not very useful for specific practical tasks. Because of this, the general pretrained model then goes through a process called <em><strong>transfer learning</strong></em>. During this process, the model is fine-tuned in a supervised way â€” that is, using human-annotated labels â€” on a given task</p><p>è¿™ç§ç±»å‹çš„æ¨¡å‹å¯¹å…¶æ‰€è®­ç»ƒçš„è¯­è¨€æœ‰ç»Ÿè®¡ç†è§£ä½†å¯¹äºç‰¹å®šçš„å®é™…ä»»åŠ¡ä¸æ˜¯å¾ˆæœ‰ç”¨ã€‚å› æ­¤é€šç”¨çš„é¢„è®­ç»ƒæ¨¡å‹éƒ½ä¼šç»å†ä¸€ä¸ªç§°ä¸º<strong>è¿ç§»å­¦ä¹ </strong>çš„è¿‡ç¨‹ã€‚åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œæ¨¡å‹åœ¨ç»™å®šçš„ä»»åŠ¡ä¸Šä»¥æœ‰ç›‘ç£çš„æ–¹å¼è¿›è¡Œå¾®è°ƒâ€”â€”å³ä½¿ç”¨äººå·¥æ ‡æ³¨çš„æ•°æ®æ ‡ç­¾ã€‚</p><hr><p>An example of a task is predicting the next word in a sentence having read the <em>n</em> previous words. This is called *<strong>causal language modeling</strong> because the output depends on the past and present inputs, but not the future ones.  </p><p>ä»»åŠ¡çš„ä¸€ä¸ªå®ä¾‹å°±æ˜¯é¢„æµ‹å·²ç»é˜…è¯»çš„å‰nä¸ªå•è¯çš„å¥å­çš„ä¸‹ä¸€ä¸ªå•è¯ã€‚è¿™ä¹Ÿè¢«ç§°ä¸º<strong>å› æœè¯­è¨€å»ºæ¨¡</strong>ï¼Œå› ä¸ºè¾“å‡ºå–å†³äºè¿‡å»å’Œç°åœ¨çš„è¾“å…¥è€Œä¸æ˜¯æœªæ¥çš„è¾“å…¥ã€‚</p><p><img src="https://s6.jpg.cm/2021/12/23/LbtxQH.png" alt="LbtxQH.png"></p><p>Another example is <em>masked language modeling</em>, in which the model predicts a masked word in the sentence.</p><p>å¦ä¸€ä¸ªä¾‹å­æ˜¯æ©ç è¯­è¨€å»ºæ¨¡ï¼Œå…¶ä¸­æ¨¡å‹é¢„æµ‹å¥å­çš„æ©ç è¯ã€‚</p><h5 id="Transformer-are-big-models"><a href="#Transformer-are-big-models" class="headerlink" title="Transformer are big models"></a>Transformer are big models</h5><p>Apart from a few outliers (like DistilBERT), the general strategy to achieve better performance is by increasing the modelsâ€™ sizes as well as the amount of data they are pretrained on.</p><p>é™¤äº†ä¸€äº›ç‰¹æ®Š(å¦‚ DistilBERT)å¤–ï¼Œå®ç°æ›´å¥½æ€§èƒ½çš„ä¸€èˆ¬ç­–ç•¥æ˜¯å¢åŠ æ¨¡å‹çš„å¤§å°ä»¥åŠé¢„è®­ç»ƒçš„æ•°æ®é‡ã€‚</p><p><img src="https://s6.jpg.cm/2021/12/23/LbtDYL.png" alt="LbtDYL.png"></p><p>Unfortunately, training a model, especially a large one, requires a large amount of data. This becomes very costly in terms of time and compute resources. It even translates to environmental impact, as can be seen in the following graph.</p><p><img src="https://s6.jpg.cm/2021/12/23/LbtZRU.png" alt="LbtZRU.png"></p><h5 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h5><p><em>Pretraining</em> is the act of training a model from scratch: the weights are randomly initialized, and the training starts without any prior knowledge.</p><p>é¢„è®­ç»ƒæ˜¯ä»å¤´å¼€å§‹è®­ç»ƒæ¨¡å‹çš„è¡Œä¸ºï¼šæƒé‡éšæœºåˆå§‹åŒ–,è®­ç»ƒåœ¨æ²¡æœ‰ä»»ä½•å…ˆéªŒçŸ¥è¯†çš„æƒ…å†µä¸‹å¼€å§‹.</p><p><img src="https://s6.jpg.cm/2021/12/23/LbNGuO.png" alt="LbNGuO.png"></p><p>This pretraining is usually done on very large amounts of data. Therefore, it requires a very large corpus of data, and training can take up to several weeks.</p><p><em>Fine-tuning</em>, on the other hand, is the training done <strong>after</strong> a model has been pretrained. To perform fine-tuning, you first acquire a pretrained language model, then perform additional training with a dataset specific to your task.</p><p>å¾®è°ƒæ˜¯åœ¨æ¨¡å‹é¢„è®­ç»ƒåè¿›è¡Œçš„è®­ç»ƒã€‚è¦è¿›è¡Œå¾®è°ƒï¼Œé¦–å…ˆéœ€è¦è·å¾—ä¸€ä¸ªé¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ç„¶åä½¿ç”¨ç‰¹å®šäºä»»åŠ¡çš„æ•°æ®é›†è¿›è¡Œé¢å¤–çš„è®­ç»ƒã€‚</p><ul><li>The pretrained model was already trained on a dataset that has some similarities with the fine-tuning dataset. The fine-tuning process is thus able to take advantage of knowledge acquired by the initial model during pretraining (for instance, with NLP problems, the pretrained model will have some kind of statistical understanding of the language you are using for your task).</li><li>Since the pretrained model was already trained on lots of data, the fine-tuning requires way less data to get decent results.</li><li>For the same reason, the amount of time and resources needed to get good results are much lower</li></ul><p>For example, one could leverage a pretrained model trained on the English language and then fine-tune it on an arXiv corpus, resulting in a science/research-based model. The fine-tuning will only require a limited amount of data: the knowledge the pretrained model has acquired is â€œtransferred,â€ hence the term <em>transfer learning</em>.</p><p><img src="https://s6.jpg.cm/2021/12/23/LbNIBw.png" alt="LbNIBw.png"></p><p>Fine-tuning a model therefore has lower time, data, financial, and environmental costs. It is also quicker and easier to iterate over different fine-tuning schemes, as the training is less constraining than a full pretraining.</p><p>å¾®è°ƒæ¨¡å‹å…·æœ‰æ›´ä½çš„æ—¶é—´,æ•°æ®,ç»æµå’Œç¯å¢ƒæˆæœ¬ã€‚è¿­ä»£ä¸åŒçš„å¾®è°ƒæ–¹æ¡ˆä¹Ÿæ›´å¿«æ›´å®¹æ˜“ï¼Œå› ä¸ºè®­ç»ƒæ¯”å®Œå…¨é¢„è®­ç»ƒçš„çº¦æŸæ›´å°‘ã€‚</p><p>This process will also achieve better results than training from scratch (unless you have lots of data), which is why you should always try to leverage a pretrained model â€” one as close as possible to the task you have at hand â€” and fine-tune it.</p><h5 id="General-Transformer-Architecture"><a href="#General-Transformer-Architecture" class="headerlink" title="General Transformer Architecture"></a>General Transformer Architecture</h5><p><img src="https://s6.jpg.cm/2021/12/23/LbNLO8.png" alt="LbNLO8.png"></p><p>The transformer is based on the attention mechanism.</p><p><img src="https://s6.jpg.cm/2021/12/23/LbNR8i.png" alt="LbNR8i.png"></p><p>The combination of the two parts is known as an encoder-decoder or a sequence-to-sequence transformer.</p><p>The model is primarily composed of two blocks:</p><ul><li><strong>Encoder (left)</strong>: The encoder receives an input and builds a representation of it (its features). This means that the model is optimized to acquire understanding from the input.</li></ul><p>ç¼–ç å™¨æ¥å—è¾“å…¥å¹¶æ„å»ºå®ƒçš„è¡¨ç¤º(å…¶ç‰¹å¾)ï¼Œè¿™æ„å‘³ç€æ¨¡å‹ç»è¿‡ä¼˜åŒ–ä»¥ä»è¾“å…¥ä¸­è·å–ç†è§£ã€‚</p><ul><li><strong>Decoder (right)</strong>: The decoder uses the encoderâ€™s representation (features) along with other inputs to generate a target sequence. This means that the model is optimized for generating outputs.</li></ul><p>è§£ç å™¨ä½¿ç”¨ç¼–ç å™¨çš„è¡¨ç¤º(ç‰¹å¾)å’Œå…¶ä»–è¾“å…¥ç”Ÿæˆç›®æ ‡åºåˆ—ï¼Œè¿™æ„å‘³ç€æ¨¡å‹é’ˆå¯¹ç”Ÿæˆè¾“å‡ºè¿›è¡Œä¼˜åŒ–ã€‚</p><p>Each of these parts can be used independently, depending on the task:</p><ul><li><p><strong>Encoder-only models</strong>: Good for tasks that require understanding of the input, such as <strong>sentence classification and named entity recognition.</strong></p><p>é€‚ç”¨äº<strong>éœ€è¦ç†è§£è¾“å…¥çš„ä»»åŠ¡ï¼Œä¾‹å¦‚å¥å­åˆ†ç±»å’Œå‘½åå®ä½“è¯†åˆ«ã€‚</strong></p></li><li><p><strong>Decoder-only models</strong>: Good for generative tasks such as <strong>text generation</strong>.</p><p>é€‚ç”¨äº<strong>ç”Ÿæˆä»»åŠ¡ï¼Œä¾‹å¦‚æ–‡æœ¬ç”Ÿæˆ</strong></p></li><li><p><strong>Encoder-decoder models</strong> or <strong>sequence-to-sequence models</strong>: Good for generative tasks that require an input, such as <strong>translation or summarization</strong>.</p><p>é€‚ç”¨äº<strong>éœ€è¦è¾“å…¥çš„ç”Ÿæˆä»»åŠ¡ï¼Œä¾‹å¦‚ç¿»è¯‘æˆ–è€…æ‘˜è¦ã€‚</strong> </p></li></ul><h5 id="Atention-layers"><a href="#Atention-layers" class="headerlink" title="Atention layers"></a>Atention layers</h5><p>A key feature of Transformer models is that they are built with special layers called <em>attention layers</em>. In fact, the title of the paper introducing the Transformer architecture was <a href="https://arxiv.org/abs/1706.03762">â€œAttention Is All You Needâ€</a>! We will explore the details of attention layers later in the course; for now, all you need to know is that this layer will tell the model to pay specific attention to certain words in the sentence you passed it (and more or less ignore the others) when dealing with the representation of each word.</p><p>Transformeræ¨¡å‹çš„å…³é”®ç‚¹å°±æ˜¯ä»–ä»¬ç”±ç§°ä¸ºæ³¨æ„åŠ›å±‚çš„ç‰¹æ®Šå±‚æ„å»ºè€Œæˆã€‚äº‹å®ä¸Šï¼Œæå‡ºTransformeræ¶æ„çš„è®ºæ–‡æ˜¯â€Attention is all your needâ€ã€‚åé¢ä¼šè¯¦ç»†æ¢ç©¶Attenton layerçš„ç»†èŠ‚ã€‚</p><p>To put this into context, consider the task of translating text from English to French. Given the input â€œYou like this courseâ€, a translation model will need to also attend to the adjacent word â€œYouâ€ to get the proper translation for the word â€œlikeâ€, because in French the verb â€œlikeâ€ is conjugated differently depending on the subject. The rest of the sentence, however, is not useful for the translation of that word. In the same vein, when translating â€œthisâ€ the model will also need to pay attention to the word â€œcourseâ€, because â€œthisâ€ translates differently depending on whether the associated noun is masculine or feminine. Again, the other words in the sentence will not matter for the translation of â€œthisâ€. With more complex sentences (and more complex grammar rules), the model would need to pay special attention to words that might appear farther away in the sentence to properly translate each word.</p><h5 id="The-original-architecture"><a href="#The-original-architecture" class="headerlink" title="The original architecture"></a>The original architecture</h5><p>The Transformer architecture was originally designed for translation. During training, the encoder receives inputs (sentences) in a certain language, while the decoder receives the same sentences in the desired target language</p><p>Transformeræ¶æ„æœ€åˆæ˜¯ä¸ºäº†ç¿»è¯‘è€Œè®¾è®¡çš„,åœ¨è®­ç»ƒæœŸé—´ï¼Œç¼–ç å™¨æ¥å—æŸç§è¯­è¨€çš„è¾“å…¥å¥å­ï¼Œè€Œè§£ç å™¨æ¥å—æ‰€éœ€ç›®æ ‡è¯­è¨€çš„ç›¸åŒå¥å­ã€‚</p><ul><li><p>In the encoder, the attention layers can use all the words in a sentence (since, as we just saw, the translation of a given word can be dependent on what is after as well as before it in the sentence).</p><p>åœ¨ç¼–ç å™¨ä¸­ï¼Œæ³¨æ„åŠ›å±‚å¯ä»¥ä½¿ç”¨å¥å­ä¸­çš„æ‰€æœ‰å•è¯(ç»™å®šå•è¯çš„ç¿»è¯‘å¯ä»¥ä¾èµ–äºå¥å­ä¸­å®ƒä¹‹åå’Œä¹‹å‰çš„å†…å®¹)</p></li><li><p>The decoder, however, works sequentially and can only pay attention to the words in the sentence that it has already translated (so, only the words before the word currently being generated). For example, when we have predicted the first three words of the translated target, we give them to the decoder which then uses all the inputs of the encoder to try to predict the fourth word.</p><p>è§£ç å™¨æ˜¯æŒ‰ç…§é¡ºåºå·¥ä½œï¼Œåªèƒ½å…³æ³¨å·²ç»ç¿»è¯‘çš„å¥å­ä¸­å•è¯ã€‚æ¯”å¦‚ï¼Œå½“æˆ‘ä»¬é¢„æµ‹ç¿»è¯‘ç›®æ ‡ä¸­çš„å‰ä¸‰ä¸ªå•è¯æ—¶ï¼Œæˆ‘ä»¬å°†ä»–ä»¬æä¾›ç»™è§£ç å™¨ç„¶åè§£ç å™¨ä½¿ç”¨ç¼–ç å™¨çš„æ‰€æœ‰è¾“å…¥å°è¯•é¢„æµ‹ç¬¬å››ä¸ªå•è¯ã€‚</p></li></ul><p>Note that the the first attention layer in a decoder block pays attention to all (past) inputs to the decoder, but the second attention layer uses the output of the encoder. It can thus access the whole input sentence to best predict the current word. This is very useful as different languages can have grammatical rules that put the words in different orders, or some context provided later in the sentence may be helpful to determine the best translation of a given word.</p><p>æ³¨æ„ï¼Œè§£ç å™¨çš„ç¬¬ä¸€ä¸ªæ³¨æ„å±‚å…³æ³¨è§£ç å™¨æ‰€æœ‰è¿‡å»çš„è¾“å…¥ï¼Œä½†ç¬¬äºŒä¸ªæ³¨æ„å±‚ä½¿ç”¨ç¼–ç å™¨çš„è¾“å‡ºã€‚å› æ­¤ï¼Œå®ƒå¯ä»¥è®¿é—®æ•´ä¸ªè¾“å…¥å¥å­ä»¥æœ€å¥½çš„é¢„æµ‹å½“å‰çš„å•è¯ï¼Œè¿™æ˜¯å¾ˆæœ‰ç”¨çš„å› ä¸ºä¸åŒçš„è¯­è¨€æœ‰ä¸åŒçš„è¯­æ³•è§„åˆ™ï¼ŒæŠŠå•è¯æ”¾åœ¨ä¸åŒçš„é¡ºåºæˆ–è€…å¥å­åé¢æä¾›çš„ä¸Šä¸‹æ–‡å¯èƒ½æœ‰åŠ©äºç¡®å®šä¸€ä¸ªç»™å®šå•è¯çš„æœ€ä½³ç¿»è¯‘ã€‚</p><p>The <em>attention mask</em> can also be used in the encoder/decoder to prevent the model from paying attention to some special words â€” for instance, the special padding word used to make all the inputs the same length when batching together sentences.</p><p><strong>attention mask</strong>ä¹Ÿå¯ä»¥è¿ç”¨åœ¨ç¼–ç /è§£ç ä¸­ï¼Œé˜²æ­¢æ¨¡å‹æ³¨æ„åˆ°æŸäº›ç‰¹æ®Šçš„å•è¯</p><h5 id="Architecture-amp-amp-Checkpoints"><a href="#Architecture-amp-amp-Checkpoints" class="headerlink" title="Architecture &amp;&amp; Checkpoints"></a>Architecture &amp;&amp; Checkpoints</h5><p>As we dive into Transformer models in this course, youâ€™ll see mentions of <em>architectures</em> and <em>checkpoints</em> as well as <em>models</em>. These terms all have slightly different meanings:</p><ul><li><strong>Architecture</strong>: This is the skeleton of the model â€” the definition of each layer and each operation that happens within the model.</li><li><strong>Checkpoints</strong>: These are the weights that will be loaded in a given architecture.</li><li><strong>Model</strong>: This is an umbrella term that isnâ€™t as precise as â€œarchitectureâ€ or â€œcheckpointâ€: it can mean both. This course will specify <em>architecture</em> or <em>checkpoint</em> when it matters to reduce ambiguity.</li></ul><p>For example, BERT is an architecture while <code>bert-base-cased</code>, a set of weights trained by the Google team for the first release of BERT, is a checkpoint. However, one can say â€œthe BERT modelâ€ and â€œthe <code>bert-base-cased</code> model.â€</p><h4 id="Encoder-models"><a href="#Encoder-models" class="headerlink" title="Encoder models"></a>Encoder models</h4><p>Encoder models use only the encoder of a Transformer model. At each stage, the attention layers can access all the words in the initial sentence. These models are often characterized as having â€œbi-directionalâ€ attention, and are often called <em>auto-encoding models</em>.</p><p>Encoder modelåªä½¿ç”¨the transformer modelçš„encoderéƒ¨åˆ†ã€‚åœ¨æ¯ä¸ªé˜¶æ®µï¼Œattention layerséƒ½å¯ä»¥è®¿é—®åˆå§‹å¥å­çš„æ‰€æœ‰è¯ã€‚è¿™äº›æ¨¡å‹åŒvè¡Œè¢«æè¿°ä¸ºå…·æœ‰â€bi-directionalâ€ï¼Œé€šå¸¸è¢«ç§°ä¸ºè‡ªç¼–ç æ¨¡å‹ã€‚</p><p>The pretraining of these models usually revolves around somehow corrupting a given sentence (for instance, by masking random words in it) and tasking the model with finding or reconstructing the initial sentence.</p><p>è¿™äº›æ¨¡å‹çš„é¢„è®­ç»ƒé€šå¸¸å›´ç»•æŸç§æ–¹å¼ç ´åç»™å®šçš„å¥å­(ä¾‹å¦‚ï¼Œé€šè¿‡å±è”½å…¶ä¸­çš„éšæœºè¯)ï¼Œå¹¶è®©æ¨¡å‹æŸ¥æ‰¾æˆ–é‡æ„åˆå§‹å¥å­ã€‚</p><p>Encoder models are best suited for tasks requiring an understanding of the full sentence, such as sentence classification, named entity recognition (and more generally word classification), and extractive question answering.</p><p>ç¼–ç å™¨æ¨¡å‹æœ€é€‚åˆéœ€è¦ç†è§£å®Œæ•´å¥å­çš„ä»»åŠ¡ï¼Œä¾‹å¦‚sentence classification,ner(å‘½åå®ä½“è¯†åˆ«)(ä»¥åŠæ›´åŠ ä¸€èˆ¬çš„å•è¯åˆ†ç±»)å’Œeqaæå–å¼å›ç­”.</p><h5 id="Representatives-of-this-family-of-models-include"><a href="#Representatives-of-this-family-of-models-include" class="headerlink" title="Representatives of this family of models include:"></a>Representatives of this family of models include:</h5><ul><li><a href="https://huggingface.co/transformers/model_doc/albert.html">ALBERT</a></li><li><a href="https://huggingface.co/transformers/model_doc/bert.html">BERT</a></li><li><a href="https://huggingface.co/transformers/model_doc/distilbert.html">DistilBERT</a></li><li><a href="https://huggingface.co/transformers/model_doc/electra.html">ELECTRA</a></li><li><a href="https://huggingface.co/transformers/model_doc/roberta.html">RoBERTa</a></li></ul><h4 id="Decoder-models"><a href="#Decoder-models" class="headerlink" title="Decoder models"></a>Decoder models</h4><p>Decoder models use only the decoder of a Transformer model. At each stage, for a given word the attention layers can only access the words positioned before it in the sentence. These models are often called <em>auto-regressive models</em>.</p><p>è§£ç å™¨æ¨¡å‹ä»…ä½¿ç”¨Transformeræ¨¡å‹çš„è§£ç å™¨ã€‚åœ¨æ¯ä¸ªé˜¶æ®µï¼Œå¯¹äºç»™å®šçš„å•è¯ï¼Œæ³¨æ„åŠ›å±‚åªèƒ½è®¿é—®ä½äºå¥å­ä¹‹å‰çš„å•è¯ã€‚è¿™äº›æ¨¡å‹é€šå¸¸è¢«ç§°ä¸ºè‡ªå›å½’æ¨¡å‹ã€‚</p><p>The pretraining of decoder models usually revolves around predicting the next word in the sentence.</p><p>è§£ç å™¨æ¨¡å‹çš„é¢„è®­ç»ƒé€šå¸¸å›´ç»•é¢„æµ‹å¥å­ä¸­çš„ä¸‹ä¸€ä¸ªå•è¯ã€‚</p><p>These models are best suited for tasks involving text generation.</p><p>è¿™äº›æ¨¡å‹æœ€é€‚åˆè®¾è®¡æ–‡æœ¬ç”Ÿæˆçš„ä»»åŠ¡.</p><h5 id="Representatives-of-this-family-of-models-include-1"><a href="#Representatives-of-this-family-of-models-include-1" class="headerlink" title="Representatives of this family of models include:"></a>Representatives of this family of models include:</h5><ul><li><a href="https://huggingface.co/transformers/model_doc/ctrl.html">CTRL</a></li><li><a href="https://huggingface.co/transformers/model_doc/gpt.html">GPT</a></li><li><a href="https://huggingface.co/transformers/model_doc/gpt2.html">GPT-2</a></li><li><a href="https://huggingface.co/transformers/model_doc/transformerxl.html">Transformer XL</a></li></ul><h4 id="Seq-to-Seq-models"><a href="#Seq-to-Seq-models" class="headerlink" title="Seq-to-Seq models"></a>Seq-to-Seq models</h4><p>Encoder-decoder models (also called <em>sequence-to-sequence models</em>) use both parts of the Transformer architecture. At each stage, the attention layers of the encoder can access all the words in the initial sentence, whereas the attention layers of the decoder can only access the words positioned before a given word in the input.</p><p>encoder-decoder models(ä¹Ÿç§°ä¸ºSeqtoSeq models)ä½¿ç”¨Transformerä½“ç³»ç»“æ„çš„æ‰€æœ‰éƒ¨åˆ†ã€‚åœ¨æ¯ä¸ªé˜¶æ®µï¼Œç¼–ç å™¨çš„æ³¨æ„åŠ›æœºåˆ¶å¯ä»¥è®¿é—®åˆå§‹å¥å­çš„æ¯ä¸ªå•è¯,è€Œè§£ç å™¨çš„æ³¨æ„åŠ›å±‚åªèƒ½è®¿é—®è¾“å…¥ä¸­æŸä¸ªå•è¯å‰é¢çš„å•è¯ã€‚</p><p>The pretraining of these models can be done using the objectives of encoder or decoder models, but usually involves something a bit more complex. For instance, <a href="https://huggingface.co/t5-base">T5</a> is pretrained by replacing random spans of text (that can contain several words) with a single mask special word, and the objective is then to predict the text that this mask word replaces.</p><p>è¿™äº›æ¨¡å‹çš„é¢„è®­ç»ƒå¯ä»¥ä½¿ç”¨ç¼–ç å™¨/è§£ç å™¨æ¨¡å‹çš„ç›®æ ‡æ¥å®Œæˆ,ä½†é€šå¸¸æ¶‰åŠä¸€äº›æ›´å¤æ‚çš„ä¸œè¥¿ã€‚ä¾‹å¦‚ï¼ŒT5æ˜¯é€šè¿‡ä¸€ä¸ªæ©ç ç‰¹æ®Šè¯å–ä»£éšæœºæ–‡æœ¬è·¨åº¦(å¯ä»¥åŒ…å«å¤šä¸ªå•è¯)è¿›è¡Œé¢„è®­ç»ƒçš„ï¼Œç„¶åç›®æ ‡æ˜¯é¢„æµ‹è¿™ä¸ªæ©ç è¯å–ä»£çš„æ–‡æœ¬ã€‚</p><p>Sequence-to-sequence models are best suited for tasks revolving around generating new sentences depending on a given input, such as summarization, translation, or generative question answering.</p><p>Seq-to-Seqæ¨¡å‹æœ€é€‚åˆæ ¹æ®ç»™å®šçš„è¾“å…¥ç”Ÿæˆæ–°å¥å­çš„ä»»åŠ¡ï¼Œæ¯”å¦‚æ‘˜è¦ï¼Œç¿»è¯‘æˆ–è€…ç”Ÿæˆå¼é—®é¢˜å›ç­”ã€‚</p><h5 id="Representatives-of-this-family-of-models-include-2"><a href="#Representatives-of-this-family-of-models-include-2" class="headerlink" title="Representatives of this family of models include:"></a>Representatives of this family of models include:</h5><ul><li><a href="https://huggingface.co/transformers/model_doc/bart.html">BART</a></li><li><a href="https://huggingface.co/transformers/model_doc/mbart.html">mBART</a></li><li><a href="https://huggingface.co/transformers/model_doc/marian.html">Marian</a></li><li><a href="https://huggingface.co/transformers/model_doc/t5.html">T5</a></li></ul><h4 id="Bias-and-limitations"><a href="#Bias-and-limitations" class="headerlink" title="Bias and limitations"></a>Bias and limitations</h4><p>If your intent is to use a pretrained model or a fine-tuned version in production, please be aware that, while these models are powerful tools, they come with limitations. The biggest of these is that, to enable pretraining on large amounts of data, researchers often scrape all the content they can find, taking the best as well as the worst of what is available on the internet.</p><p>å¦‚æœæ‰“ç®—åœ¨productionä¸­ä½¿ç”¨ä¸€ä¸ªé¢„å…ˆè®­ç»ƒçš„æ¨¡å‹æˆ–è€…ç»è¿‡å¾®è°ƒçš„ç‰ˆæœ¬ï¼Œè¯·æ³¨æ„ï¼Œå°½ç®¡è¿™äº›æ¨¡å‹æ˜¯æœ€å¼ºå¤§çš„å·¥å…·ä½†æ˜¯ä»–ä»¬ä¹Ÿæœ‰å±€é™æ€§ã€‚å…¶ä¸­æœ€å¤§çš„é—®é¢˜æ˜¯æ˜¯ä¸ºäº†èƒ½å¤Ÿå¯¹å¤§é‡çš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œç ”ç©¶äººå‘˜ç»å¸¸æœé›†ä»–ä»¬èƒ½å¤Ÿæ‰¾åˆ°çš„æ‰€æœ‰å†…å®¹ï¼Œå¹¶ä¸”ä»äº’è”ç½‘ä¸Šå¯è·å¾—çš„ä¿¡æ¯ä¸­æŒ‘é€‰å‡ºæœ€å¥½çš„å’Œæœ€å·®çš„ã€‚</p><p>Exampleï¼š<strong>pipeli    ne:fill-mask model:bert-base-uncased</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipelineunmasker <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"fill-mask"</span><span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"bert-base-uncased"</span><span class="token punctuation">)</span>result <span class="token operator">=</span> unmasker<span class="token punctuation">(</span><span class="token string">"This man works as a [MASK]."</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">[</span>r<span class="token punctuation">[</span><span class="token string">"token_str"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> r <span class="token keyword">in</span> result<span class="token punctuation">]</span><span class="token punctuation">)</span>result <span class="token operator">=</span> unmasker<span class="token punctuation">(</span><span class="token string">"This woman works as a [MASK]."</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">[</span>r<span class="token punctuation">[</span><span class="token string">"token_str"</span><span class="token punctuation">]</span> <span class="token keyword">for</span> r <span class="token keyword">in</span> result<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python"><code class="language-python">Some weights of the model checkpoint at bert<span class="token operator">-</span>base<span class="token operator">-</span>uncased were <span class="token operator">not</span> used when initializing BertForMaskedLM<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'cls.seq_relationship.bias'</span><span class="token punctuation">,</span> <span class="token string">'cls.seq_relationship.weight'</span><span class="token punctuation">]</span><span class="token operator">-</span> This IS expected <span class="token keyword">if</span> you are initializing BertForMaskedLM <span class="token keyword">from</span> the checkpoint of a model trained on another task <span class="token operator">or</span> <span class="token keyword">with</span> another architecture <span class="token punctuation">(</span>e<span class="token punctuation">.</span>g<span class="token punctuation">.</span> initializing a BertForSequenceClassification model <span class="token keyword">from</span> a BertForPreTraining model<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token operator">-</span> This IS NOT expected <span class="token keyword">if</span> you are initializing BertForMaskedLM <span class="token keyword">from</span> the checkpoint of a model that you expect to be exactly identical <span class="token punctuation">(</span>initializing a BertForSequenceClassification model <span class="token keyword">from</span> a BertForSequenceClassification model<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token punctuation">[</span><span class="token string">'carpenter'</span><span class="token punctuation">,</span> <span class="token string">'lawyer'</span><span class="token punctuation">,</span> <span class="token string">'farmer'</span><span class="token punctuation">,</span> <span class="token string">'businessman'</span><span class="token punctuation">,</span> <span class="token string">'doctor'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'nurse'</span><span class="token punctuation">,</span> <span class="token string">'maid'</span><span class="token punctuation">,</span> <span class="token string">'teacher'</span><span class="token punctuation">,</span> <span class="token string">'waitress'</span><span class="token punctuation">,</span> <span class="token string">'prostitute'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>When asked to fill in the missing word in these two sentences, the model gives only one gender-free answer (waiter/waitress). The others are work occupations usually associated with one specific gender â€” and yes, prostitute ended up in the top 5 possibilities the model associates with â€œwomanâ€ and â€œwork.â€ This happens even though BERT is one of the rare Transformer models not built by scraping data from all over the internet, but rather using apparently neutral data (itâ€™s trained on the <a href="https://huggingface.co/datasets/wikipedia">English Wikipedia</a> and <a href="https://huggingface.co/datasets/bookcorpus">BookCorpus</a> datasets).</p><p>å¯ä»¥é€šè¿‡ä¾‹å­å‘ç°,å½“éœ€è¦å¡«å†™è¿™ä¸¤å¥è¯ä¸­è¢«å±è”½çš„å•è¯æ—¶,æ¨¡å‹åªç»™å‡ºäº†ä¸€ä¸ªä¸åˆ†æ€§åˆ«çš„ç­”æ¡ˆå¹¶æŒ‰ç…§â€˜manâ€™å’Œâ€˜workâ€™ç›¸å…³è”ï¼Œâ€˜womanâ€™å’Œâ€˜workâ€™ç›¸å…³è”å¯èƒ½æ€§æœ€å¤§çš„å‰5ç§å¯èƒ½æ€§ä¸­ã€‚</p><p>When you use these tools, you therefore need to keep in the back of your mind that the original model you are using could very easily generate sexist, racist, or homophobic content. Fine-tuning the model on your data wonâ€™t make this intrinsic bias disappear.</p><h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><p>In this chapter, you saw how to approach different NLP tasks using the high-level <code>pipeline()</code> function from ğŸ¤— Transformers. You also saw how to search for and use models in the Hub, as well as how to use the Inference API to test the models directly in your browser.</p><p>We discussed how Transformer models work at a high level, and talked about the importance of transfer learning and fine-tuning. A key aspect is that you can use the full architecture or only the encoder or decoder, depending on what kind of task you aim to solve. The following table summarizes this:</p><p>å…³é”®ç‚¹åœ¨äºï¼Œå¯ä»¥ä½¿ç”¨å®Œæ•´çš„transformeræ¶æ„ä¹Ÿå¯ä»¥ä½¿ç”¨ç¼–ç å™¨å’Œè§£ç å™¨ï¼Œå…·ä½“å´å†³äºä½ è¦è§£å†³çš„taskç‰¹ç‚¹ï¼Œä¸‹è¡¨è¿›è¡Œç®€å•æ€»ç»“ï¼š</p><table><thead><tr><th>Model</th><th>Examples</th><th>Tasks</th></tr></thead><tbody><tr><td>Encoder</td><td>ALBERT, BERT, DistilBERT, ELECTRA, RoBERTa</td><td>Sentence classification, named entity recognition, extractive question answering</td></tr><tr><td>Decoder</td><td>CTRL, GPT, GPT-2, Transformer XL</td><td>Text generation</td></tr><tr><td>Encoder-decoder</td><td>BART, T5, Marian, mBART</td><td>Summarization, translation, generative question answering</td></tr></tbody></table><h4 id="Using-Transformers"><a href="#Using-Transformers" class="headerlink" title="Using Transformers"></a>Using Transformers</h4><ul><li><p><strong>Ease of use</strong>: Downloading, loading, and using a state-of-the-art NLP model for inference can be done in just two lines of code.</p><p>ä¸‹è½½ï¼ŒåŠ è½½å’Œä½¿ç”¨SOTAçš„NLPæ¨¡å‹è¿›è¡Œæ¨ç†å¾ˆç®€å•çš„APIè°ƒç”¨å³å¯</p></li><li><p><strong>Flexibility</strong>: At their core, all models are simple PyTorch <code>nn.Module</code> or TensorFlow <code>tf.keras.Model</code> classes and can be handled like any other models in their respective machine learning (ML) frameworks.</p><p>å…¶å®æ‰€æœ‰æ¨¡å‹éƒ½æ˜¯Pytorch <strong>nn.module</strong>å’ŒTensorflow <strong>tf.keras.model</strong>ç±»ï¼Œå¹¶ä¸”å¯ä»¥åƒå„è‡ªæœºå™¨å­¦ä¹ æ¡†æ¶çš„ä»»ä½•å…¶ä»–æ¨¡å‹ä¸€æ ·è¿›è¡Œå¤„ç†ã€‚</p></li><li><p><strong>Simplicity</strong>: Hardly any abstractions are made across the library. The â€œAll in one fileâ€ is a core concept: a modelâ€™s forward pass is entirely defined in a single file, so that the code itself is understandable and hackable.</p></li></ul><p>This last feature makes ğŸ¤— Transformers quite different from other ML libraries. The models are not built on modules that are shared across files; instead, each model has its own layers. In addition to making the models more approachable and understandable, this allows you to easily experiment on one model without affecting others.</p><p>è¿™äº›æ¨¡å‹ä¸æ˜¯å»ºç«‹åœ¨è·¨æ–‡ä»¶å…±äº«çš„æ¨¡å—ä¸Š.</p><p>This chapter will begin with an end-to-end example where we use a model and a tokenizer together to replicate the <code>pipeline()</code> function introduced in <a href="https://huggingface.co/course/chapter1">Chapter 1</a>. Next, weâ€™ll discuss the model API: weâ€™ll dive into the model and configuration classes, and show you how to load a model and how it processes numerical inputs to output predictions.</p><p>æ¥ä¸‹æ¥ä»ä¸€ä¸ªç«¯åˆ°ç«¯çš„ä¾‹å­å¼€å§‹ï¼Œä½¿ç”¨ä¸€ä¸ªæ¨¡å‹å’Œåˆ†è¯å™¨æ¥æ·±å…¥ç†è§£pipelineå‡½æ•°ï¼›ç¨åï¼Œæ·±å…¥è®¨è®ºæ¨¡å‹APIï¼šæ·±å…¥ç ”ç©¶æ¨¡å‹å’Œé…ç½®ç±»ï¼Œå¹¶å±•å¼€å¦‚å¯åŠ è½½æ¨¡å‹ä»¥åŠå¦‚ä½•å¤„ç†æ•°å€¼è¾“å…¥ä»¥ä¾¿è¾“å‡ºé¢„æµ‹ã€‚</p><p>Theneâ€™ll look at the tokenizer API, which is the other main component of the <code>pipeline()</code> function. Tokenizers take care of the first and last processing steps, handling the conversion from text to numerical inputs for the neural network, and the conversion back to text when it is needed. Finally, weâ€™ll show you how to handle sending multiple sentences through a model in a prepared batch, then wrap it all up with a closer look at the high-level <code>tokenizer()</code> function.    </p><h5 id="Behind-the-pipeline"><a href="#Behind-the-pipeline" class="headerlink" title="Behind the pipeline"></a>Behind the pipeline</h5><p>take a look at the example:</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipelineclassifier <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"sentiment-analysis"</span><span class="token punctuation">)</span>classifier<span class="token punctuation">(</span>    <span class="token punctuation">[</span>        <span class="token string">"I've been waiting for a HuggingFace course my whole life."</span><span class="token punctuation">,</span>        <span class="token string">"I hate this so much!"</span><span class="token punctuation">,</span>    <span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>and obtained:</p><pre class="line-numbers language-python"><code class="language-python"><span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token string">'POSITIVE'</span><span class="token punctuation">,</span> <span class="token string">'score'</span><span class="token punctuation">:</span> <span class="token number">0.9598047137260437</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token string">'label'</span><span class="token punctuation">:</span> <span class="token string">'NEGATIVE'</span><span class="token punctuation">,</span> <span class="token string">'score'</span><span class="token punctuation">:</span> <span class="token number">0.9994558095932007</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>As we can see,this pipeline groups together three steps: preprocessing, passing the inputs through the model, and postprocessing:</p><p><img src="https://s6.jpg.cm/2021/12/23/Lbo6gW.png" alt="Lbo6gW.png"></p><h6 id="Preprocessing-with-a-tokenizer"><a href="#Preprocessing-with-a-tokenizer" class="headerlink" title="Preprocessing with a tokenizer"></a>Preprocessing with a tokenizer</h6><p>Like other neural networks, Transformer models canâ€™t process raw text directly, so the first step of our pipeline is to convert the text inputs into numbers that the model can make sense of. To do this we use a <em>tokenizer</em>, which will be responsible for:</p><ul><li>Splitting the input into words, subwords, or symbols (like punctuation) that are called <em>tokens</em></li><li>Mapping each token to an integer</li><li>Adding additional inputs that may be useful to the model</li></ul><p>All this preprocessing needs to be done in exactly the same way as when the model was pretrained, so we first need to download that information from the <a href="https://huggingface.co/models">Model Hub</a>. To do this, we use the <code>AutoTokenizer</code> class and its <code>from_pretrained()</code> method. Using the checkpoint name of our model, it will automatically fetch the data associated with the modelâ€™s tokenizer and cache it (so itâ€™s only downloaded the first time you run the code below).</p><p>â€‹    </p>]]></content>
      
      
      <categories>
          
          <category> dialogue </category>
          
      </categories>
      
      
        <tags>
            
            <tag> transformer </tag>
            
            <tag> pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dialogue_system</title>
      <link href="/year/11/21/Dialogue-system/"/>
      <url>/year/11/21/Dialogue-system/</url>
      
        <content type="html"><![CDATA[<p>NLPé¢†åŸŸæ¯”è¾ƒä¼ ç»Ÿå’Œæ ¸å¿ƒçš„taskæœ‰å¾ˆå¤š</p><p>ä¸‹é¢å…ˆä»‹ç»Chinese NLPçš„åŸºæœ¬ä»»åŠ¡:</p><h4 id="Co-reference-Resolution"><a href="#Co-reference-Resolution" class="headerlink" title="Co-reference Resolution"></a>Co-reference Resolution</h4><p>Background</p><hr><p>â€‹    Co-reference identifies pieces of text and links them with other pieces of text that refer to the same thing. Sometimes pieces of text have zero-length, where an overt pronoun or noun is omitted.</p><p>Example</p><hr><p>input:</p><pre><code>æˆ‘çš„å§å§ç»™æˆ‘å¥¹çš„ç‹—ã€‚å¾ˆå–œæ¬¢.</code></pre><p>output</p><pre><code>[æˆ‘]0çš„[å§å§]1ç»™[æˆ‘]0[å¥¹]1çš„[ç‹—]2ã€‚[]0å¾ˆå–œæ¬¢[]2.</code></pre><h6 id="Standard-Metrics"><a href="#Standard-Metrics" class="headerlink" title="Standard Metrics"></a>Standard Metrics</h6><p>Average of F1-scores returned by these three precison/recall metrics:</p><ul><li>MUC</li><li>B-cubed</li><li>Entity-based CEAF</li><li>BLANC</li><li>Link-Based Entity-Aware metric(LEA)</li></ul><h4 id="Sentiment-Analysis"><a href="#Sentiment-Analysis" class="headerlink" title="Sentiment Analysis"></a>Sentiment Analysis</h4><p>Background</p><hr><p>Sentiment Analysis detects identifies and extracts subjective information from text.<br>æƒ…æ„Ÿåˆ†ææ£€æµ‹è¯†åˆ«å¹¶ä»æ–‡æœ¬ä¸­æå–ä¸»è§‚ä¿¡æ¯.</p><hr><p>Example</p><hr><p>inputs:</p><pre><code>æ€»çš„æ„Ÿè§‰è¿™å°æœºå™¨è¿˜ä¸é”™ï¼Œå®ç”¨çš„æœ‰ï¼šé˜´é˜³å†æ˜¾ç¤ºï¼Œæ—¶é—´ä¸æ—¥æœŸå¿«é€Ÿè½¬æ¢, è®°äº‹æœ¬ç­‰ã€‚</code></pre><p>Output:</p><pre><code>Positive</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Faster-RCNN</title>
      <link href="/year/11/06/Faster%20R-CNN/"/>
      <url>/year/11/06/Faster%20R-CNN/</url>
      
        <content type="html"><![CDATA[<h5 id="Perface"><a href="#Perface" class="headerlink" title="Perface:"></a>Perface:</h5><p>åœ¨ğŸ¦ŒåŒå­¦çš„æ„ŸæŸ“ä¸‹ï¼Œç¬”è€…æœ€è¿‘ä¹Ÿå­¦ä¹ äº†ç›®æ ‡æ£€æµ‹æ–¹å‘çš„ç›¸å…³å†…å®¹ï¼Œçœ‹çš„ç¬¬ä¸€ç¯‡è®ºæ–‡æ˜¯<a href="https://arxiv.org/abs/1504.08083#">Faster R-CNNï¼šTowards Rel-Time Objection Dection with Region Proposal Networks</a>ï¼Œé‡Œé¢æ¶‰åŠåˆ°å¾ˆå¤šå‰ç½®æ¨¡å‹éœ€è¦äº†è§£ç»“æ„ï¼Œåœ¨è¿™é‡Œåˆ†äº«ä¸€ç‚¹ç¬”è®°</p><h5 id="ç›®æ ‡æ£€æµ‹èƒŒæ™¯"><a href="#ç›®æ ‡æ£€æµ‹èƒŒæ™¯" class="headerlink" title="ç›®æ ‡æ£€æµ‹èƒŒæ™¯"></a>ç›®æ ‡æ£€æµ‹èƒŒæ™¯</h5><p>ç›®æ ‡æ£€æµ‹æ˜¯å¾ˆå¤šè®¡ç®—æœºè§†è§‰äººç‰©çš„åŸºç¡€ï¼Œç›®å‰ä¸»æµçš„ç›®æ ‡æ£€æµ‹çš„ç®—æ³•ä¸»è¦åŸºäºæ·±åº¦å­¦ä¹ æ¨¡å‹å¯ä»¥åˆ†ä¸ºä¸¤å¤§ç±»</p><ol><li>one-stageæ£€æµ‹ç®—æ³•,è¿™ç§ç®—æ³•ç›´æ¥äº§ç”Ÿç‰©ä½“çš„ç±»åˆ«æ¦‚ç‡å’Œåæ ‡ä½ç½®,ä¸éœ€è¦ç›´æ¥äº§ç”Ÿå€™é€‰åŒºåŸŸ.æ¯”å¦‚è¯´YOLOå’ŒSSD</li><li>two-stageæ£€æµ‹ç®—æ³•,è¿™æ˜¯å°†æ£€æµ‹é—®é¢˜åˆ’åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µ,é¦–å…ˆæ˜¯äº§ç”Ÿå€™é€‰åŒºåŸŸ,ç„¶åå¯¹å€™é€‰åŒºåŸŸåˆ†ç±»;å…¸å‹ç®—æ³•æ˜¯R-CNNç³»åˆ—,faster rcnnå°±æ˜¯åŸºäº<strong>region proposal</strong>(å€™é€‰åŒºåŸŸ)</li></ol><h5 id="backbone-network"><a href="#backbone-network" class="headerlink" title="backbone network"></a>backbone network</h5><p><strong>Faster R-CNN</strong>ä½¿ç”¨çš„ä¸»å¹²ç½‘ç»œæ˜¯VGG-16,åœ¨è®ºæ–‡ä¸­ç§°ä¸»å¹²ç½‘ç»œæ—¶<strong>backbone network</strong>,ä¸»å¹²ç½‘ç»œå°±æ˜¯ç”¨æ¥<strong>feature extraction</strong>,å½“ç„¶è¿™ä¸ªä¸æ˜¯ä¸€æˆä¸å˜çš„,å¯ä»¥æ›¿æ¢,æ¯”å¦‚ç°åœ¨ä¹ŸåŒæ ·æµè¡Œä½¿ç”¨<strong>Resnet</strong>,å†å¦‚<strong>CornerNet</strong>ç®—æ³•ä¸­ä½¿ç”¨çš„backbone networkæ˜¯Hourglass Network.<br>å…³äºVGG-16å¯ä»¥å‚è€ƒ<a href="http://zh.gluon.ai/chapter_convolutional-neural-networks/vgg.html">VGGä»‹ç»</a>,16çš„å«ä¹‰æ˜¯å«æœ‰å‚æ•°æœ‰16å±‚,åˆ†åˆ«æ˜¯13ä¸ªå·ç§¯å±‚+3ä¸ªå…¨è¿æ¥å±‚</p><p>å›¾æ¥è‡ªç½‘ç»œ</p><h5 id="Faster-R-CNNç®—æ³•æ­¥éª¤"><a href="#Faster-R-CNNç®—æ³•æ­¥éª¤" class="headerlink" title="Faster R-CNNç®—æ³•æ­¥éª¤"></a>Faster R-CNNç®—æ³•æ­¥éª¤</h5><p>è¿™éƒ¨åˆ†æ˜¯ä¸ºäº†ç†è§£Faster R-CNN,æ€»ä½“æè¿°ä¸‹ç®—æ³•çš„æ•´ä¸ªè¿‡ç¨‹ä»¥ä¾¿åæœŸåšç»†èŠ‚åˆ†æ</p><p><img src="https://s6.jpg.cm/2021/12/23/LbJi0t.png" alt="LbJi0t.png"></p><p>å¤§è‡´æµç¨‹æ˜¯:å°†æ•´å¼ å›¾ç‰‡è¾“å…¥CNNå±‚,å¾—åˆ°feature map,å·ç§¯ç‰¹å¾è¾“å…¥åˆ°**RPN(Region Proposal Network)**å¾—åˆ°å€™é€‰æ¡†çš„ç‰¹å¾ä¿¡æ¯,å¯¹å€™é€‰æ¡†ä¸­æå–çš„ç‰¹å¾ä½¿ç”¨åˆ†ç±»å™¨åˆ¤åˆ«æ˜¯å¦å±äºä¸€ä¸ªç‰¹å®šç±»åˆ«,å¯¹äºå±äºæŸä¸€ç‰¹å¾çš„å€™é€‰æ¡†ç”¨å›å½’å™¨è¿›ä¸€æ­¥è°ƒæ•´å…¶ä½ç½®.</p><p>Faster R-CNNå¯ä»¥çœ‹ä½œRPNå’ŒFast R-CNNæ¨¡å‹çš„ç»“åˆ,å³Faster R-CNN = RPN + Fast R-CNN.ä¸‹é¢ä»‹ç»æ¯ä¸€æ­¥éª¤çš„è¾“å…¥è¾“å‡ºçš„ç»†èŠ‚.</p><ul><li>é¦–å…ˆé€šè¿‡é¢„è®­ç»ƒæ¨¡å‹è®­ç»ƒå¾—åˆ°Conv layers(è¿™ä¸ªconv layerå®é™…ä¸Šå°±æ˜¯VGG-16)èƒ½å¤Ÿæ¥æ”¶æ•´å¼ å›¾ç‰‡å¹¶æå–ç‰¹å¾å›¾feature maps,è¿™ä¸ªfeature mapæ˜¯åœ¨convå±‚ä¹‹åè·å¾—çš„ç‰¹å¾.</li><li>feature mapè¢«å…±äº«ä¹‹åç”¨äºåç»­çš„RPNå’ŒRolæ± åŒ–å±‚<ul><li>BPNå±‚:BPNç½‘ç»œç”¨äºç”Ÿæˆregion proposals.è¯¥å±‚é€šè¿‡softmaxåˆ¤æ–­anchorså±äºå‰æ™¯(foreground)è¿˜æ˜¯èƒŒæ™¯(background),å†åˆ©ç”¨è¾¹æ¡†å›å½’ä¿®æ­£anchors,è·å¾—ç²¾ç¡®çš„proposals </li><li>RoI Poolingå±‚:è¯¥å±‚æ”¶é›†è¾“å…¥çš„feature mapå’Œproposalsç»¼åˆè¿™äº›ä¿¡æ¯æå–proposal feature map,è¿›å…¥åˆ°åé¢å¯åˆ©ç”¨å…¨è¿æ¥æ“ä½œå±‚è¿›è¡Œç›®æ ‡è¯†åˆ«å’Œå®šä½</li></ul></li><li>æœ€åçš„classifierä¼šå°†Roi Poolingå±‚å½¢æˆå›ºå®šå¤§å°çš„feature mapè¿›è¡Œå…¨è¿æ¥æ“ä½œ,åˆ©ç”¨softmaxè¿›è¡Œå…·ä½“ç±»åˆ«çš„åˆ†ç±»,åŒæ—¶åˆ©ç”¨L1 losså®Œæˆbounding box regressionå›å½’æ“ä½œè·å¾—ç‰©ä½“çš„å‡†ç¡®ä½ç½®</li></ul><h5 id="ç»†èŠ‚"><a href="#ç»†èŠ‚" class="headerlink" title="ç»†èŠ‚"></a>ç»†èŠ‚</h5><h6 id="1-RPN"><a href="#1-RPN" class="headerlink" title="1.RPN"></a>1.RPN</h6><p>ä¹‹å‰çš„R-CNNå’ŒFast R-CNNéƒ½æ˜¯é‡‡ç”¨å¯é€‰æ‹©æ€§æœç´¢(SS)æ¥äº§ç”Ÿå€™é€‰æ¡†çš„,ä½†æ˜¯è¿™ç§æ–¹æ³•ç‰¹åˆ«è€—æ—¶;Faster R-CNNæœ€å¤§çš„äº®ç‚¹æ˜¯æŠ›å¼ƒSS,é‡‡ç”¨RPNç”Ÿæˆå€™é€‰æ¡†.<br><a href="https://imagelol.com/image/LbJCxk"><img src="https://s6.jpg.cm/2021/12/23/LbJCxk.png" alt="LbJCxk.png"></a></p><p>è¯´æ˜:</p><ol><li>Conv feature map:VGG-16ç½‘ç»œæœ€åä¸€ä¸ªå·ç§¯å±‚è¾“å‡ºçš„feature map</li><li>Sliding window:æ»‘åŠ¨çª—å£å®é™…ä¸Šå°±æ˜¯3*3çš„å·ç§¯æ ¸,æ»‘çª—åªè¦é€‰å–æ‰€æœ‰å¯èƒ½çš„åŒºåŸŸå¹¶æ²¡æœ‰é¢å¤–çš„ä½œç”¨</li><li>K anchor boxes:åœ¨æ¯ä¸ªsliding windowçš„ç‚¹ä¸Šåˆå§‹åŒ–çš„å‚è€ƒåŒºåŸŸ(è®ºæ–‡ä¸­k=9)å°±æ˜¯9ä¸ªçŸ©å½¢æ¡†</li><li>Intermediate layer:ä¸­é—´å±‚ï¼Œ256-dæ˜¯ä¸­é—´å±‚çš„ç»´åº¦(è®ºæ–‡ä¸­è°ç”¨ZFç½‘ç»œå°±æ˜¯256ç»´,VGGå°±æ˜¯512ç»´)</li><li>Cls layer:åˆ†ç±»å±‚,é¢„æµ‹proposalçš„anchorå¯¹åº”çš„proposalçš„(x,y,w,h)</li><li>2k scores:2kä¸ªåˆ†æ•°(18ä¸ª)</li><li>Reg layer:å›å½’å±‚,åˆ¤æ–­è¯¥proposalæ˜¯å‰æ™¯è¿˜æ˜¯èƒŒæ™¯</li><li>4k coordinates:4kåæ ‡(36ä¸ª)</li></ol><ul><li>RPNçš„è¾“å…¥æ˜¯å·ç§¯ç‰¹å¾å›¾,è¾“å‡ºæ˜¯å›¾ç‰‡ç”Ÿæˆçš„proposals,RPNé€šè¿‡ä¸€ä¸ªæ»‘åŠ¨çª—å£è¿æ¥åœ¨æœ€åä¸€ä¸ªå·ç§¯å±‚çš„feature mapä¸Š,ç”Ÿæˆä¸€ä¸ªé•¿åº¦256çš„å…¨è¿æ¥ç‰¹å¾</li><li>è¿™ä¸ªå…¨è¿æ¥å±‚ç‰¹å¾åˆ†åˆ«é€å…¥ä¸¤ä¸ªå…¨è¿æ¥å±‚ä¸€ä¸ªæ˜¯åˆ†ç±»å±‚,ç”¨äºåˆ†ç±»æ£€æµ‹;ä¸€ä¸ªæ˜¯å›å½’å±‚,ç”¨äºå›å½’;å¯¹äºæ¯ä¸ªæ»‘åŠ¨çª—å£ä½ç½®ä¸€èˆ¬è®¾ç½®k(è®ºæ–‡ä¸­k=9)ä¸ªä¸åŒå¤§å°æˆ–è€…æ¯”ä¾‹çš„anchorsè¿™æ„å‘³ç€æ¯ä¸ªæ»‘çª—è¦†ç›–çš„ä½ç½®å°±ä¼šé¢„æµ‹9å“¥å€™é€‰åŒºåŸŸ<br><strong>åˆ†ç±»å±‚</strong>:æ¯ä¸ªanchorè¾“å‡ºä¸¤ä¸ªé¢„æµ‹å€¼:anchoræ˜¯èƒŒæ™¯(background,éobject)çš„scoreå’Œanchoræ˜¯å‰æ™¯(foreground,object)çš„score<br><strong>å›å½’å±‚</strong>:è¾“å‡º4k(4*9=36)ä¸ªåæ ‡å€¼è¡¨ç¤ºæ¯ä¸ªå€™é€‰åŒºåŸŸçš„ä½ç½®(x,y,w,h)</li></ul><p>ä¹Ÿå°±æ˜¯è¯´æˆ‘ä¹ˆæ˜¯é€šè¿‡è¿™äº›ç‰¹å¾å›¾åº”ç”¨æ»‘åŠ¨çª—å£åŠ anchoræœºåˆ¶è¿›è¡Œç›®æ ‡åŒºåŸŸåˆ¤å®šå’Œåˆ†ç±»çš„,è¿™é‡Œçš„æ»‘çª—åŠ anchoræœºåˆ¶åŠŸèƒ½ç±»ä¼¼äºfast rcnnçš„selective searchç”Ÿæˆproposalsçš„ä½œç”¨,è€Œæˆ‘ä»¬æ˜¯é€šè¿‡RPNç”Ÿæˆproposals.RPNå°±æ˜¯ä¸€ä¸ªå·ç§¯å±‚ + relu +å·¦å³ä¸¤ä¸ªå±‚(cls layerå’Œreg layer)çš„å°å‹ç½‘ç»œ</p><h6 id="2-anchor"><a href="#2-anchor" class="headerlink" title="2.anchor"></a>2.anchor</h6><p>è®ºæ–‡å†…å®¹:The k proposals are parameterized relative to k reference boxes, which we call anchors;å¯ä»¥ç†è§£ä¸ºé”šç‚¹ä½äºä¹‹å‰è¯´çš„3 * 3çš„æ»‘çª—ä¸­å¿ƒå¤„,å°±æ˜¯å› ä¸ºæœ‰å¤šä¸ªanchor.è¿™9ä¸ªanchoræ˜¯ä½œè€…è®¾ç½®çš„,è®ºæ–‡ä¸­scale=[128,256,512],é•¿å®½æ¯”[1:1,1:2,2:1]æœ‰9ç§ï¼›è‡ªå·±å¯ä»¥æ ¹æ®ç›®æ ‡çš„ç‰¹ç‚¹åšå‡ºä¸åŒçš„è®¾è®¡;å¯¹äºä¸€å¹… w * hçš„feature mapä¸€å…±æœ‰w * h * kä¸ªé”šç‚¹.</p><p><img src="https://s6.jpg.cm/2021/12/23/LbJjEy.png" alt="LbJjEy.png"></p><h6 id="3-VGGæå–ç‰¹å¾"><a href="#3-VGGæå–ç‰¹å¾" class="headerlink" title="3.VGGæå–ç‰¹å¾"></a>3.VGGæå–ç‰¹å¾</h6><p>VGGçš„ç½‘ç»œæµç¨‹å›¾:</p><p><a href="https://imagelol.com/image/LbJh6e"><img src="https://s6.jpg.cm/2021/12/23/LbJh6e.png" alt="LbJh6e.png"></a></p><p>æ¯ä¸ªå·ç§¯å±‚åˆ©ç”¨å‰é¢ç½‘ç»œä¿¡æ¯ç”ŸæˆæŠ½è±¡æè¿°:<br>ç¬¬ä¸€å±‚å­¦ä¹ è¾¹ç¼˜edgesä¿¡æ¯ï¼›<br>ç¬¬äºŒå±‚:å­¦ä¹ è¾¹ç¼˜edgesä¸­å›¾æ¡ˆpatternsä»¥å­¦ä¹ æ›´åŠ å¤æ‚çš„å½¢çŠ¶ä¿¡æ¯ï¼›æœ€ç»ˆå¾—åˆ°å·ç§¯ç‰¹å¾å›¾å…¶ç©ºé—´ç»´åº¦(åˆ†è¾¨ç‡)æ¯”åŸå›¾å°äº†å¾ˆå¤šä½†æ›´æ·±ï¼›<br>ç‰¹å¾å›¾çš„widthå’Œheightç”±äºå·ç§¯å±‚é—´çš„æ± åŒ–å±‚è€Œé™ä½,è€Œdepthç”±äºå·ç§¯å±‚å­¦ä¹ çš„filtersæ•°é‡è€Œå¢åŠ .</p><h6 id="4-ROI-pooling"><a href="#4-ROI-pooling" class="headerlink" title="4.ROI pooling"></a>4.ROI pooling</h6><p>ROIå°±æ˜¯region of interestæŒ‡çš„æ˜¯æ„Ÿå…´è¶£åŒºåŸŸ;å¦‚æœæ˜¯åŸå›¾ï¼Œroiå°±æ˜¯ç›®æ ‡ï¼Œå¦‚æœæ˜¯featuremapï¼Œroiå°±æ˜¯ç‰¹å¾å›¾åƒç›®æ ‡çš„ç‰¹å¾äº†ï¼Œroiåœ¨è¿™é‡Œå°±æ˜¯ç»è¿‡RPNç½‘ç»œå¾—åˆ°çš„ï¼Œæ€»ä¹‹å°±æ˜¯ä¸€ä¸ªæ¡†ã€‚poolingå°±æ˜¯æ± åŒ–ã€‚æ‰€ä»¥ROI Poolingå°±æ˜¯Poolingçš„ä¸€ç§ï¼Œåªæ˜¯æ˜¯é’ˆå¯¹äºRoisçš„poolingæ“ä½œè€Œå·²ã€‚RPN å¤„ç†åï¼Œå¯ä»¥å¾—åˆ°ä¸€å †æ²¡æœ‰ class score çš„ object proposals.å¾…å¤„ç†é—®é¢˜ä¸ºï¼šå¦‚ä½•åˆ©ç”¨è¿™äº›proposalsåˆ†ç±».Roi poolingå±‚çš„è¿‡ç¨‹å°±æ˜¯ä¸ºäº†å°†ä¸åŒè¾“å…¥å°ºå¯¸çš„feature mapï¼ˆROIï¼‰æŠ å‡ºæ¥ï¼Œç„¶åresizeåˆ°ç»Ÿä¸€çš„å¤§å°.</p><p>ROI poolingå±‚çš„è¾“å…¥:</p><ol><li>ç‰¹å¾å›¾features map(è¿™ä¸ªç‰¹å¾å›¾å°±æ˜¯cnnå·ç§¯å‡ºæ¥ä»¥åç”¨äºå…±äº«çš„é‚£ä¸ªç‰¹å¾å›¾)</li><li>roiä¿¡æ¯:(å°±æ˜¯RPNç½‘ç»œçš„è¾“å‡º,ä¸€ä¸ªè¡¨ç¤ºæ‰€æœ‰ROIçš„N*5çŸ©é˜µ,Nè¡¨ç¤ºROIçš„æ•°ç›®;ç¬¬ä¸€åˆ—è¡¨ç¤ºå›¾åƒindex,å…¶ä½™å››åˆ—è¡¨ç¤ºå…¶ä½™çš„å·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡,åæ ‡ä¿¡æ¯æ˜¯å¯¹åº”åŸå›¾ä¸­çš„ç»å¯¹åæ ‡)</li></ol><p>ROI poolingå±‚çš„è¿‡ç¨‹:</p><p>é¦–å…ˆå°†RPNä¸­å¾—åˆ°çš„åŸå›¾ä¸­roiä¿¡æ¯æ˜ å°„åˆ°feature mapä¸ŠæŒ‰åŸå›¾ä¸featuremapçš„æ¯”ä¾‹ç¼©å°roiåæ ‡å°±è¡Œäº†ï¼‰ï¼Œç„¶åç»è¿‡æœ€å¤§æ± åŒ–ï¼Œæ± åŒ–åˆ°å›ºå®šå¤§å°wÃ—hã€‚ä½†è¿™ä¸ªpoolingä¸æ˜¯ä¸€èˆ¬çš„Poolingï¼Œè€Œæ˜¯å°†åŒºåŸŸç­‰åˆ†ï¼Œç„¶åå–æ¯ä¸€å°å—çš„æœ€å¤§å€¼ï¼Œæœ€åæ‰èƒ½å¾—åˆ°å›ºå®šå°ºå¯¸çš„roiã€‚</p><p>ä¹Ÿå°±æ˜¯ï¼š</p><p>æ ¹æ®è¾“å…¥çš„imageï¼Œå°†Roiæ˜ å°„åˆ°feature mapå¯¹åº”çš„ä½ç½®ï¼›<br>å°†æ˜ å°„åçš„åŒºåŸŸåˆ’åˆ†ä¸ºç›¸åŒå¤§å°çš„sectionsï¼ˆsectionsæ•°é‡å’Œè¾“å‡ºçš„ç»´åº¦ç›¸åŒï¼‰ï¼›<br>å¯¹æ¯ä¸ªsectionè¿›è¡Œmax poolingæ“ä½œï¼›<br>ROI poolingå±‚çš„è¾“å‡ºï¼š</p><p>ç»“æœæ˜¯ï¼Œç”±ä¸€ç»„å¤§å°å„å¼‚çš„çŸ©å½¢ï¼Œæˆ‘ä»¬å¿«é€Ÿè·å–åˆ°å…·æœ‰å›ºå®šå¤§å°çš„ç›¸åº”ç‰¹å¾å›¾ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒRoI pooling è¾“å‡ºçš„ç»´åº¦å®é™…ä¸Šå¹¶ä¸å–å†³äºè¾“å…¥ç‰¹å¾å›¾çš„å¤§å°ï¼Œä¹Ÿä¸å–å†³äºåŒºåŸŸææ¡ˆçš„å¤§å°ã€‚è¿™å®Œå…¨å–å†³äºæˆ‘ä»¬å°†åŒºåŸŸåˆ†æˆå‡ éƒ¨åˆ†ã€‚ä¹Ÿå°±æ˜¯ï¼Œbatchä¸ªroiçŸ©é˜µï¼Œæ¯ä¸€ä¸ªroiçŸ©é˜µä¸ºï¼šé€šé“æ•°xWxH,ä¹Ÿå°±æ˜¯ä»selective searchå¾—åˆ°batchä¸ªroiï¼Œç„¶åæ˜ å°„ä¸ºå›ºå®šå¤§å°ã€‚</p><h6 id="5-NMS"><a href="#5-NMS" class="headerlink" title="5.NMS"></a>5.NMS</h6><p>NMSï¼ˆNon Maximum Suppressionï¼Œéæå¤§å€¼æŠ‘åˆ¶ï¼‰ç”¨äºåæœŸçš„ç‰©ä½“å†—ä½™è¾¹ç•Œæ¡†å»é™¤ï¼Œå› ä¸ºç›®æ ‡æ£€æµ‹æœ€ç»ˆä¸€ä¸ªç›®æ ‡åªéœ€è¦ä¸€ä¸ªæ¡†ï¼Œæ‰€ä»¥è¦æŠŠå¤šä½™çš„æ¡†å¹²æ‰ï¼Œç•™ä¸‹æœ€å‡†ç¡®çš„é‚£ä¸ªã€‚</p><p>NMSçš„è¾“å…¥ï¼š</p><p>æ£€æµ‹åˆ°çš„Boxes(åŒä¸€ä¸ªç‰©ä½“å¯èƒ½è¢«æ£€æµ‹åˆ°å¾ˆå¤šBoxesï¼Œæ¯ä¸ªboxå‡æœ‰åˆ†ç±»score)</p><p>NMSçš„è¾“å‡ºï¼š</p><p>æœ€ä¼˜çš„Box.</p><h6 id="6-FC-layer"><a href="#6-FC-layer" class="headerlink" title="6.FC layer"></a>6.FC layer</h6><p>ç»è¿‡roi poolingå±‚ä¹‹åï¼Œbatch_size=300, proposal feature mapçš„å¤§å°æ˜¯7Ã—7,512-d,å¯¹ç‰¹å¾å›¾è¿›è¡Œå…¨è¿æ¥ï¼Œå‚ç…§ä¸‹å›¾ï¼Œæœ€ååŒæ ·åˆ©ç”¨Softmax Losså’ŒL1 Losså®Œæˆåˆ†ç±»å’Œå®šä½ã€‚</p><p><img src="https://s6.jpg.cm/2021/12/23/LbJ3wi.png" alt="LbJ3wi.png"></p><p>é€šè¿‡å…¨è¿æ¥å±‚ä¸softmaxè®¡ç®—æ¯ä¸ªregion proposalå…·ä½“å±äºå“ªä¸ªç±»åˆ«ï¼ˆå¦‚äººï¼Œé©¬ï¼Œè½¦ç­‰ï¼‰ï¼Œè¾“å‡ºcls_probæ¦‚ç‡å‘é‡ï¼›åŒæ—¶å†æ¬¡åˆ©ç”¨bounding box regressionè·å¾—æ¯ä¸ªregion proposalçš„ä½ç½®åç§»é‡bbox_predï¼Œç”¨äºå›å½’è·å¾—æ›´åŠ ç²¾ç¡®çš„ç›®æ ‡æ£€æµ‹æ¡†</p><p>å³ä»PoI Poolingè·å–åˆ°7x7å¤§å°çš„proposal feature mapsåï¼Œé€šè¿‡å…¨è¿æ¥ä¸»è¦åšäº†ï¼š</p><p>é€šè¿‡å…¨è¿æ¥å’Œsoftmaxå¯¹region proposalsè¿›è¡Œå…·ä½“ç±»åˆ«çš„åˆ†ç±»ï¼›</p><p>å†æ¬¡å¯¹region proposalsè¿›è¡Œbounding box regressionï¼Œè·å–æ›´é«˜ç²¾åº¦çš„rectangle boxã€‚</p><h5 id="ä¸»è¦éƒ¨åˆ†"><a href="#ä¸»è¦éƒ¨åˆ†" class="headerlink" title="ä¸»è¦éƒ¨åˆ†"></a>ä¸»è¦éƒ¨åˆ†</h5><p><strong>Faster</strong> <strong>RCNN</strong>å…¶å®å¯ä»¥åˆ†ä¸ºå››éƒ¨åˆ†ä¸»è¦å†…å®¹</p><h6 id="1-Conv-Layer"><a href="#1-Conv-Layer" class="headerlink" title="1.Conv Layer"></a>1.Conv Layer</h6><p>ä½œä¸ºä¸€ç§CNNç›®æ ‡æ£€æµ‹æ–¹æ³•,Faster RCNNé¦–å…ˆä½¿ç”¨ä¸€ç»„åŸºç¡€çš„cnn+relu+poolingå±‚æå–imageçš„feature map,è¿™ä¸ªfeature mapè¢«å…±äº«ç”¨ç”¨äºåç»­RPNå±‚å’Œå…¨è¿æ¥å±‚</p><h6 id="2-Region-Proposal-NetWorks"><a href="#2-Region-Proposal-NetWorks" class="headerlink" title="2.Region Proposal NetWorks"></a>2.Region Proposal NetWorks</h6><p>RPNç½‘ç»œç”¨äºç”Ÿæˆregion proposals,è¯¥å±‚é€šè¿‡softmaxåˆ¤æ–­anchorså±äºpositiveè¿˜æ˜¯negative,å†åˆ©ç”¨bounding</p><p>box regressionä¿®æ­£anchorsè·å¾—ç²¾ç¡®çš„proposals</p><h6 id="3-Roi-Pooling"><a href="#3-Roi-Pooling" class="headerlink" title="3.Roi Pooling"></a>3.Roi Pooling</h6><p>è¯¥å±‚æ‰‹æœºè¾“å…¥çš„feature mapå’Œproposals,ç»¼åˆè¿™äº›ä¿¡æ¯ä¹‹åæå–proposals,ç»¼åˆè¿™äº›ä¿¡æ¯æå–proposals feature mapsé€å…¥åç»­å…¨è¿æ¥å±‚åˆ¤å®šç›®æ ‡ç±»åˆ«</p><h6 id="4-Classfication"><a href="#4-Classfication" class="headerlink" title="4.Classfication"></a>4.Classfication</h6><p>åˆ©ç”¨proposals feature mapè®¡ç®—proposalsçš„ç±»åˆ«åŒæ—¶å†æ¬¡bounding box regressionè·å¾—æ£€æµ‹æ¡†æœ€ç»ˆçš„ç²¾ç¡®ä½ç½®</p><p><img src="https://s6.jpg.cm/2021/12/23/LbJyjr.png" alt="LbJyjr.png"></p><p>ä¸Šå›¾å±•ç¤ºäº†pythonç‰ˆæœ¬ä¸­çš„VGG16æ¨¡å‹ä¸­çš„faster rcnnçš„ç½‘ç»œç»“æ„å¯ä»¥æ¸…æ™°çš„çœ‹åˆ°è¯¥ç½‘ç»œå¯¹äºä¸€å¹…ä»»æ„å¤§å°çš„P*Qçš„å›¾åƒ:</p><ul><li>é¦–å…ˆå›ºå®šè‡³å¤§å°MÃ—Nç„¶åå°†MÃ—Nå›¾åƒé€å…¥ç½‘ç»œ;</li><li>è€ŒConv layer</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> cv </tag>
            
            <tag> RCNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dian2021å¤ä»¤è¥</title>
      <link href="/year/11/06/002/"/>
      <url>/year/11/06/002/</url>
      
        <content type="html"><![CDATA[<p>æŠ¥åå‚åŠ å¤ä»¤è¥èµ·åˆæ˜¯æƒ³èŠ±æ—¶é—´ç ”ç©¶AIæœºå™¨å­¦ä¹ é¢†åŸŸçš„ç»å…¸ç®—æ³•ï¼Œç„¶ååšäº†diançš„ä¸€ä¸ª<strong>lab</strong></p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> dian </tag>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> CNNç®€æ˜“æ¡†æ¶æ­å»º </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SeqToSeq_Translation(Attention)</title>
      <link href="/year/09/27/code%20of%20seq2seq_translation/"/>
      <url>/year/09/27/code%20of%20seq2seq_translation/</url>
      
        <content type="html"><![CDATA[<p>ä»¥ä¸‹åšæ–‡å‚è€ƒpytorchå®˜ç½‘çš„æ•™ç¨‹(åŸæ–‡æ¬è¿)ï¼š</p><pre class="line-numbers language-python"><code class="language-python"><span class="token operator">%</span>matplotlib inline<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>NLP From Scratch: Translation with a Sequence to Sequence Network and Attention</p><hr><p><strong>Author</strong>: <code>Sean Robertson &lt;https://github.com/spro/practical-pytorch&gt;</code>_</p><p>This is the third and final tutorial on doing â€œNLP From Scratchâ€, where we<br>write our own classes and functions to preprocess the data to do our NLP<br>modeling tasks. We hope after you complete this tutorial that youâ€™ll proceed to<br>learn how <code>torchtext</code> can handle much of this preprocessing for you in the<br>three tutorials immediately following this one.</p><p>In this project we will be teaching a neural network to translate from<br>French to English.</p><p>::</p><pre class="line-numbers language-yaml"><code class="language-yaml"><span class="token punctuation">[</span><span class="token key atrule">KEY</span><span class="token punctuation">:</span> <span class="token punctuation">></span> input<span class="token punctuation">,</span> = target<span class="token punctuation">,</span> &lt; output<span class="token punctuation">]</span><span class="token punctuation">></span> il est en train de peindre un tableau .= he is painting a picture .&lt; he is painting a picture .<span class="token punctuation">></span> pourquoi ne pas essayer ce vin delicieux <span class="token punctuation">?</span>= why not try that delicious wine <span class="token punctuation">?</span>&lt; why not try that delicious wine <span class="token punctuation">?</span><span class="token punctuation">></span> elle n est pas poete mais romanciere .= she is not a poet but a novelist .&lt; she not not a poet but a novelist .<span class="token punctuation">></span> vous etes trop maigre .= you re too skinny .&lt; you re all alone .<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>â€¦ to varying degrees of success.</p><p>This is made possible by the simple but powerful idea of the <code>sequence to sequence network &lt;https://arxiv.org/abs/1409.3215&gt;</code>__, in which two<br>recurrent neural networks work together to transform one sequence to<br>another. An encoder network condenses an input sequence into a vector,<br>and a decoder network unfolds that vector into a new sequence.</p><p>.. figure:: /_static/img/seq-seq-images/seq2seq.png<br>   :alt:</p><p>To improve upon this model weâ€™ll use an <code>attention mechanism &lt;https://arxiv.org/abs/1409.0473&gt;</code>__, which lets the decoder<br>learn to focus over a specific range of the input sequence.</p><p><strong>Recommended Reading:</strong></p><p>I assume you have at least installed PyTorch, know Python, and<br>understand Tensors:</p><ul><li> <a href="https://pytorch.org/">https://pytorch.org/</a> For installation instructions</li><li> :doc:<code>/beginner/deep_learning_60min_blitz</code> to get started with PyTorch in general</li><li> :doc:<code>/beginner/pytorch_with_examples</code> for a wide and deep overview</li><li> :doc:<code>/beginner/former_torchies_tutorial</code> if you are former Lua Torch user</li></ul><p>It would also be useful to know about Sequence to Sequence networks and<br>how they work:</p><ul><li><code>Learning Phrase Representations using RNN Encoder-Decoder for  Statistical Machine Translation &lt;https://arxiv.org/abs/1406.1078&gt;</code>__</li><li><code>Sequence to Sequence Learning with Neural  Networks &lt;https://arxiv.org/abs/1409.3215&gt;</code>__</li><li><code>Neural Machine Translation by Jointly Learning to Align and  Translate &lt;https://arxiv.org/abs/1409.0473&gt;</code>__</li><li> <code>A Neural Conversational Model &lt;https://arxiv.org/abs/1506.05869&gt;</code>__</li></ul><p>You will also find the previous tutorials on<br>:doc:<code>/intermediate/char_rnn_classification_tutorial</code><br>and :doc:<code>/intermediate/char_rnn_generation_tutorial</code><br>helpful as those concepts are very similar to the Encoder and Decoder<br>models, respectively.</p><p><strong>Requirements</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> __future__ <span class="token keyword">import</span> unicode_literals<span class="token punctuation">,</span> print_function<span class="token punctuation">,</span> division<span class="token keyword">from</span> io <span class="token keyword">import</span> open<span class="token keyword">import</span> unicodedata<span class="token keyword">import</span> string<span class="token keyword">import</span> re<span class="token keyword">import</span> random<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">from</span> torch <span class="token keyword">import</span> optim<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> Fdevice <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="Loading-data-files"><a href="#Loading-data-files" class="headerlink" title="Loading data files"></a>Loading data files</h1><p>The data for this project is a set of many thousands of English to<br>French translation pairs.</p><p><code>This question on Open Data Stack Exchange &lt;https://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages&gt;</code>__<br>pointed me to the open translation site <a href="https://tatoeba.org/">https://tatoeba.org/</a> which has<br>downloads available at <a href="https://tatoeba.org/eng/downloads">https://tatoeba.org/eng/downloads</a> - and better<br>yet, someone did the extra work of splitting language pairs into<br>individual text files here: <a href="https://www.manythings.org/anki/">https://www.manythings.org/anki/</a></p><p>The English to French pairs are too big to include in the repo, so<br>download to <code>data/eng-fra.txt</code> before continuing. The file is a tab<br>separated list of translation pairs:</p><p>::</p><pre><code>I am cold.    J'ai froid.</code></pre><p>.. Note::<br>   Download the data from<br>   <code>here &lt;https://download.pytorch.org/tutorial/data.zip&gt;</code>_<br>   and extract it to the current directory.</p><p>Similar to the character encoding used in the character-level RNN<br>tutorials, we will be representing each word in a language as a one-hot<br>vector, or giant vector of zeros except for a single one (at the index<br>of the word). Compared to the dozens of characters that might exist in a<br>language, there are many many more words, so the encoding vector is much<br>larger. We will however cheat a bit and trim the data to only use a few<br>thousand words per language.</p><p>.. figure:: /_static/img/seq-seq-images/word-encoding.png<br>   :alt:</p><p>Weâ€™ll need a unique index per word to use as the inputs and targets of<br>the networks later. To keep track of all this we will use a helper class<br>called <code>Lang</code> which has word â†’ index (<code>word2index</code>) and index â†’ word<br>(<code>index2word</code>) dictionaries, as well as a count of each word<br><code>word2count</code> which will be used to replace rare words later.</p><pre class="line-numbers language-python"><code class="language-python">SOS_token <span class="token operator">=</span> <span class="token number">0</span>EOS_token <span class="token operator">=</span> <span class="token number">1</span><span class="token keyword">class</span> <span class="token class-name">Lang</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>name <span class="token operator">=</span> name        self<span class="token punctuation">.</span>word2index <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>        self<span class="token punctuation">.</span>word2count <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>        self<span class="token punctuation">.</span>index2word <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">"SOS"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">"EOS"</span><span class="token punctuation">}</span>        self<span class="token punctuation">.</span>n_words <span class="token operator">=</span> <span class="token number">2</span>  <span class="token comment" spellcheck="true"># Count SOS and EOS</span>    <span class="token keyword">def</span> <span class="token function">addSentence</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> word <span class="token keyword">in</span> sentence<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>addWord<span class="token punctuation">(</span>word<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">addWord</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> word<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> word <span class="token operator">not</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>word2index<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>word2index<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>n_words            self<span class="token punctuation">.</span>word2count<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>            self<span class="token punctuation">.</span>index2word<span class="token punctuation">[</span>self<span class="token punctuation">.</span>n_words<span class="token punctuation">]</span> <span class="token operator">=</span> word            self<span class="token punctuation">.</span>n_words <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>word2count<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>The files are all in Unicode, to simplify we will turn Unicode<br>characters to ASCII, make everything lowercase, and trim most<br>punctuation.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Turn a Unicode string to plain ASCII, thanks to</span><span class="token comment" spellcheck="true"># https://stackoverflow.com/a/518232/2809427</span><span class="token keyword">def</span> <span class="token function">unicodeToAscii</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>        c <span class="token keyword">for</span> c <span class="token keyword">in</span> unicodedata<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span><span class="token string">'NFD'</span><span class="token punctuation">,</span> s<span class="token punctuation">)</span>        <span class="token keyword">if</span> unicodedata<span class="token punctuation">.</span>category<span class="token punctuation">(</span>c<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token string">'Mn'</span>    <span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Lowercase, trim, and remove non-letter characters</span><span class="token keyword">def</span> <span class="token function">normalizeString</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>    s <span class="token operator">=</span> unicodeToAscii<span class="token punctuation">(</span>s<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    s <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>r<span class="token string">"([.!?])"</span><span class="token punctuation">,</span> r<span class="token string">" \1"</span><span class="token punctuation">,</span> s<span class="token punctuation">)</span>    s <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>r<span class="token string">"[^a-zA-Z.!?]+"</span><span class="token punctuation">,</span> r<span class="token string">" "</span><span class="token punctuation">,</span> s<span class="token punctuation">)</span>    <span class="token keyword">return</span> s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>To read the data file we will split the file into lines, and then split<br>lines into pairs. The files are all English â†’ Other Language, so if we<br>want to translate from Other Language â†’ English I added the <code>reverse</code><br>flag to reverse the pairs.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">readLangs</span><span class="token punctuation">(</span>lang1<span class="token punctuation">,</span> lang2<span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Reading lines..."</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Read the file and split into lines</span>    lines <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">'data/%s-%s.txt'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>lang1<span class="token punctuation">,</span> lang2<span class="token punctuation">)</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>\   <span class="token operator">//</span> ç›¸åº”æ•°æ®é›†ä¸‹è½½ä»¥åæ³¨æ„ç›¸å¯¹è·¯å¾„çš„è®¾ç½®        read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Split every line into pairs and normalize</span>    pairs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>normalizeString<span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token keyword">for</span> s <span class="token keyword">in</span> l<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> l <span class="token keyword">in</span> lines<span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># Reverse pairs, make Lang instances</span>    <span class="token keyword">if</span> reverse<span class="token punctuation">:</span>        pairs <span class="token operator">=</span> <span class="token punctuation">[</span>list<span class="token punctuation">(</span>reversed<span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> pairs<span class="token punctuation">]</span>        input_lang <span class="token operator">=</span> Lang<span class="token punctuation">(</span>lang2<span class="token punctuation">)</span>        output_lang <span class="token operator">=</span> Lang<span class="token punctuation">(</span>lang1<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        input_lang <span class="token operator">=</span> Lang<span class="token punctuation">(</span>lang1<span class="token punctuation">)</span>        output_lang <span class="token operator">=</span> Lang<span class="token punctuation">(</span>lang2<span class="token punctuation">)</span>    <span class="token keyword">return</span> input_lang<span class="token punctuation">,</span> output_lang<span class="token punctuation">,</span> pairs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Since there are a <em>lot</em> of example sentences and we want to train<br>something quickly, weâ€™ll trim the data set to only relatively short and<br>simple sentences. Here the maximum length is 10 words (that includes<br>ending punctuation) and weâ€™re filtering to sentences that translate to<br>the form â€œI amâ€ or â€œHe isâ€ etc. (accounting for apostrophes replaced<br>earlier).</p><pre class="line-numbers language-python"><code class="language-python">MAX_LENGTH <span class="token operator">=</span> <span class="token number">10</span>eng_prefixes <span class="token operator">=</span> <span class="token punctuation">(</span>    <span class="token string">"i am "</span><span class="token punctuation">,</span> <span class="token string">"i m "</span><span class="token punctuation">,</span>    <span class="token string">"he is"</span><span class="token punctuation">,</span> <span class="token string">"he s "</span><span class="token punctuation">,</span>    <span class="token string">"she is"</span><span class="token punctuation">,</span> <span class="token string">"she s "</span><span class="token punctuation">,</span>    <span class="token string">"you are"</span><span class="token punctuation">,</span> <span class="token string">"you re "</span><span class="token punctuation">,</span>    <span class="token string">"we are"</span><span class="token punctuation">,</span> <span class="token string">"we re "</span><span class="token punctuation">,</span>    <span class="token string">"they are"</span><span class="token punctuation">,</span> <span class="token string">"they re "</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">filterPair</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> len<span class="token punctuation">(</span>p<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> MAX_LENGTH <span class="token operator">and</span> \        len<span class="token punctuation">(</span>p<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> MAX_LENGTH <span class="token operator">and</span> \        p<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>startswith<span class="token punctuation">(</span>eng_prefixes<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">filterPairs</span><span class="token punctuation">(</span>pairs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token punctuation">[</span>pair <span class="token keyword">for</span> pair <span class="token keyword">in</span> pairs <span class="token keyword">if</span> filterPair<span class="token punctuation">(</span>pair<span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>The full process for preparing the data is:</p><ul><li> Read text file and split into lines, split lines into pairs</li><li> Normalize text, filter by length and content</li><li> Make word lists from sentences in pairs</li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">prepareData</span><span class="token punctuation">(</span>lang1<span class="token punctuation">,</span> lang2<span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    input_lang<span class="token punctuation">,</span> output_lang<span class="token punctuation">,</span> pairs <span class="token operator">=</span> readLangs<span class="token punctuation">(</span>lang1<span class="token punctuation">,</span> lang2<span class="token punctuation">,</span> reverse<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Read %s sentence pairs"</span> <span class="token operator">%</span> len<span class="token punctuation">(</span>pairs<span class="token punctuation">)</span><span class="token punctuation">)</span>    pairs <span class="token operator">=</span> filterPairs<span class="token punctuation">(</span>pairs<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Trimmed to %s sentence pairs"</span> <span class="token operator">%</span> len<span class="token punctuation">(</span>pairs<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Counting words..."</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> pair <span class="token keyword">in</span> pairs<span class="token punctuation">:</span>        input_lang<span class="token punctuation">.</span>addSentence<span class="token punctuation">(</span>pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        output_lang<span class="token punctuation">.</span>addSentence<span class="token punctuation">(</span>pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Counted words:"</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>input_lang<span class="token punctuation">.</span>name<span class="token punctuation">,</span> input_lang<span class="token punctuation">.</span>n_words<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>output_lang<span class="token punctuation">.</span>name<span class="token punctuation">,</span> output_lang<span class="token punctuation">.</span>n_words<span class="token punctuation">)</span>    <span class="token keyword">return</span> input_lang<span class="token punctuation">,</span> output_lang<span class="token punctuation">,</span> pairsinput_lang<span class="token punctuation">,</span> output_lang<span class="token punctuation">,</span> pairs <span class="token operator">=</span> prepareData<span class="token punctuation">(</span><span class="token string">'eng'</span><span class="token punctuation">,</span> <span class="token string">'fra'</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>pairs<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Reading lines...Read 135842 sentence pairsTrimmed to 10599 sentence pairsCounting words...Counted words:fra 4345eng 2803['je suis lessive et fatigue .', 'i m broke and tired .']</code></pre><h1 id="The-Seq2Seq-Model"><a href="#The-Seq2Seq-Model" class="headerlink" title="The Seq2Seq Model"></a>The Seq2Seq Model</h1><p>A Recurrent Neural Network, or RNN, is a network that operates on a<br>sequence and uses its own output as input for subsequent steps.</p><p>A <code>Sequence to Sequence network &lt;https://arxiv.org/abs/1409.3215&gt;</code><strong>, or<br>seq2seq network, or <code>Encoder Decoder network &lt;https://arxiv.org/pdf/1406.1078v3.pdf&gt;</code></strong>, is a model<br>consisting of two RNNs called the encoder and decoder. The encoder reads<br>an input sequence and outputs a single vector, and the decoder reads<br>that vector to produce an output sequence.</p><p>.. figure:: /_static/img/seq-seq-images/seq2seq.png<br>   :alt:</p><p>Unlike sequence prediction with a single RNN, where every input<br>corresponds to an output, the seq2seq model frees us from sequence<br>length and order, which makes it ideal for translation between two<br>languages.</p><p>Consider the sentence â€œJe ne suis pas le chat noirâ€ â†’ â€œI am not the<br>black catâ€. Most of the words in the input sentence have a direct<br>translation in the output sentence, but are in slightly different<br>orders, e.g. â€œchat noirâ€ and â€œblack catâ€. Because of the â€œne/pasâ€<br>construction there is also one more word in the input sentence. It would<br>be difficult to produce a correct translation directly from the sequence<br>of input words.</p><p>With a seq2seq model the encoder creates a single vector which, in the<br>ideal case, encodes the â€œmeaningâ€ of the input sequence into a single<br>vector â€” a single point in some N dimensional space of sentences.</p><h2 id="The-Encoder"><a href="#The-Encoder" class="headerlink" title="The Encoder"></a>The Encoder</h2><p>The encoder of a seq2seq network is a RNN that outputs some value for<br>every word from the input sentence. For every input word the encoder<br>outputs a vector and a hidden state, and uses the hidden state for the<br>next input word.</p><p>.. figure:: /_static/img/seq-seq-images/encoder-network.png<br>   :alt:</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">EncoderRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>EncoderRNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>gru <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span><span class="token punctuation">:</span>        embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>input<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        output <span class="token operator">=</span> embedded        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>gru<span class="token punctuation">(</span>output<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>        <span class="token keyword">return</span> output<span class="token punctuation">,</span> hidden    <span class="token keyword">def</span> <span class="token function">initHidden</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="The-Decoder"><a href="#The-Decoder" class="headerlink" title="The Decoder"></a>The Decoder</h2><p>The decoder is another RNN that takes the encoder output vector(s) and<br>outputs a sequence of words to create the translation.</p><p>Simple Decoder<br>^^^^^^^^^^^^^^</p><p>In the simplest seq2seq decoder we use only last output of the encoder.<br>This last output is sometimes called the <em>context vector</em> as it encodes<br>context from the entire sequence. This context vector is used as the<br>initial hidden state of the decoder.</p><p>At every step of decoding, the decoder is given an input token and<br>hidden state. The initial input token is the start-of-string <code>&lt;SOS&gt;</code><br>token, and the first hidden state is the context vector (the encoderâ€™s<br>last hidden state).</p><p>.. figure:: /_static/img/seq-seq-images/decoder-network.png<br>   :alt:</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DecoderRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>DecoderRNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>output_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>gru <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>LogSoftmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>input<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        output <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>output<span class="token punctuation">)</span>        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>gru<span class="token punctuation">(</span>output<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>output<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> output<span class="token punctuation">,</span> hidden    <span class="token keyword">def</span> <span class="token function">initHidden</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>I encourage you to train and observe the results of this model, but to<br>save space weâ€™ll be going straight for the gold and introducing the<br>Attention Mechanism.</p><p>Attention Decoder<br>^^^^^^^^^^^^^^^^^</p><p>If only the context vector is passed between the encoder and decoder,<br>that single vector carries the burden of encoding the entire sentence.</p><p>Attention allows the decoder network to â€œfocusâ€ on a different part of<br>the encoderâ€™s outputs for every step of the decoderâ€™s own outputs. First<br>we calculate a set of <em>attention weights</em>. These will be multiplied by<br>the encoder output vectors to create a weighted combination. The result<br>(called <code>attn_applied</code> in the code) should contain information about<br>that specific part of the input sequence, and thus help the decoder<br>choose the right output words.</p><p>.. figure:: <a href="https://i.imgur.com/1152PYf.png">https://i.imgur.com/1152PYf.png</a><br>   :alt:</p><p>Calculating the attention weights is done with another feed-forward<br>layer <code>attn</code>, using the decoderâ€™s input and hidden state as inputs.<br>Because there are sentences of all sizes in the training data, to<br>actually create and train this layer we have to choose a maximum<br>sentence length (input length, for encoder outputs) that it can apply<br>to. Sentences of the maximum length will use all the attention weights,<br>while shorter sentences will only use the first few.</p><p>.. figure:: /_static/img/seq-seq-images/attention-decoder-network.png<br>   :alt:</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">AttnDecoderRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> dropout_p<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span>MAX_LENGTH<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>AttnDecoderRNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size        self<span class="token punctuation">.</span>output_size <span class="token operator">=</span> output_size        self<span class="token punctuation">.</span>dropout_p <span class="token operator">=</span> dropout_p        self<span class="token punctuation">.</span>max_length <span class="token operator">=</span> max_length        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attn <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>max_length<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attn_combine <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout_p<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>gru <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>output_size<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input<span class="token punctuation">,</span> hidden<span class="token punctuation">,</span> encoder_outputs<span class="token punctuation">)</span><span class="token punctuation">:</span>        embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>input<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>embedded<span class="token punctuation">)</span>        attn_weights <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>            self<span class="token punctuation">.</span>attn<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>embedded<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        attn_applied <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>attn_weights<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                 encoder_outputs<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        output <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>embedded<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> attn_applied<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>attn_combine<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        output <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>output<span class="token punctuation">)</span>        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>gru<span class="token punctuation">(</span>output<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>        output <span class="token operator">=</span> F<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>output<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> output<span class="token punctuation">,</span> hidden<span class="token punctuation">,</span> attn_weights    <span class="token keyword">def</span> <span class="token function">initHidden</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="alert alert-info"><h4>Note</h4><p>There are other forms of attention that work around the length  limitation by using a relative position approach. Read about "local  attention" in `Effective Approaches to Attention-based Neural Machine  Translation <https: arxiv.org="" abs="" 1508.04025="">`__.</https:></p></div><h1 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h1><h2 id="Preparing-Training-Data"><a href="#Preparing-Training-Data" class="headerlink" title="Preparing Training Data"></a>Preparing Training Data</h2><p>To train, for each pair we will need an input tensor (indexes of the<br>words in the input sentence) and target tensor (indexes of the words in<br>the target sentence). While creating these vectors we will append the<br>EOS token to both sequences.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">indexesFromSentence</span><span class="token punctuation">(</span>lang<span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token punctuation">[</span>lang<span class="token punctuation">.</span>word2index<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> sentence<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token keyword">def</span> <span class="token function">tensorFromSentence</span><span class="token punctuation">(</span>lang<span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>    indexes <span class="token operator">=</span> indexesFromSentence<span class="token punctuation">(</span>lang<span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>    indexes<span class="token punctuation">.</span>append<span class="token punctuation">(</span>EOS_token<span class="token punctuation">)</span>    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>indexes<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">tensorsFromPair</span><span class="token punctuation">(</span>pair<span class="token punctuation">)</span><span class="token punctuation">:</span>    input_tensor <span class="token operator">=</span> tensorFromSentence<span class="token punctuation">(</span>input_lang<span class="token punctuation">,</span> pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    target_tensor <span class="token operator">=</span> tensorFromSentence<span class="token punctuation">(</span>output_lang<span class="token punctuation">,</span> pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token punctuation">(</span>input_tensor<span class="token punctuation">,</span> target_tensor<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Training-the-Model"><a href="#Training-the-Model" class="headerlink" title="Training the Model"></a>Training the Model</h2><p>To train we run the input sentence through the encoder, and keep track<br>of every output and the latest hidden state. Then the decoder is given<br>the <code>&lt;SOS&gt;</code> token as its first input, and the last hidden state of the<br>encoder as its first hidden state.</p><p>â€œTeacher forcingâ€ is the concept of using the real target outputs as<br>each next input, instead of using the decoderâ€™s guess as the next input.<br>Using teacher forcing causes it to converge faster but <code>when the trained network is exploited, it may exhibit instability &lt;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&amp;rep=rep1&amp;type=pdf&gt;</code>__.</p><p>You can observe outputs of teacher-forced networks that read with<br>coherent grammar but wander far from the correct translation -<br>intuitively it has learned to represent the output grammar and can â€œpick<br>upâ€ the meaning once the teacher tells it the first few words, but it<br>has not properly learned how to create the sentence from the translation<br>in the first place.</p><p>Because of the freedom PyTorchâ€™s autograd gives us, we can randomly<br>choose to use teacher forcing or not with a simple if statement. Turn<br><code>teacher_forcing_ratio</code> up to use more of it.</p><pre class="line-numbers language-python"><code class="language-python">teacher_forcing_ratio <span class="token operator">=</span> <span class="token number">0.5</span><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>input_tensor<span class="token punctuation">,</span> target_tensor<span class="token punctuation">,</span> encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">,</span> encoder_optimizer<span class="token punctuation">,</span> decoder_optimizer<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> max_length<span class="token operator">=</span>MAX_LENGTH<span class="token punctuation">)</span><span class="token punctuation">:</span>    encoder_hidden <span class="token operator">=</span> encoder<span class="token punctuation">.</span>initHidden<span class="token punctuation">(</span><span class="token punctuation">)</span>    encoder_optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    decoder_optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    input_length <span class="token operator">=</span> input_tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    target_length <span class="token operator">=</span> target_tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    encoder_outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>max_length<span class="token punctuation">,</span> encoder<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>    loss <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> ei <span class="token keyword">in</span> range<span class="token punctuation">(</span>input_length<span class="token punctuation">)</span><span class="token punctuation">:</span>        encoder_output<span class="token punctuation">,</span> encoder_hidden <span class="token operator">=</span> encoder<span class="token punctuation">(</span>            input_tensor<span class="token punctuation">[</span>ei<span class="token punctuation">]</span><span class="token punctuation">,</span> encoder_hidden<span class="token punctuation">)</span>        encoder_outputs<span class="token punctuation">[</span>ei<span class="token punctuation">]</span> <span class="token operator">=</span> encoder_output<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>    decoder_input <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>SOS_token<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>    decoder_hidden <span class="token operator">=</span> encoder_hidden    use_teacher_forcing <span class="token operator">=</span> <span class="token boolean">True</span> <span class="token keyword">if</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> teacher_forcing_ratio <span class="token keyword">else</span> <span class="token boolean">False</span>    <span class="token keyword">if</span> use_teacher_forcing<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Teacher forcing: Feed the target as the next input</span>        <span class="token keyword">for</span> di <span class="token keyword">in</span> range<span class="token punctuation">(</span>target_length<span class="token punctuation">)</span><span class="token punctuation">:</span>            decoder_output<span class="token punctuation">,</span> decoder_hidden<span class="token punctuation">,</span> decoder_attention <span class="token operator">=</span> decoder<span class="token punctuation">(</span>                decoder_input<span class="token punctuation">,</span> decoder_hidden<span class="token punctuation">,</span> encoder_outputs<span class="token punctuation">)</span>            loss <span class="token operator">+=</span> criterion<span class="token punctuation">(</span>decoder_output<span class="token punctuation">,</span> target_tensor<span class="token punctuation">[</span>di<span class="token punctuation">]</span><span class="token punctuation">)</span>            decoder_input <span class="token operator">=</span> target_tensor<span class="token punctuation">[</span>di<span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># Teacher forcing</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Without teacher forcing: use its own predictions as the next input</span>        <span class="token keyword">for</span> di <span class="token keyword">in</span> range<span class="token punctuation">(</span>target_length<span class="token punctuation">)</span><span class="token punctuation">:</span>            decoder_output<span class="token punctuation">,</span> decoder_hidden<span class="token punctuation">,</span> decoder_attention <span class="token operator">=</span> decoder<span class="token punctuation">(</span>                decoder_input<span class="token punctuation">,</span> decoder_hidden<span class="token punctuation">,</span> encoder_outputs<span class="token punctuation">)</span>            topv<span class="token punctuation">,</span> topi <span class="token operator">=</span> decoder_output<span class="token punctuation">.</span>topk<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            decoder_input <span class="token operator">=</span> topi<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># detach from history as input</span>            loss <span class="token operator">+=</span> criterion<span class="token punctuation">(</span>decoder_output<span class="token punctuation">,</span> target_tensor<span class="token punctuation">[</span>di<span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> decoder_input<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> EOS_token<span class="token punctuation">:</span>                <span class="token keyword">break</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    encoder_optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    decoder_optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> target_length<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>This is a helper function to print time elapsed and estimated time<br>remaining given the current time and progress %.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> time<span class="token keyword">import</span> math<span class="token keyword">def</span> <span class="token function">asMinutes</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>    m <span class="token operator">=</span> math<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>s <span class="token operator">/</span> <span class="token number">60</span><span class="token punctuation">)</span>    s <span class="token operator">-=</span> m <span class="token operator">*</span> <span class="token number">60</span>    <span class="token keyword">return</span> <span class="token string">'%dm %ds'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>m<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">timeSince</span><span class="token punctuation">(</span>since<span class="token punctuation">,</span> percent<span class="token punctuation">)</span><span class="token punctuation">:</span>    now <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    s <span class="token operator">=</span> now <span class="token operator">-</span> since    es <span class="token operator">=</span> s <span class="token operator">/</span> <span class="token punctuation">(</span>percent<span class="token punctuation">)</span>    rs <span class="token operator">=</span> es <span class="token operator">-</span> s    <span class="token keyword">return</span> <span class="token string">'%s (- %s)'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>asMinutes<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">,</span> asMinutes<span class="token punctuation">(</span>rs<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>The whole training process looks like this:</p><ul><li> Start a timer</li><li> Initialize optimizers and criterion</li><li> Create set of training pairs</li><li> Start empty losses array for plotting</li></ul><p>Then we call <code>train</code> many times and occasionally print the progress (%<br>of examples, time so far, estimated time) and average loss.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">trainIters</span><span class="token punctuation">(</span>encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">,</span> n_iters<span class="token punctuation">,</span> print_every<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> plot_every<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    plot_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    print_loss_total <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment" spellcheck="true"># Reset every print_every</span>    plot_loss_total <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment" spellcheck="true"># Reset every plot_every</span>    encoder_optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>encoder<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>    decoder_optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>decoder<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>    training_pairs <span class="token operator">=</span> <span class="token punctuation">[</span>tensorsFromPair<span class="token punctuation">(</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>pairs<span class="token punctuation">)</span><span class="token punctuation">)</span>                      <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n_iters<span class="token punctuation">)</span><span class="token punctuation">]</span>    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>NLLLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> iter <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n_iters <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        training_pair <span class="token operator">=</span> training_pairs<span class="token punctuation">[</span>iter <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span>        input_tensor <span class="token operator">=</span> training_pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        target_tensor <span class="token operator">=</span> training_pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        loss <span class="token operator">=</span> train<span class="token punctuation">(</span>input_tensor<span class="token punctuation">,</span> target_tensor<span class="token punctuation">,</span> encoder<span class="token punctuation">,</span>                     decoder<span class="token punctuation">,</span> encoder_optimizer<span class="token punctuation">,</span> decoder_optimizer<span class="token punctuation">,</span> criterion<span class="token punctuation">)</span>        print_loss_total <span class="token operator">+=</span> loss        plot_loss_total <span class="token operator">+=</span> loss        <span class="token keyword">if</span> iter <span class="token operator">%</span> print_every <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            print_loss_avg <span class="token operator">=</span> print_loss_total <span class="token operator">/</span> print_every            print_loss_total <span class="token operator">=</span> <span class="token number">0</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'%s (%d %d%%) %.4f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>timeSince<span class="token punctuation">(</span>start<span class="token punctuation">,</span> iter <span class="token operator">/</span> n_iters<span class="token punctuation">)</span><span class="token punctuation">,</span>                                         iter<span class="token punctuation">,</span> iter <span class="token operator">/</span> n_iters <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">,</span> print_loss_avg<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> iter <span class="token operator">%</span> plot_every <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            plot_loss_avg <span class="token operator">=</span> plot_loss_total <span class="token operator">/</span> plot_every            plot_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>plot_loss_avg<span class="token punctuation">)</span>            plot_loss_total <span class="token operator">=</span> <span class="token number">0</span>    showPlot<span class="token punctuation">(</span>plot_losses<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Plotting-results"><a href="#Plotting-results" class="headerlink" title="Plotting results"></a>Plotting results</h2><p>Plotting is done with matplotlib, using the array of loss values<br><code>plot_losses</code> saved while training.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>switch_backend<span class="token punctuation">(</span><span class="token string">'agg'</span><span class="token punctuation">)</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>ticker <span class="token keyword">as</span> ticker<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">def</span> <span class="token function">showPlot</span><span class="token punctuation">(</span>points<span class="token punctuation">)</span><span class="token punctuation">:</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>    fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># this locator puts ticks at regular intervals</span>    loc <span class="token operator">=</span> ticker<span class="token punctuation">.</span>MultipleLocator<span class="token punctuation">(</span>base<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>    ax<span class="token punctuation">.</span>yaxis<span class="token punctuation">.</span>set_major_locator<span class="token punctuation">(</span>loc<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>points<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h1><p>Evaluation is mostly the same as training, but there are no targets so<br>we simply feed the decoderâ€™s predictions back to itself for each step.<br>Every time it predicts a word we add it to the output string, and if it<br>predicts the EOS token we stop there. We also store the decoderâ€™s<br>attention outputs for display later.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">,</span> sentence<span class="token punctuation">,</span> max_length<span class="token operator">=</span>MAX_LENGTH<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        input_tensor <span class="token operator">=</span> tensorFromSentence<span class="token punctuation">(</span>input_lang<span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>        input_length <span class="token operator">=</span> input_tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        encoder_hidden <span class="token operator">=</span> encoder<span class="token punctuation">.</span>initHidden<span class="token punctuation">(</span><span class="token punctuation">)</span>        encoder_outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>max_length<span class="token punctuation">,</span> encoder<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>        <span class="token keyword">for</span> ei <span class="token keyword">in</span> range<span class="token punctuation">(</span>input_length<span class="token punctuation">)</span><span class="token punctuation">:</span>            encoder_output<span class="token punctuation">,</span> encoder_hidden <span class="token operator">=</span> encoder<span class="token punctuation">(</span>input_tensor<span class="token punctuation">[</span>ei<span class="token punctuation">]</span><span class="token punctuation">,</span>                                                     encoder_hidden<span class="token punctuation">)</span>            encoder_outputs<span class="token punctuation">[</span>ei<span class="token punctuation">]</span> <span class="token operator">+=</span> encoder_output<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>        decoder_input <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>SOS_token<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># SOS</span>        decoder_hidden <span class="token operator">=</span> encoder_hidden        decoded_words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        decoder_attentions <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>max_length<span class="token punctuation">,</span> max_length<span class="token punctuation">)</span>        <span class="token keyword">for</span> di <span class="token keyword">in</span> range<span class="token punctuation">(</span>max_length<span class="token punctuation">)</span><span class="token punctuation">:</span>            decoder_output<span class="token punctuation">,</span> decoder_hidden<span class="token punctuation">,</span> decoder_attention <span class="token operator">=</span> decoder<span class="token punctuation">(</span>                decoder_input<span class="token punctuation">,</span> decoder_hidden<span class="token punctuation">,</span> encoder_outputs<span class="token punctuation">)</span>            decoder_attentions<span class="token punctuation">[</span>di<span class="token punctuation">]</span> <span class="token operator">=</span> decoder_attention<span class="token punctuation">.</span>data            topv<span class="token punctuation">,</span> topi <span class="token operator">=</span> decoder_output<span class="token punctuation">.</span>data<span class="token punctuation">.</span>topk<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> topi<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> EOS_token<span class="token punctuation">:</span>                decoded_words<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'&lt;EOS>'</span><span class="token punctuation">)</span>                <span class="token keyword">break</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                decoded_words<span class="token punctuation">.</span>append<span class="token punctuation">(</span>output_lang<span class="token punctuation">.</span>index2word<span class="token punctuation">[</span>topi<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            decoder_input <span class="token operator">=</span> topi<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> decoded_words<span class="token punctuation">,</span> decoder_attentions<span class="token punctuation">[</span><span class="token punctuation">:</span>di <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>We can evaluate random sentences from the training set and print out the<br>input, target, and output to make some subjective quality judgements:</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">evaluateRandomly</span><span class="token punctuation">(</span>encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>        pair <span class="token operator">=</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>pairs<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'>'</span><span class="token punctuation">,</span> pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'='</span><span class="token punctuation">,</span> pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        output_words<span class="token punctuation">,</span> attentions <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">,</span> pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        output_sentence <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>output_words<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'&lt;'</span><span class="token punctuation">,</span> output_sentence<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="Training-and-Evaluating"><a href="#Training-and-Evaluating" class="headerlink" title="Training and Evaluating"></a>Training and Evaluating</h1><p>With all these helper functions in place (it looks like extra work, but<br>it makes it easier to run multiple experiments) we can actually<br>initialize a network and start training.</p><p>Remember that the input sentences were heavily filtered. For this small<br>dataset we can use relatively small networks of 256 hidden nodes and a<br>single GRU layer. After about 40 minutes on a MacBook CPU weâ€™ll get some<br>reasonable results.</p><p>.. Note::<br>   If you run this notebook you can train, interrupt the kernel,<br>   evaluate, and continue training later. Comment out the lines where the<br>   encoder and decoder are initialized and run <code>trainIters</code> again.</p><pre class="line-numbers language-python"><code class="language-python">hidden_size <span class="token operator">=</span> <span class="token number">20</span>encoder1 <span class="token operator">=</span> EncoderRNN<span class="token punctuation">(</span>input_lang<span class="token punctuation">.</span>n_words<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>attn_decoder1 <span class="token operator">=</span> AttnDecoderRNN<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_lang<span class="token punctuation">.</span>n_words<span class="token punctuation">,</span> dropout_p<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>trainIters<span class="token punctuation">(</span>encoder1<span class="token punctuation">,</span> attn_decoder1<span class="token punctuation">,</span> <span class="token number">75000</span><span class="token punctuation">,</span> print_every<span class="token operator">=</span><span class="token number">5000</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>2m 24s (- 33m 37s) (5000 6%) 3.37745m 0s (- 32m 31s) (10000 13%) 2.86507m 36s (- 30m 26s) (15000 20%) 2.736810m 9s (- 27m 56s) (20000 26%) 2.655212m 38s (- 25m 17s) (25000 33%) 2.582015m 17s (- 22m 55s) (30000 40%) 2.538217m 50s (- 20m 23s) (35000 46%) 2.521520m 30s (- 17m 57s) (40000 53%) 2.459122m 51s (- 15m 14s) (45000 60%) 2.425925m 22s (- 12m 41s) (50000 66%) 2.362327m 50s (- 10m 7s) (55000 73%) 2.340230m 22s (- 7m 35s) (60000 80%) 2.308033m 3s (- 5m 5s) (65000 86%) 2.272235m 38s (- 2m 32s) (70000 93%) 2.276438m 20s (- 0m 0s) (75000 100%) 2.2802</code></pre><pre class="line-numbers language-python"><code class="language-python">evaluateRandomly<span class="token punctuation">(</span>encoder1<span class="token punctuation">,</span> attn_decoder1<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>&gt; il s en met plein les poches .= he s raking it in .&lt; he s always to the . . &lt;EOS&gt;&gt; je suis en train de griller du poisson .= i am grilling fish .&lt; i m a . . &lt;EOS&gt;&gt; c est un mannequin .= she s a model .&lt; he s a nice . &lt;EOS&gt;&gt; il n est pas un saint .= he s no saint .&lt; he s not a . . &lt;EOS&gt;&gt; je n abandonne pas .= i m not giving up .&lt; i m not alone . &lt;EOS&gt;&gt; vous etes jeunes .= you re young .&lt; you re a . &lt;EOS&gt;&gt; il fait un super boulot .= he is doing a super job .&lt; he s a to of . . &lt;EOS&gt;&gt; tu es trop maigre .= you re too skinny .&lt; you re very busy . &lt;EOS&gt;&gt; je ne suis pas intimide .= i m not intimidated .&lt; i m not alone . &lt;EOS&gt;&gt; il est plus fort que moi .= he s stronger than me .&lt; he s not as . &lt;EOS&gt;</code></pre><p>â€‹    </p><h2 id="Visualizing-Attention"><a href="#Visualizing-Attention" class="headerlink" title="Visualizing Attention"></a>Visualizing Attention</h2><p>A useful property of the attention mechanism is its highly interpretable<br>outputs. Because it is used to weight specific encoder outputs of the<br>input sequence, we can imagine looking where the network is focused most<br>at each time step.</p><p>You could simply run <code>plt.matshow(attentions)</code> to see attention output<br>displayed as a matrix, with the columns being input steps and rows being<br>output steps:</p><pre class="line-numbers language-python"><code class="language-python">output_words<span class="token punctuation">,</span> attentions <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>    encoder1<span class="token punctuation">,</span> attn_decoder1<span class="token punctuation">,</span> <span class="token string">"je suis trop froid ."</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>matshow<span class="token punctuation">(</span>attentions<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>&lt;matplotlib.image.AxesImage at 0x7f68d8ef77b8&gt;</code></pre><p>For a better viewing experience we will do the extra work of adding axes<br>and labels:</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">showAttention</span><span class="token punctuation">(</span>input_sentence<span class="token punctuation">,</span> output_words<span class="token punctuation">,</span> attentions<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># Set up figure with colorbar</span>    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>    ax <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">111</span><span class="token punctuation">)</span>    cax <span class="token operator">=</span> ax<span class="token punctuation">.</span>matshow<span class="token punctuation">(</span>attentions<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'bone'</span><span class="token punctuation">)</span>    fig<span class="token punctuation">.</span>colorbar<span class="token punctuation">(</span>cax<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Set up axes</span>    ax<span class="token punctuation">.</span>set_xticklabels<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">''</span><span class="token punctuation">]</span> <span class="token operator">+</span> input_sentence<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span> <span class="token operator">+</span>                       <span class="token punctuation">[</span><span class="token string">'&lt;EOS>'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> rotation<span class="token operator">=</span><span class="token number">90</span><span class="token punctuation">)</span>    ax<span class="token punctuation">.</span>set_yticklabels<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">''</span><span class="token punctuation">]</span> <span class="token operator">+</span> output_words<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Show label at every tick</span>    ax<span class="token punctuation">.</span>xaxis<span class="token punctuation">.</span>set_major_locator<span class="token punctuation">(</span>ticker<span class="token punctuation">.</span>MultipleLocator<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ax<span class="token punctuation">.</span>yaxis<span class="token punctuation">.</span>set_major_locator<span class="token punctuation">(</span>ticker<span class="token punctuation">.</span>MultipleLocator<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">evaluateAndShowAttention</span><span class="token punctuation">(</span>input_sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>    output_words<span class="token punctuation">,</span> attentions <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>        encoder1<span class="token punctuation">,</span> attn_decoder1<span class="token punctuation">,</span> input_sentence<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'input ='</span><span class="token punctuation">,</span> input_sentence<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output ='</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>output_words<span class="token punctuation">)</span><span class="token punctuation">)</span>    showAttention<span class="token punctuation">(</span>input_sentence<span class="token punctuation">,</span> output_words<span class="token punctuation">,</span> attentions<span class="token punctuation">)</span>evaluateAndShowAttention<span class="token punctuation">(</span><span class="token string">"elle a cinq ans de moins que moi ."</span><span class="token punctuation">)</span>evaluateAndShowAttention<span class="token punctuation">(</span><span class="token string">"elle est trop petit ."</span><span class="token punctuation">)</span>evaluateAndShowAttention<span class="token punctuation">(</span><span class="token string">"je ne crains pas de mourir ."</span><span class="token punctuation">)</span>evaluateAndShowAttention<span class="token punctuation">(</span><span class="token string">"c est un jeune directeur plein de talent ."</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>input = elle a cinq ans de moins que moi .output = she is always to of as me . &lt;EOS&gt;input = elle est trop petit .output = she is very nice . &lt;EOS&gt;input = je ne crains pas de mourir .output = i m not going to . . &lt;EOS&gt;input = c est un jeune directeur plein de talent .output = he s a a man . &lt;EOS&gt;</code></pre><h1 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h1><ul><li><p>Try with a different dataset</p><ul><li> Another language pair</li><li> Human â†’ Machine (e.g. IOT commands)</li><li> Chat â†’ Response</li><li> Question â†’ Answer</li></ul></li><li><p>Replace the embeddings with pre-trained word embeddings such as word2vec or<br> GloVe</p></li><li><p>Try with more layers, more hidden units, and more sentences. Compare<br> the training time and results.</p></li><li><p>If you use a translation file where pairs have two of the same phrase<br> (<code>I am test \t I am test</code>), you can use this as an autoencoder. Try<br> this:</p><ul><li> Train as an autoencoder</li><li> Save only the Encoder network</li><li> Train a new Decoder for translation from there</li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> è®ºæ–‡å¤ç° </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>sshè¿œç¨‹è¿æ¥æœåŠ¡å™¨</title>
      <link href="/year/09/21/004/"/>
      <url>/year/09/21/004/</url>
      
        <content type="html"><![CDATA[<p>â€‹    æœ¬æ–‡ç®€å•ä»‹ç»sshè¿œç¨‹è¿æ¥å®éªŒå®¤æœåŠ¡å™¨çš„æ­¥éª¤ï¼Œè¸©å‘è®¸å¤šï¼Œå¾ˆå¤šåŸç†ä¾æ—§ä¸æ‡‚ï¼Œä½†æœ€åå®ç°:</p><ul><li>è¿æ¥å®éªŒå®¤ç½‘ç»œåå†…ç½‘è¿æ¥è¿œç¨‹æœåŠ¡å™¨åŠŸèƒ½</li><li>é…ç½®æœ¬åœ°å¯†é’¥å’Œè¿œç¨‹æœåŠ¡å™¨ç”¨æˆ·å¯†é’¥ä½¿å…¶å…å¯†é’¥åŠŸèƒ½</li><li>2021/09/25æ›´æ–°ï¼šå®ç°å¤–ç½‘è¿æ¥å®éªŒå®¤æœåŠ¡å™¨çš„åŠŸèƒ½</li></ul><h5 id="1-å®ç°è¿œç¨‹è¿æ¥æœåŠ¡å™¨"><a href="#1-å®ç°è¿œç¨‹è¿æ¥æœåŠ¡å™¨" class="headerlink" title="1.å®ç°è¿œç¨‹è¿æ¥æœåŠ¡å™¨"></a>1.å®ç°è¿œç¨‹è¿æ¥æœåŠ¡å™¨</h5><h6 id="1-æœ¬åœ°æœåŠ¡å‡†å¤‡"><a href="#1-æœ¬åœ°æœåŠ¡å‡†å¤‡" class="headerlink" title="1.æœ¬åœ°æœåŠ¡å‡†å¤‡"></a>1.æœ¬åœ°æœåŠ¡å‡†å¤‡</h6><p>æœ¬åœ°ä¸»æœºä¸Šæ‰“å¼€windows terminalçª—å£(ç°åœ¨çš„windowsä¸€èˆ¬ä¼šè‡ªåŠ¨å®‰è£…openSSHå®¢æˆ·ç«¯å’ŒæœåŠ¡ç«¯),æ‰§è¡Œå‘½ä»¤ï¼š</p><pre class="line-numbers language-none"><code class="language-none">ssh-keygen -t rsa<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>æ‰§è¡Œå‘½ä»¤åä¼šåœ¨<code>.ssh</code>æ–‡ä»¶ä¸‹ç”Ÿæˆä¸¤ä¸ªå¯†é’¥ï¼Œ<code>id_rsa</code>å’Œ<code>id_rsa.pub</code>ä¸€ä¸ªç§é’¥ä¸€ä¸ªå…¬é’¥;å®ç°è¿œç¨‹è¿æ¥æœåŠ¡å™¨å…³é”®æ˜¯æŠŠ<strong>å…¬é’¥</strong>å­˜æ”¾åˆ°è¿œç¨‹æœåŠ¡å™¨ç«¯</p><h6 id="2-é…ç½®æœ¬åœ°configæ–‡ä»¶"><a href="#2-é…ç½®æœ¬åœ°configæ–‡ä»¶" class="headerlink" title="2.é…ç½®æœ¬åœ°configæ–‡ä»¶"></a>2.é…ç½®æœ¬åœ°configæ–‡ä»¶</h6><h6 id="3-å°†æœ¬åœ°å…¬é’¥ä¸Šä¼ è‡³æœåŠ¡å™¨"><a href="#3-å°†æœ¬åœ°å…¬é’¥ä¸Šä¼ è‡³æœåŠ¡å™¨" class="headerlink" title="3.å°†æœ¬åœ°å…¬é’¥ä¸Šä¼ è‡³æœåŠ¡å™¨"></a>3.å°†æœ¬åœ°å…¬é’¥ä¸Šä¼ è‡³æœåŠ¡å™¨</h6><p>åœ¨windows terminalä¸‹æ‰§è¡Œå‘½ä»¤</p><pre class="line-numbers language-none"><code class="language-none">scp C:\Users\VrShadow\.ssh\id_rsa.pub XXX@192.168.0.75:\home\xxx\<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>æœ¬åœ°å…¬é’¥æ‹·è´è‡³è¿œç¨‹æœåŠ¡å™¨[æ³¨æ„xxxæ›´æ”¹ä¸ºè‡ªå·±åœ¨è¿œç¨‹æœåŠ¡å™¨ç«¯åˆ†é…çš„ç”¨æˆ·åï¼ï¼ï¼],æ­¤æ—¶ä¼ è¿‡æ¥çš„å…¬é’¥å­˜åœ¨<code>./home/xxx</code>ä¸‹</p><h6 id="4-å…¬é’¥å†™å…¥æˆæƒæ–‡ä»¶"><a href="#4-å…¬é’¥å†™å…¥æˆæƒæ–‡ä»¶" class="headerlink" title="4.å…¬é’¥å†™å…¥æˆæƒæ–‡ä»¶"></a>4.å…¬é’¥å†™å…¥æˆæƒæ–‡ä»¶</h6><p>åœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Šæ‰§è¡Œå‘½ä»¤</p><pre class="line-numbers language-none"><code class="language-none">touch ./.ssh/authorized_keys<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>è¿œç¨‹æœåŠ¡å™¨ç«¯è¿™è¾¹ç”¨çš„æ˜¯linuxç³»ç»Ÿï¼Œæ‰€ä»¥å…ˆè¦åˆ›å»ºæ–‡ä»¶<code>authorized_keys</code></p><p>å°†æœ¬åœ°ä¼ è¿‡æ¥çš„å¯†é’¥<strong>å†™å…¥authorizd_keys</strong>ä¸­</p><pre class="line-numbers language-none"><code class="language-none">cat ./home/xxx/id_rsa.pub >> ./.ssh/authorized_keys<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="2-vscodeå…å¯†ç™»å½•"><a href="#2-vscodeå…å¯†ç™»å½•" class="headerlink" title="2.vscodeå…å¯†ç™»å½•"></a>2.vscodeå…å¯†ç™»å½•</h5><h6 id="1-å‡†å¤‡æ’ä»¶SSH"><a href="#1-å‡†å¤‡æ’ä»¶SSH" class="headerlink" title="1.å‡†å¤‡æ’ä»¶SSH"></a>1.å‡†å¤‡æ’ä»¶SSH</h6><p>åœ¨æ’ä»¶é‡Œæœç´¢å®‰è£…å³å¯</p><h6 id="2-ä¿®æ”¹æœ¬åœ°configé…ç½®æ–‡ä»¶"><a href="#2-ä¿®æ”¹æœ¬åœ°configé…ç½®æ–‡ä»¶" class="headerlink" title="2.ä¿®æ”¹æœ¬åœ°configé…ç½®æ–‡ä»¶"></a>2.ä¿®æ”¹æœ¬åœ°configé…ç½®æ–‡ä»¶</h6><p>æœ¬åœ°configæ–‡ä»¶é‡Œé¢åŠ å…¥<strong>â€IdentifyFileâ€ â€C:\Users\VrShadow.ssh\id_rsaâ€</strong></p><p>å®Œæˆä¹‹åä¾§è¾¹å¯¼èˆªæ ä¼šå‡ºç°è¿œç¨‹èµ„æºç®¡ç†å™¨å›¾æ ‡ï¼Œç‚¹å‡»ä¹‹åé€‰æ‹©è¿œç¨‹æœåŠ¡å™¨æ—¶å¯¹åº”çš„ç«¯å£ä¸‹çš„åˆ†æ”¯ç”¨æˆ·ï¼Œç‚¹å‡»å°±ä¼šå¼€å¯æ–°çš„çª—å£(ç¬¬ä¸€æ¬¡ä¼šè®©ä½ é€‰æ‹©è¿œç¨‹æœåŠ¡å™¨çš„æ“ä½œç³»ç»Ÿ)ï¼Œä¹‹åå°±ä¼šè¿›å…¥å¯¹åº”ç”¨æˆ·ä¸‹çš„ç›®å½•è¿›è¡Œå·¥ä½œã€‚</p><h5 id="3-å¤–ç½‘è¿œç¨‹è¿æ¥"><a href="#3-å¤–ç½‘è¿œç¨‹è¿æ¥" class="headerlink" title="3.å¤–ç½‘è¿œç¨‹è¿æ¥"></a>3.å¤–ç½‘è¿œç¨‹è¿æ¥</h5><p>è‡ªå·±çš„æœ¬åœ°ç”¨æˆ·<code>.ssh</code>æ–‡ä»¶é‡Œé¢å·²ç»é…ç½®äº†<strong>config</strong>æ–‡ä»¶ï¼Œå·²ç»é…ç½®äº†jumpå†…ç½‘æƒé™<br>å‘½ä»¤è¡Œæ‰§è¡Œï¼š</p><pre class="line-numbers language-none"><code class="language-none">ssh jumpnone<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>æ‰§è¡Œåéœ€è¦è¿œç¨‹æœåŠ¡å™¨çš„å¯†ç ï¼š********</p><p>è¾“å…¥å¯†ç åè¿›è¡Œè¿œç¨‹è¿æ¥æ“ä½œ</p><pre class="line-numbers language-none"><code class="language-none">ssh username@host<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>å¦‚æœæœ¬åœ°ç”¨æˆ·åå’Œè¿œç¨‹ç”¨æˆ·åä¸€è‡´,ç™»å½•æ—¶å¯ä»¥çœç•¥ç”¨æˆ·å</p><pre class="line-numbers language-none"><code class="language-none">ssh host<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>SSHçš„é»˜è®¤ç«¯å£æ˜¯22,ä¹Ÿå°±æ˜¯è¯´ä½ çš„ç™»å½•è¯·æ±‚ä¼šé€è¿›è¿œç¨‹ä¸»æœºçš„22ç«¯å£.ä½¿ç”¨<code>-p</code>å‚æ•°å¯ä»¥ä¿®æ”¹ç«¯å£</p><pre><code>ssh -p 2222 user@host  # æ­¤æ¡å‘½ä»¤è¡¨ç¤ºsshç›´æ¥è¿æ¥è¿œç¨‹ä¸»æœºçš„2222ç«¯å£</code></pre><p>æˆ‘å†™çš„æ¯”è¾ƒç²—ç³™,(å·ä¸ªæ‡’)å¯ä»¥å‚è€ƒæˆ‘æœ‹å‹çš„blogï¼š</p><blockquote><p><a href="https://lry89757.github.io/2021/09/24/linux-bi-ji/">æœ‹å‹çš„åšå®¢</a></p></blockquote><p>ã€æœ€åçš„å®éªŒå°±æ˜¯å¦‚ä¸‹çš„æ•ˆæœ:</p><ul><li><p>è¿æ¥å¤–ç½‘çš„æƒ…å†µä¸‹</p><h5 id="è¿æ¥æœåŠ¡å™¨"><a href="#è¿æ¥æœåŠ¡å™¨" class="headerlink" title="è¿æ¥æœåŠ¡å™¨"></a>è¿æ¥æœåŠ¡å™¨</h5><pre><code># ä¸¤ç§æ–¹æ³•ï¼š(åœ¨å·²ç»é…ç½®å¥½confiå’Œå…¬é’¥æ–‡ä»¶ä¸‹å¹¶ä¸”æ‰“å¼€jumpè·³æ¿å’Œå¼€å¯â€œIdentiyfile"ä¸‹)ssh 43004   # å¿…é¡»è¦æ‰“å¼€è·³æ¿æƒé™,è€Œä¸”å›è½¦åæ¯æ¬¡éƒ½è¦è¾“å…¥æœåŠ¡å™¨æ‰€åœ¨å…¬ç½‘åœ°å€çš„å¯†ç             # å½“ç„¶åˆ†é…ç»™user@hostsçš„å¯†ç è¦çœ‹ä½ æ˜¯å¦æ³¨é‡Šäº†å…¬é’¥ssh gyf@192.168.0.75 # è¿™æ ·è®¿é—®åœ¨å†…ç½‘ä¸‹ä½¿ç”¨ï¼Œå½“ç„¶å†…ç½‘ä¸‹ä¹Ÿå¯ä»¥ä½¿ç”¨ssh 43004è¿æ¥æœåŠ¡å™¨</code></pre><ul><li><h5 id="å¤–ç½‘è®¿é—®"><a href="#å¤–ç½‘è®¿é—®" class="headerlink" title="å¤–ç½‘è®¿é—®"></a>å¤–ç½‘è®¿é—®</h5><ul><li><strong>ssh 43004</strong>:éœ€è¦è¾“å…¥æœåŠ¡å™¨æ‰€åœ¨å…¬ç½‘åœ°å€å¯†ç å’Œåˆ†é…ç»™ç”¨æˆ·çš„å¯†ç </li><li><strong>ssh user@host</strong>:ä¸èƒ½è¿æ¥æœåŠ¡å™¨</li></ul></li><li><h5 id="å†…ç½‘è®¿é—®"><a href="#å†…ç½‘è®¿é—®" class="headerlink" title="å†…ç½‘è®¿é—®"></a>å†…ç½‘è®¿é—®</h5><ul><li><strong>ssh 43004</strong>:ä»ç„¶éœ€è¦è¾“å…¥æœåŠ¡å™¨æ‰€åœ¨å…¬ç½‘åœ°å€å¯†ç ä½†æ˜¯ä¸ç”¨è¾“å…¥åˆ†é…ç»™ç”¨æˆ·çš„å¯†ç äº†</li><li><strong>ssh user@host</strong>:è¿™æ ·å…¬ç½‘å¯†ç å’Œåˆ†é…ç»™ç”¨æˆ·çš„å¯†ç éƒ½ä¸ç”¨è¾“å…¥äº†ç›´æ¥è¿æ¥</li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> æ­å»ºç¯å¢ƒ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> windows terminal </tag>
            
            <tag> ssh </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è®ºæ–‡é˜…è¯»ä¸€:Attention Mechanism</title>
      <link href="/year/09/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB(%E4%B8%80)/"/>
      <url>/year/09/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB(%E4%B8%80)/</url>
      
        <content type="html"><![CDATA[<h4 id="Abstract-amp-amp-Introduction"><a href="#Abstract-amp-amp-Introduction" class="headerlink" title="Abstract &amp;&amp; Introduction"></a>Abstract &amp;&amp; Introduction</h4><p>â€‹    è¿™å‡ å¤©é˜…è¯»äº†ä¸€ç¯‡è¾ƒæ—©æå‡ºAttention machanismçš„è®ºæ–‡<a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a>,è¿™ç¯‡è®ºæ–‡å°†æ³¨æ„åŠ›æœºåˆ¶åº”ç”¨åœ¨ç¥ç»ç½‘ç»œç¿»è¯‘ä¸­ï¼Œè®ºæ–‡çš„æ€è·¯ä»ä¼ ç»ŸNMT(Neural Machine Translation)ç³»ç»Ÿçš„ç¼ºé™·è¯´èµ·ï¼Œé’ˆå¯¹å…¶è¿›è¡Œæ”¹è¿›ï¼Œæœ€åè¿›è¡Œäº†å®šé‡å’Œå®šæ€§åˆ†æ.</p><p>â€‹    é¦–å…ˆæˆ‘ä»¬è¦äº†è§£ç»å…¸çš„Sea2Seqæ¨¡å‹æ˜¯å¦‚ä½•è¿›è¡Œç¿»è¯‘çš„ï¼šæ•´ä½“æ¨¡å‹é‡‡ç”¨Encoder-Decoderè¿›è¡Œåˆ†æï¼Œå°†è¾“å…¥çš„åºåˆ—ç»è¿‡Encoderå¤„ç†ï¼Œå‹ç¼©æˆä¸€ä¸ªFixed-length Vectorï¼›åœ¨Decoderé˜¶æ®µï¼Œå°†è¿™ä¸ªå‘é‡çš„ä¿¡æ¯è¿˜åŸæˆä¸€ä¸ªåºåˆ—å®Œæˆç¿»è¯‘ä»»åŠ¡ã€‚åŸºäºRNNçš„Seq2Seqæ¨¡å‹ä¸»è¦ç”±ä¸¤ç¯‡æ–‡ç« ä»‹ç»ï¼Œåªæ˜¯é‡‡ç”¨äº†ä¸åŒçš„RNNæ¨¡å‹ã€‚Ilya Sutskeverç­‰äºº2014å¹´åœ¨è®ºæ–‡ã€ŠSequence to Sequence Learning with Neural Networksã€‹ä¸­ä½¿ç”¨LSTMæ¥æ­å»ºSeq2Seqæ¨¡å‹ã€‚éšåï¼Œ2015å¹´ï¼ŒKyunghyun Choç­‰äººåœ¨è®ºæ–‡ã€ŠLearning Phrase Representations using RNN Encoderâ€“Decoder for Statistical Machine Translationã€‹æå‡ºäº†åŸºäºGRUçš„Seq2Seqæ¨¡å‹ã€‚æƒ³è¦è§£å†³çš„ä¸»è¦é—®é¢˜å°±æ˜¯å¦‚ä½•æŠŠæœºå™¨ç¿»è¯‘ä¸­ï¼Œå˜é•¿çš„è¾“å…¥Xæ˜ å°„åˆ°ä¸€ä¸ªå˜é•¿è¾“å‡ºYã€‚è€Œè¿™ç¯‡è®ºæ–‡æå‡ºä¸€ç§æ–°çš„æ–¹æ³•ï¼Œè¿™ä¸ªæ–¹æ³•ä¹Ÿæ˜¯åŸºäº<code>encoder-decoder</code>çš„ï¼Œä¸ä¹‹å‰çš„<code>encoder-decoder</code>æ¨¡å‹ä¸åŒçš„æ˜¯ï¼Œæ¯æ¬¡åœ¨ç¿»è¯‘ä¸€ä¸ªå•è¯çš„æ—¶å€™ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨æœå¯»è¯¥å•è¯ä¸æºå¥å­å“ªäº›å•è¯æœ‰å…³è”ï¼Œå¹¶å°†è¿™ç§å…³è”çš„å¼ºåº¦è¿›è¡Œæ•°å­—åŒ–è¡¨ç¤º(åœ¨æ¨¡å‹ä¸­å°±æ˜¯æƒé‡)ï¼Œå¹¶ä¸”è®­ç»ƒå¾—å‡ºè¿™ç§æ–¹æ³•å¯ä»¥è§£å†³å¥å­ç¿»è¯‘ä¸å‡†çš„é—®é¢˜ã€‚</p><h4 id="ä¼ ç»ŸRNN"><a href="#ä¼ ç»ŸRNN" class="headerlink" title="ä¼ ç»ŸRNN"></a>ä¼ ç»ŸRNN</h4><p>â€‹    å¤§éƒ¨åˆ†çš„ç¥ç»æœºå™¨ç¿»è¯‘éƒ½æ˜¯åŸºäº<code>encoder-decoder</code>æ¡†æ¶çš„å¹¶ä¸”éƒ½ä¼šå°†æºè¯­è¨€å¥å­åºåˆ—å‹ç¼©æˆä¸€ä¸ªå›ºå®šçš„å‘é‡ï¼Œç„¶åä¼ é€’ç»™decoderã€‚ä¼ ç»Ÿçš„RNN Encoder-Decoderæ¨¡å‹åœ¨è®­ç»ƒé˜¶æ®µæ—¶å€™ï¼Œä¼šä½¿æ¨¡å‹å»æœ€å¤§åŒ–æºè¯­è¨€ç¿»è¯‘æˆç›®æ ‡è¯­è¨€çš„æ¡ä»¶æ¦‚ç‡ã€‚å½“æ¨¡å‹è®­ç»ƒå¥½ä¹‹åï¼Œå½“ä»£ç¿»è¯‘çš„æºè¯­è¨€å¥å­æ”¾å…¥åˆ°æ¨¡å‹ä¸­åï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨è®¡ç®—æœ€å¤§ç›®æ ‡å¥å­çš„æ¦‚ç‡å¹¶ä¸”å°†è¿™ä¸ªå¥å­å½“ä½œæ˜¯ç¿»è¯‘åçš„å¥å­ã€‚ç®€å•ä»‹ç»ä»¥ä¸‹ä¼ ç»Ÿçš„RNN:</p><p><img src="https://s2.loli.net/2021/12/23/qwz1MDimjBKYVfI.png"></p><p>ä¸Šå›¾ä¸­<code>C</code>çš„å·¦ä¾§æ˜¯<code>Encoder</code>,å³ä¾§æ˜¯<code>Decoder</code>,â€Câ€æ˜¯å¾…ç¿»è¯‘è¯­å¥çš„è¯­ä¹‰ä¿¡æ¯ï¼›è¾“å…¥ä¸€ä¸ªå¥å­çš„æ—¶å€™ä¼šç»è¿‡Encoderï¼ŒEncoderè®²è¿™å¥è¯è¿›è¡Œç¼–ç ï¼ŒEncoderç”¨åˆ°çš„æ¨¡å‹æ˜¯RNNï¼Œç¼–ç ç»“æŸä»¥åå°†æœ€åä¸€ä¸ªæ—¶åˆ»RNNçš„éšå±‚çš„è¾“å‡ºå½“ä½œè¾“å…¥çš„è¿™å¥è¯çš„â€è¯­ä¹‰å‹ç¼©â€ã€‚ç„¶åè§£ç å™¨æ¯äº§ç”Ÿä¸€ä¸ªç¿»è¯‘åçš„è‹±æ–‡å•è¯çš„æ—¶å€™ï¼Œéƒ½ä¼šåˆ©ç”¨<strong>C</strong>å¹¶ä¸”è¿˜ä¼šæ¥å—è¾“å…¥tæ—¶åˆ»çš„ä¸Šä¸€ä¸ªéšè—å‘é‡<strong>s</strong>ã€‚è¿™ä¸ªæ—¶åˆ»çš„è¾“å‡ºç«¯å°±ä¼šäº§ç”Ÿç¬¬ä¸€ä¸ªå•è¯(è¿™é‡Œä½¿ç”¨äº†softmaxå‡½æ•°ï¼Œè¾“å‡ºå±‚æ˜¯ä¸€ä¸ªè¯å…¸å¤§å°ç»´åº¦çš„å‘é‡)ï¼Œå“ªä¸ªç»´åº¦çš„å€¼æœ€å¤§å°±å–å“ªä¸ªç»´åº¦æ‰€å¯¹åº”çš„å•è¯ã€‚å¤§å®¶å¯ä»¥æ˜ç™½çš„æ˜¯è®­ç»ƒé˜¶æ®µï¼ŒEncoderå’ŒDecoderä¸å¯èƒ½ç«‹é©¬äº§ç”Ÿç›®æ ‡å•è¯ï¼Œè€Œæ˜¯äº§ç”Ÿä¸€ä¸ªé¢„æµ‹ç»“æœï¼Œè®­ç»ƒçš„ç›®çš„å°±æ˜¯ä¸æ–­ä¼˜åŒ–å‚æ•°ã€‚</p><h4 id="Attentionæœºåˆ¶åŠ å…¥"><a href="#Attentionæœºåˆ¶åŠ å…¥" class="headerlink" title="Attentionæœºåˆ¶åŠ å…¥"></a>Attentionæœºåˆ¶åŠ å…¥</h4><p>æœ¬paperæå‡ºçš„æ¨¡å‹å«åš<strong>RNNsearch</strong>ï¼š</p><p><img src="https://s6.jpg.cm/2021/12/23/LbozvD.png"></p><p>â€‹    å›¾ä¸­çš„å³åŠéƒ¨åˆ†æ˜¯encoderï¼Œè¿™ä¸€éƒ¨åˆ†å’ŒRNNencæ¨¡å‹ä¸€æ ·ï¼Œé‡ç‚¹åœ¨decoderéƒ¨åˆ†å’Œä¼ ç»Ÿçš„ä¼šæœ‰å·¨å¤§çš„å·®åˆ«ï¼›åœ¨t=0æ—¶åˆ»ï¼Œdecoderçš„BiLSTMæ¥å—ä¸‰ä¸ªè¾“å…¥ï¼Œç¬¬ä¸€ä¸ªæ˜¯åˆå§‹çŠ¶æ€s0(è¿™ä¸ªæ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œæ— è®ºæ˜¯è®­ç»ƒé˜¶æ®µè¿˜æ˜¯é¢„æµ‹é˜¶æ®µéƒ½æ˜¯éšæœº)ï¼›ç¬¬äºŒä¸ªè¾“å…¥æ¥æºäºemdeddingåçš„å‘é‡ï¼›ç¬¬ä¸‰ä¸ªè¾“å…¥æ¯”è¾ƒå¤æ‚ï¼Œä¹Ÿæ˜¯æ–°æ¨¡å‹çš„æ ¸å¿ƒåˆ›æ–°ç‚¹</p><p>â€‹    é¦–å…ˆï¼Œéšæœºåˆ ç®—(è®¡ç®—æ–¹å¼æœ‰å¾ˆå¤šç§å¯ä»¥è‡ªå·±å®šä¹‰)ï¼Œå„è‡ªå¾—åˆ°ä¸€ä¸ªe1 ~ e6çš„å€¼ï¼Œå¯¹è¿™ä¸ª6ä¸ªå€¼è¿›è¡Œä¸€æ¬¡softmaxå¾—åˆ°Î±1 ~ Î±6ï¼Œå’Œæ˜¯1ï¼›å°†Î±1ï¼ŒÎ±2ï¼ŒÎ±3ï¼ŒÎ±4ï¼ŒÎ±5ï¼ŒÎ±6çœ‹ä½œæ˜¯s0å’Œh1 ~ h6çš„ç›¸ä¼¼åº¦ã€‚ç„¶åÎ±å’Œhå‘é‡åšä¸€æ¬¡å…ƒç´ ä¹˜ç§¯ï¼Œå¾—åˆ°çš„6ä¸ªå‘é‡åšä¸€æ¬¡å…ƒç´ çš„ç›¸åŠ å¾—åˆ°æœ€ç»ˆçš„å‘é‡ã€‚å°†è¿™ä¸ªå‘é‡å½“ä½œ0æ—¶åˆ»BiLSTMçš„ç¬¬ä¸‰ä¸ªè¾“å…¥ã€‚æ—¶åˆ»0ï¼ŒBiLSTMå°±ä¼šæœ‰ä¸€ä¸ªè¾“å‡ºï¼Œæ—¶åˆ»å˜ä¸º1ï¼Œæ¥ä¸‹æ¥çš„è¿‡ç¨‹ç»§ç»­å‘åè¿›è¡Œã€‚</p><p><a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html">NLP From Scratch: Translation with a Sequence to Sequence Network and Attention</a>å®ç°Seq2Seq(Attention)åçš„æ¨¡å‹ï¼ŒåŸºæœ¬å®ç°äº†æ­¤ç¯‡è®ºæ–‡çš„åˆ›æ–°ç‚¹ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ³¨æ„åŠ›æœºåˆ¶ </tag>
            
            <tag> nlp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>åŸºç¡€ç®—æ³•è€Œå·²</title>
      <link href="/year/09/17/basic_alogorithm/"/>
      <url>/year/09/17/basic_alogorithm/</url>
      
        <content type="html"><![CDATA[<p>ç®—æ³•å…¥é—¨ï¼šå•Šå“ˆç®—æ³• ç®—æ³•å›¾è§£ å¤§è¯æ•°æ®ç»“æ„</p><p>ç®—æ³•è¿›é˜¶ï¼šcf ç™½ä¹¦ ç´«ä¹¦ è“ä¹¦</p><h2 id="ç¬¬ä¸€ç« -åŸºç¡€ç®—æ³•"><a href="#ç¬¬ä¸€ç« -åŸºç¡€ç®—æ³•" class="headerlink" title="ç¬¬ä¸€ç«  åŸºç¡€ç®—æ³•"></a>ç¬¬ä¸€ç«  åŸºç¡€ç®—æ³•</h2><h3 id="åŸºç¡€ç®—æ³•-ä¸€"><a href="#åŸºç¡€ç®—æ³•-ä¸€" class="headerlink" title="åŸºç¡€ç®—æ³•(ä¸€)"></a>åŸºç¡€ç®—æ³•(ä¸€)</h3><h4 id="æ’åº"><a href="#æ’åº" class="headerlink" title="æ’åº"></a>æ’åº</h4><ul><li>å«ä¹‰:æ’åºæ˜¯æŒ‡å°†ä¸€ä¸ªæ— åºåºåˆ—æŒ‰ç…§æŸä¸ªè§„åˆ™è¿›è¡Œæœ‰åºæ’åˆ—(ä»¥ä¸‹æ’åºå‡å®ç°çš„æ˜¯ä»å°åˆ°å¤§æ’åº)</li></ul><h5 id="ç®€å•æ’åº"><a href="#ç®€å•æ’åº" class="headerlink" title="ç®€å•æ’åº"></a>ç®€å•æ’åº</h5><ul><li><p>å†’æ³¡æ’åºçš„æœ¬è´¨åœ¨äº==äº¤æ¢== ï¼Œå³æ¯æ¬¡é€šè¿‡äº¤æ¢çš„æ–¹å¼æŠŠå½“å‰å‰©ä½™å…ƒç´ çš„æœ€å¤§å€¼ç§»åŠ¨åˆ°ä¸€ç«¯</p><pre class="line-numbers language-c++"><code class="language-c++"># å†’æ³¡æ’åº(ä»¥ä¸‹å®ç°ä»å°åˆ°å¤§æ’åº)int a[n]={......};for(int i=1;i<n;i++){  //è¿›è¡Œn-1èºº//ç¬¬ièººï¼Œä»a[0]-a[n-i-1]æ¯ä¸€ä¸ªæ•°éƒ½è¦ä¸ä¸‹ä¸€ä¸ªæ•°è¿›è¡Œæ¯”è¾ƒï¼Œé‡åˆ°åé¢æ¯”è‡ªå·±è¾ƒå¤§çš„æ•°å°±äº¤æ¢ï¼Œå®ç°æ¯ä¸€è¶Ÿå‰©ä½™çš„æ•°a[0]-a[n-    i]çš„å†’æ³¡æ’åºï¼Œä½¿å½“å‰a[0]~a[n-i]ä¸­çš„æœ€å¤§çš„å…ƒç´ ç§»åŠ¨åˆ°æœ€åé¢çš„,a[n-i+1]-a[i]å·²ç»æ’å¥½åº    for(int j=0;j< n-i;j++){        if(a[j] > a[j+1]){  //å¦‚æœå·¦è¾¹çš„æ•°æ›´å¤§ï¼Œåˆ™a[j]ä¸a[j+1]äº¤æ¢            int temp = a[j];            a[j] = a[j+1];            a[j+1] = temp;        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>(ç®€å•)é€‰æ‹©æ’åºï¼š</p><pre class="line-numbers language-c++"><code class="language-c++"># é€‰æ‹©æ’åº(ä»¥ä¸‹å®ç°ä»å°åˆ°å¤§æ’åº)# ç®€å•é€‰æ‹©æ’åºæ˜¯æŒ‡å¯¹ä¸€ä¸ªåºåˆ—a[n]ä¸­çš„å…ƒç´ a[1]~a[n]ï¼Œä»¤iä»1~nè¿›è¡Œæšä¸¾ï¼Œè¿›è¡Œnè¶Ÿæ“ä½œï¼Œæ¯è¶Ÿä»å¾…æ’åºéƒ¨åˆ†[i,n]å…¶ä¸­é€‰æ‹©æœ€å°çš„å…ƒç´ ï¼Œä»¤å…¶ä¸å¾…æ’éƒ¨åˆ†çš„ç¬¬ä¸€ä¸ªå…ƒç´ a[i]è¿›è¡Œäº¤æ¢ï¼Œè¿™æ ·å…ƒç´ a[i]å°±ä¼šä¸å½“å‰åŒºé—´[1,i-1]å½¢æˆæ–°çš„æœ‰åºåŒºé—´[1,i],nè¶Ÿæ“ä½œä»¥åï¼Œå°±å½¢æˆæœ‰åºåŒºé—´int a[n]={......};void select_sort(){    for(int i=1;i<=n;i++){  //è¿›è¡Œnè¶Ÿæ“ä½œ        int k = i;        for(int j=i;j<=n;j++){  //é€‰å‡º[i,n]ä¸­æœ€å°å…ƒç´ çš„ä¸‹æ ‡ï¼Œå¹¶ä¸”å°†ä¸‹æ ‡è®°ä¸ºk            if(a[j]<a[k]){                k = j;            }        }        int temp = a[i];  //äº¤æ¢a[k]ä¸å½“å‰å¾…æ’åºåºåˆ—[i,n]çš„ç¬¬ä¸€ä¸ªå…ƒç´ a[i]        a[i] = a[k];        a[j] = temp;    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>(ç›´æ¥)æ’å…¥æ’åºï¼š</p><pre class="line-numbers language-c++"><code class="language-c++"># ç›´æ¥æ’å…¥æ’åº# ç›´æ¥æ’å…¥æ’åºæ˜¯æŒ‡å¯¹åºåˆ—a[n]ä¸­çš„å…ƒç´ a[i]~a[n]ï¼Œiä»2~nè¿›è¡Œæšä¸¾ï¼Œè¿›è¡Œn-1è¶Ÿæ“ä½œã€‚å‡è®¾æŸä¸€è¶Ÿï¼Œåºåˆ—a[1]~a[i-1]å·²ç»æœ‰åºï¼Œé‚£ä¹ˆè¿™ä¸€æ¬¡å°±æ˜¯ä»èŒƒå›´[1,i-1]ä¸­å¯»æ‰¾æŸä¸ªä½ç½®j,ä½¿å¾—a[i]æ’å…¥åˆ°è¿™ä¸ªä½ç½®jåï¼Œæ­¤æ—¶a[j]~a[i-1]ä¼šè‡ªåŠ¨å‘åç§»åŠ¨ä¸€ä½åˆ°a[j+1]~a[i],èŒƒå›´a[1,i]æœ‰åºint a[n]={......};  //nä¸ºå…ƒç´ ä¸ªæ•°ï¼Œæ•°ç»„ä¸‹æ ‡ä¸º1~nvoid insert_sort(){    for(int i=2;i<=n;i++){  //è¿›è¡Œn-1è¶Ÿæ’åº        int temp = a[i],j = i; //tempä¸´æ—¶å­˜æ”¾a[i]        while(j>1 && temp<a[j-1]){            a[j] = a[j-1];            j--;        }        a[j] = temp;    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h5 id="å¿«æ’"><a href="#å¿«æ’" class="headerlink" title="å¿«æ’"></a>å¿«æ’</h5><ul><li><p>å¿«æ’çš„ä¸»è¦æ€æƒ³æ˜¯åˆ†æ²»</p><pre class="line-numbers language-c++"><code class="language-c++">//å¿«æ’çš„æ—¶é—´å¤æ‚åº¦æ˜¯nlogn(è¿™é‡Œæ‰€æŒ‡çš„æ˜¯å¹³å‡å¤æ‚åº¦)#include <iostream>acwing 785å¿«é€Ÿæ’åºusing namespace std;const int N = 1e6+10;int n;int q[N];void quick_sort(int q[], int l, int r){    if (l >= r) return;    int i = l - 1, j = r + 1, x = q[l + r >> 1];  //xçš„å–å€¼å¯ä»¥å–åŒºé—´é‡Œé¢ä»»æ„ä¸€ä¸ª    while (i < j)    {        do i ++ ; while (q[i] < x);        do j -- ; while (q[j] > x);        if (i < j) swap(q[i], q[j]);    }    quick_sort(q, l, j); //å¯¹å·¦è¾¹çš„è¿›è¡Œå¿«æ’    quick_sort(q, j + 1, r); //å¯¹å³è¾¹è¿›è¡Œå¿«æ’}int main(){    scanf("%d",&n);    for(int i=0;i<n;i++){        scanf("%d",&q[i]);    }    quick_sort(q,0,n-1);        for(int i=0;i<n;i++){        printf("%d ",q[i]);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h5 id="å½’å¹¶æ’åº"><a href="#å½’å¹¶æ’åº" class="headerlink" title="å½’å¹¶æ’åº"></a>å½’å¹¶æ’åº</h5><ul><li><p>å½’å¹¶çš„ä¸»è¦æ€æƒ³ä¹Ÿæ˜¯åˆ†æ²»</p><pre class="line-numbers language-c++"><code class="language-c++">acwing787 å½’å¹¶æ’åº#include <iostream>using namespace std;const int N = 1e6+10;int n;int q[N];int tmp[N];void merge_sort(int q[],int l,int r){    if(l>=r) return ;        int mid = l+r >> 1;  //1ï¼šç¡®å®šåˆ†ç•Œç‚¹        merge_sort(q,l,mid);   //å¯¹å·¦å³ä¸¤è¾¹åˆ†åˆ«è¿›è¡Œå½’å¹¶æ’åº    merge_sort(q,mid+1,r);        // å°†å·¦å³ä¸¤è¾¹è¿›è¡Œå½’å¹¶æ’åºï¼ŒæŠŠä¸¤ä¸ªæœ‰åºçš„åºåˆ—æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œæ‹¼æ¥çš„æ–¹æ³•å°±æ˜¯å½’å¹¶    int k=0,i=l,j=mid+1;     while(i<=mid && j<= r){        if(q[i]<=q[j]) tmp[k++] = q[i++];        else tmp[k++] = q[j++];    }    while(i<=mid) tmp[k++]=q[i++];  //å¯¹äºq[l]~[mid]å’Œq[mid+1~r]ä¸¤ä¸ªåºåˆ—ï¼Œå¦‚æœå­˜åœ¨åºåˆ—æ²¡æœ‰å¾ªç¯ç»“æŸçš„è¯å°±ç›´æ¥                                åˆ°tmpåºåˆ—åé¢å³å¯    while(j<=r) tmp[k++]=q[j++];        for(i=l,j=0;i <= r;i++,j++) q[i] = tmp[j];}int main(){    scanf("%d",&n);    for(int i=0;i<n;i++) scanf("%d",&q[i]);        merge_sort(q,0,n-1);        for(int i=0;i<n;i++) printf("%d ",q[i]);        return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h4 id="äºŒåˆ†"><a href="#äºŒåˆ†" class="headerlink" title="äºŒåˆ†"></a>äºŒåˆ†</h4><h5 id="æ•´æ•°"><a href="#æ•´æ•°" class="headerlink" title="æ•´æ•°"></a>æ•´æ•°</h5><ul><li><p>æ•´æ•°äºŒåˆ†çš„æœ¬è´¨:æœ‰å•è°ƒæ€§çš„è¯ä¸€å®šå¯ä»¥äºŒåˆ†ï¼›ä½†æ˜¯èƒ½äºŒåˆ†çš„ä¸ä¸€å®šå…·æœ‰å•è°ƒæ€§<br>äºŒåˆ†çš„æœ¬è´¨æ˜¯å¯¹äºä¸€ä¸ªæ•´æ•°åŒºé—´ï¼Œæˆ‘ä»¬å…ˆå®šä¹‰ä¸€ä¸ªæ€§è´¨ï¼Œè¦æ‰¾åˆ°ä¸€ä¸ªä¸­é—´ç‚¹ï¼Œæ˜¯çš„åœ¨è¿™ä¸ªç‚¹çš„å³åŠè¾¹æ»¡è¶³è¿™ä¸ªæ€§è´¨ï¼Œå·¦åŠè¾¹ä¸æ»¡è¶³è¿™ä¸ªæ€§è´¨ï¼Œè¿™æ ·å°±å¯ä»¥æŠŠä¸€ä¸ªåŒºé—´ä¸€åˆ†ä¸ºäºŒï¼Œæ‰¾åˆ°è¿™ä¸ªè¾¹ç•Œ</p><pre class="line-numbers language-c++"><code class="language-c++">#1.æ‰¾åˆ°ä¸€ä¸ªä¸­é—´å€¼mid# if(check(mid)) true:midæ»¡è¶³è¿™ä¸ªæ€§è´¨  false:midä¸æ»¡è¶³è¿™ä¸ªæ€§è´¨# äºŒåˆ†çš„æ—¶å€™ä¸€å®šè¦ä¿è¯è¦å¯»æ‰¾çš„å€¼ä¸€å®šåœ¨ä¸æ–­ç¼©å°çš„é‚£ä¸ªåŒºé—´é‡Œé¢ï¼Œå½“åŒºé—´çš„é•¿åº¦ä¸º1çš„æ—¶å€™å°±ä»£è¡¨æ‰¾åˆ°ç­”æ¡ˆ#acwing789:æ•°çš„èŒƒå›´#include <iostream>#include <algorithm>#include <cstring>using namespace std;const int N=100010;int a,b;int q[N];int main(){    scanf("%d %d",&a,&b);    for(int i=0;i<a;i++) scanf("%d",&q[i]);        while(b--){        int x;        scanf("%d",&x);                int l=0,r=a-1;        while(l<r){            int mid= l+r >> 1;            if(q[mid]>=x) r=mid;            else l=mid+1;        }                if(q[l]!=x) cout<<"-1 -1"<<endl;  // è¿™ä¸ªè¡¨ç¤ºè¦å¯»æ‰¾çš„é‚£ä¸ªå€¼ä¸åœ¨åŒºé—´é‡Œé¢ï¼Œæ­¤æ—¶q[l]çš„å€¼æ˜¯ç¬¬ä¸€ä¸ªæ»¡è¶³å¤§äºxçš„æ•°        else{            cout<<l<<' ';                        int l=0,r=a-1;            while(l<r){                int mid= l+r+1 >> 1;                if(q[mid]<=x) l=mid;                else r=mid-1;            }            cout<<l        }    }    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h5 id="æµ®ç‚¹æ•°"><a href="#æµ®ç‚¹æ•°" class="headerlink" title="æµ®ç‚¹æ•°"></a>æµ®ç‚¹æ•°</h5><ul><li><p>æµ®ç‚¹æ•°äºŒåˆ†:æœ¬è´¨ä¸Šä¹Ÿæ˜¯å¯»æ‰¾è¾¹ç•Œï¼Œæ»¡è¶³å·¦åŠè¾¹æ»¡è¶³æ€§è´¨ï¼Œå³åŠè¾¹ä¸æ»¡è¶³æ€§è´¨ï¼ŒçŸ¥é“</p></li><li><pre class="line-numbers language-c++"><code class="language-c++"># ä¾‹å­:ç®—å¹³æ–¹æ ¹#include <iostream>using namespace std;int mian(){    double x;    cin>>x;        double l=0,r=x;    double mid = (l+r)/2;    while(r-l > 1e-8){        if(mid*mid>=x)  r=mid;        else l=mid;    }        printf("%lf",&l);}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> ç®—æ³• </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ’åºç®—æ³• </tag>
            
            <tag> acwing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ç¬¬ä¸€ç¯‡ï¼Œè¡¨è¾¾ç‚¹çœ‹æ³•å§</title>
      <link href="/year/09/15/001/"/>
      <url>/year/09/15/001/</url>
      
        <content type="html"><![CDATA[<p><span class="github-emoji"><span>ğŸ˜„</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span><span class="github-emoji"><span>ğŸ˜†</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span><span class="github-emoji"><span>ğŸ˜†</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>å€¼å¾—è®°å½•ä¸€ä¸‹</p><p>è¿™æ˜¯æˆ‘çš„ç¬¬ä¸€ç¯‡åšæ–‡ï¼ŒèŠ±äº†å¾ˆé•¿æ—¶é—´æ¥è¿›è¡Œæ“ä½œï¼Œåœ¨ç½‘ä¸Šæœç´¢çš„æ•™ç¨‹å‚å·®ä¸é½ï¼Œä¹ŸåŒæ ·ä¼šå‡ºç°å„ç§å„æ ·çš„é—®é¢˜ï¼Œæ¯”å¦‚nodejsç‰ˆæœ¬è¿‡é«˜ä¸hexoä¸å…¼å®¹é—®é¢˜ï¼Œæˆ‘è§‰å¾—è¿˜æ˜¯æœ‰é—®é¢˜è¿˜æ˜¯è¦å¤šå’Œå…¶ä»–äººæ²Ÿé€šï¼Œå¦å¤–å¯¹ä¸»é¢˜çš„è®¾ç½®å¯ä»¥æŒ‰ç…§è‡ªå·±çš„é£æ ¼æ¥ï¼Œä½†æ˜¯è¿™å°±éœ€è¦å¯¹webçŸ¥è¯†æœ‰ä¸€å®šçš„äº†è§£ï¼Œå¯¹æ’ç‰ˆæœ‰è‡ªå·±çš„ç†è§£æ‰å¯ä»¥ã€‚<br>åœ¨æˆ‘çœ‹æ¥ï¼Œåšå®¢æ›´åŠ æ³¨é‡çš„åº”è¯¥æ˜¯å†…å®¹ï¼Œä»¥åŠå…»æˆè®°å½•æ—¥è®°çš„ä¹ æƒ¯ï¼Œå¯¹è‡ªå·±æ¯ä¸ªé˜¶æ®µçš„å­¦ä¹ æœ‰ä¸€ä¸ªé€‚å½“çš„æ€»ç»“ï¼Œå¯ä»¥è®©è‡ªå·±è®¡åˆ’æ›´åŠ æ˜ç¡®ã€‚<br>æ‰€ä»¥æˆ‘å°±ç®€å•ä»‹ç»hexo+github.ioæ­å»ºåšå®¢è¿‡ç¨‹ä¸­é‡è¦çš„ç‚¹å§(æˆ‘æ˜¯ç”¨çš„ä¸»é¢˜æ˜¯matery)</p><h4 id="æœ¬åœ°é…ç½®æ–‡ä»¶"><a href="#æœ¬åœ°é…ç½®æ–‡ä»¶" class="headerlink" title="æœ¬åœ°é…ç½®æ–‡ä»¶"></a>æœ¬åœ°é…ç½®æ–‡ä»¶</h4><p><img src="https://s2.loli.net/2021/12/23/AehfvZbFOsL2ycW.png" alt="image-20210916214915453.png"></p><ul><li><p><strong>_config.yml</strong>ï¼š</p><p>ç½‘ç«™<strong>ç«™ç‚¹é…ç½®æ–‡ä»¶</strong>ï¼Œåˆå«æ ¹ç›®å½•ç«™ç‚¹é…ç½®æ–‡ä»¶ï¼Œåœ¨è¿™ä¸ªæ–‡ä»¶é‡Œé¢å¯ä»¥é…ç½®å¤§éƒ¨åˆ†çš„å‚æ•°</p></li><li><p><strong>scaffolds</strong>:</p><p>æ­¤æ–‡ä»¶å¤¹ä¼šæ”¾ä¸€äº›é»˜è®¤çš„æ–‡ä»¶ï¼Œç”¨æ¥å½“ä½œåˆ›å»ºåšæ–‡çš„æ¨¡æ¿mdæ–‡ä»¶ï¼Œhexoä¼šæ ¹æ®scaffoldæ¥å»ºç«‹æ–‡ä»¶ã€‚æ¨¡æ¿æ˜¯æŒ‡æ–°å»ºçš„mdæ–‡ä»¶ä¼šé»˜è®¤æ”¾å…¥æ¨¡æ¿æ–‡ä»¶çš„åˆå§‹å†…å®¹</p></li><li><p><strong>public</strong>ï¼š</p><p>è¿™ä¸ªæ–‡ä»¶çš„å†…å®¹æœ€ç»ˆéƒ½ä¼špushåˆ°githubä»“åº“ä¸­</p></li><li><p><strong>source</strong>:</p><p>è¿™ä¸ªæ–‡ä»¶å¤¹æ˜¯å­˜æ”¾ç”¨æˆ·èµ„æºçš„åœ°æ–¹ï¼Œé™¤äº†<code>_posts</code>æ–‡ä»¶å¤¹ä¹‹å¤–ï¼Œå¼€å¤´å‘½åä¸º_(ä¸‹åˆ’çº¿çš„æ–‡ä»¶/æ–‡ä»¶å¤¹ä»¥åŠéšè—çš„æ–‡ä»¶éƒ½ä¼šè¢«å¿½ç•¥)ã€‚markdownå’Œhtmlæ–‡ä»¶éƒ½ä¼šè¢«è§£æå¹¶æ”¾åˆ°<strong>public</strong>æ–‡ä»¶å¤¹é‡Œé¢ï¼Œè€Œå…¶ä»–æ–‡ä»¶ä¼šè¢«æ‹·è´åˆ°publicæ–‡ä»¶å¤¹ã€‚</p></li><li><p>**ä¸ºgithubä»“åº“æ·»åŠ readme</p><p>æ—¢ç„¶<code>source</code>æ–‡ä»¶å¤¹ä¸­çš„å†…å®¹ä¼šè¢«å…¨éƒ¨æ¨é€åˆ°publicæ–‡ä»¶å¤¹ï¼Œpublicæ–‡ä»¶å¤¹ä¸­çš„å†…å®¹æœ€ç»ˆåˆä¼šè¢«pushåˆ°githubä»“åº“ï¼Œæ‰€ä»¥å¦‚æœæƒ³è¦ä¸ºgithubä»“åº“æ·»åŠ readme.mdï¼Œåªè¦åœ¨sourceæ–‡ä»¶å¤¹ä¸­åˆ›å»ºå°±å¥½äº†ã€‚æœ€å<strong>éƒ¨ç½²</strong>åˆ°githubå°±æœ‰readmeäº†ã€‚ä½†æ˜¯ä¼šå‘ç°ï¼ŒREADME.mdæ–‡ä»¶éƒ¨ç½²çš„æ—¶å€™ä¼šè¢«è§£ææˆhtmlæ–‡ä»¶ï¼Œæ˜¾ç¤ºçš„æ˜¯htmlä»£ç ï¼Œä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„æ–‡æ¡£å†…å®¹ã€‚</p><p><strong>è§£å†³åŠæ³•</strong>ï¼šå°†åœ¨sourceæ–‡ä»¶å¤¹æ–°å»ºçš„README.mdé‡å‘½åä¸ºREMADE.MDWNï¼Œåœ¨é‡æ–°éƒ¨ç½²åˆ°githubã€‚(sourceæ–‡ä»¶å¤¹ä¸­ï¼Œ.mdä¼šè¢«è§£æä¸ºhtmlã€‚å¹¶æ”¾åˆ°publicæ–‡ä»¶å¤¹è¢«pushåˆ°githubï¼Œä½†.MDWNä¸ä¼šè¢«è§£æ)</p></li></ul><h4 id="ä¸€äº›å¸¸ç”¨çš„Hexoå‘½ä»¤"><a href="#ä¸€äº›å¸¸ç”¨çš„Hexoå‘½ä»¤" class="headerlink" title="ä¸€äº›å¸¸ç”¨çš„Hexoå‘½ä»¤"></a>ä¸€äº›å¸¸ç”¨çš„Hexoå‘½ä»¤</h4><ul><li><p>å¸¸ç”¨å‘½ä»¤</p><pre><code>hexo new "postName" #æ–°å»ºåšæ–‡hexo generate #ç”Ÿæˆé™æ€é¡µé¢è‡³publicç›®å½•hexo server #å¼€å¯é¢„è§ˆè®¿é—®ç«¯å£ï¼ˆé»˜è®¤ç«¯å£4000ï¼Œâ€™crtl+c'å…³é—­serverï¼‰hexo deploy #éƒ¨ç½²åˆ°githubhexo help #æŸ¥çœ‹å¸®åŠ©hexo version #æŸ¥çœ‹ç‰ˆæœ¬</code></pre></li><li><p>ç¼©å†™</p><pre><code>hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deploy</code></pre></li><li><p>ç»„åˆå‘½ä»¤</p><pre><code>hexo s -g #ç”Ÿæˆå¹¶æœ¬åœ°é¢„è§ˆhexo d -g #ç”Ÿæˆå¹¶éƒ¨ç½²åˆ°äº‘ç«¯</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> æµ‹è¯•ï¼Œæµ‹è¯•çš„å­åˆ†ç±» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> åšæ–‡ </tag>
            
            <tag> æµ‹è¯• </tag>
            
            <tag> whatever </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>README.md</title>
      <link href="/year/09/14/README/"/>
      <url>/year/09/14/README/</url>
      
        <content type="html"><![CDATA[<h3 id="2021-9-17-ç¬¬ä¸€æ¬¡æ›´æ–°"><a href="#2021-9-17-ç¬¬ä¸€æ¬¡æ›´æ–°" class="headerlink" title="2021.9.17 ç¬¬ä¸€æ¬¡æ›´æ–°"></a>2021.9.17 ç¬¬ä¸€æ¬¡æ›´æ–°</h3><ul><li>å¯¹æ–‡ç« Front-matterä»‹ç»çš„ä¸€äº›åº”ç”¨å°è¯•å¢åŠ <ul><li>æ¯”å¦‚title,date,topï¼Œsummaryç­‰ï¼Œå‰©ä¸‹çš„å¾…æ›´æ–°å°è¯•<span class="github-emoji"><span>ğŸ‘Š</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f44a.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span><span class="github-emoji"><span>ğŸ’¤</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a4.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span></li></ul></li></ul><h3 id="2021-9-14-æ°´ç¬¬ä¸€ç¯‡ï¼Œå•¥åŠŸèƒ½æ²¡æœ‰"><a href="#2021-9-14-æ°´ç¬¬ä¸€ç¯‡ï¼Œå•¥åŠŸèƒ½æ²¡æœ‰" class="headerlink" title="2021.9.14 æ°´ç¬¬ä¸€ç¯‡ï¼Œå•¥åŠŸèƒ½æ²¡æœ‰"></a>2021.9.14 æ°´ç¬¬ä¸€ç¯‡ï¼Œå•¥åŠŸèƒ½æ²¡æœ‰</h3><ul><li>èƒ½æ­£å¸¸éƒ¨ç½²æ–‡ç« å’Œæ¸²æŸ“æ­£å¸¸</li><li>èƒ½å¤Ÿè®¿é—®blog</li></ul><h3 id="2021-11-05"><a href="#2021-11-05" class="headerlink" title="2021.11.05"></a>2021.11.05</h3><ul><li>å»ºç«™åŠŸèƒ½</li><li>ä¸è’œå­åˆå§‹åŒ–è®¡æ•°</li></ul><h3 id="2021-11-07"><a href="#2021-11-07" class="headerlink" title="2021.11.07"></a>2021.11.07</h3><ul><li>å…¨å±€æœç´¢</li><li>ä»£ç é«˜äº®</li></ul>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
