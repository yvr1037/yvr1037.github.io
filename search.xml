<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Dialogue_system</title>
      <link href="/year/11/21/Dialogue-system/"/>
      <url>/year/11/21/Dialogue-system/</url>
      
        <content type="html"><![CDATA[<p>NLPé¢†åŸŸæ¯”è¾ƒä¼ ç»Ÿå’Œæ ¸å¿ƒçš„taskæœ‰å¾ˆå¤š</p><p>ä¸‹é¢å…ˆä»‹ç»Chinese NLPçš„åŸºæœ¬ä»»åŠ¡:</p><h4 id="Co-reference-Resolution"><a href="#Co-reference-Resolution" class="headerlink" title="Co-reference Resolution"></a>Co-reference Resolution</h4><p>Background</p><hr><p>â€‹    Co-reference identifies pieces of text and links them with other pieces of text that refer to the same thing. Sometimes pieces of text have zero-length, where an overt pronoun or noun is omitted.</p><p>Example</p><hr><p>input:</p><pre><code>æˆ‘çš„å§å§ç»™æˆ‘å¥¹çš„ç‹—ã€‚å¾ˆå–œæ¬¢.</code></pre><p>output</p><pre><code>[æˆ‘]0çš„[å§å§]1ç»™[æˆ‘]0[å¥¹]1çš„[ç‹—]2ã€‚[]0å¾ˆå–œæ¬¢[]2.</code></pre><h6 id="Standard-Metrics"><a href="#Standard-Metrics" class="headerlink" title="Standard Metrics"></a>Standard Metrics</h6><p>Average of F1-scores returned by these three precison/recall metrics:</p><ul><li>MUC</li><li>B-cubed</li><li>Entity-based CEAF</li><li>BLANC</li><li>Link-Based Entity-Aware metric(LEA)</li></ul><h4 id="Sentiment-Analysis"><a href="#Sentiment-Analysis" class="headerlink" title="Sentiment Analysis"></a>Sentiment Analysis</h4><p>Background</p><hr><p>Sentiment Analysis detects identifies and extracts subjective information from text.<br>æƒ…æ„Ÿåˆ†ææ£€æµ‹è¯†åˆ«å¹¶ä»æ–‡æœ¬ä¸­æå–ä¸»è§‚ä¿¡æ¯.</p><hr><p>Example</p><hr><p>inputs:</p><pre><code>æ€»çš„æ„Ÿè§‰è¿™å°æœºå™¨è¿˜ä¸é”™ï¼Œå®ç”¨çš„æœ‰ï¼šé˜´é˜³å†æ˜¾ç¤ºï¼Œæ—¶é—´ä¸æ—¥æœŸå¿«é€Ÿè½¬æ¢, è®°äº‹æœ¬ç­‰ã€‚</code></pre><p>Output:</p><pre><code>Positive</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Faster-RCNN</title>
      <link href="/year/11/06/Faster%20R-CNN/"/>
      <url>/year/11/06/Faster%20R-CNN/</url>
      
        <content type="html"><![CDATA[<h5 id="Perface"><a href="#Perface" class="headerlink" title="Perface:"></a>Perface:</h5><p>åœ¨ğŸ¦ŒåŒå­¦çš„æ„ŸæŸ“ä¸‹ï¼Œç¬”è€…æœ€è¿‘ä¹Ÿå­¦ä¹ äº†ç›®æ ‡æ£€æµ‹æ–¹å‘çš„ç›¸å…³å†…å®¹ï¼Œçœ‹çš„ç¬¬ä¸€ç¯‡è®ºæ–‡æ˜¯<a href="https://arxiv.org/abs/1504.08083#">Faster R-CNNï¼šTowards Rel-Time Objection Dection with Region Proposal Networks</a>ï¼Œé‡Œé¢æ¶‰åŠåˆ°å¾ˆå¤šå‰ç½®æ¨¡å‹éœ€è¦äº†è§£ç»“æ„ï¼Œåœ¨è¿™é‡Œåˆ†äº«ä¸€ç‚¹ç¬”è®°</p><h5 id="ç›®æ ‡æ£€æµ‹èƒŒæ™¯"><a href="#ç›®æ ‡æ£€æµ‹èƒŒæ™¯" class="headerlink" title="ç›®æ ‡æ£€æµ‹èƒŒæ™¯"></a>ç›®æ ‡æ£€æµ‹èƒŒæ™¯</h5><p>ç›®æ ‡æ£€æµ‹æ˜¯å¾ˆå¤šè®¡ç®—æœºè§†è§‰äººç‰©çš„åŸºç¡€ï¼Œç›®å‰ä¸»æµçš„ç›®æ ‡æ£€æµ‹çš„ç®—æ³•ä¸»è¦åŸºäºæ·±åº¦å­¦ä¹ æ¨¡å‹å¯ä»¥åˆ†ä¸ºä¸¤å¤§ç±»</p><ol><li>one-stageæ£€æµ‹ç®—æ³•,è¿™ç§ç®—æ³•ç›´æ¥äº§ç”Ÿç‰©ä½“çš„ç±»åˆ«æ¦‚ç‡å’Œåæ ‡ä½ç½®,ä¸éœ€è¦ç›´æ¥äº§ç”Ÿå€™é€‰åŒºåŸŸ.æ¯”å¦‚è¯´YOLOå’ŒSSD</li><li>two-stageæ£€æµ‹ç®—æ³•,è¿™æ˜¯å°†æ£€æµ‹é—®é¢˜åˆ’åˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µ,é¦–å…ˆæ˜¯äº§ç”Ÿå€™é€‰åŒºåŸŸ,ç„¶åå¯¹å€™é€‰åŒºåŸŸåˆ†ç±»;å…¸å‹ç®—æ³•æ˜¯R-CNNç³»åˆ—,faster rcnnå°±æ˜¯åŸºäº<strong>region proposal</strong>(å€™é€‰åŒºåŸŸ)</li></ol><h5 id="backbone-network"><a href="#backbone-network" class="headerlink" title="backbone network"></a>backbone network</h5><p><strong>Faster R-CNN</strong>ä½¿ç”¨çš„ä¸»å¹²ç½‘ç»œæ˜¯VGG-16,åœ¨è®ºæ–‡ä¸­ç§°ä¸»å¹²ç½‘ç»œæ—¶<strong>backbone network</strong>,ä¸»å¹²ç½‘ç»œå°±æ˜¯ç”¨æ¥<strong>feature extraction</strong>,å½“ç„¶è¿™ä¸ªä¸æ˜¯ä¸€æˆä¸å˜çš„,å¯ä»¥æ›¿æ¢,æ¯”å¦‚ç°åœ¨ä¹ŸåŒæ ·æµè¡Œä½¿ç”¨<strong>Resnet</strong>,å†å¦‚<strong>CornerNet</strong>ç®—æ³•ä¸­ä½¿ç”¨çš„backbone networkæ˜¯Hourglass Network.<br>å…³äºVGG-16å¯ä»¥å‚è€ƒ<a href="http://zh.gluon.ai/chapter_convolutional-neural-networks/vgg.html">VGGä»‹ç»</a>,16çš„å«ä¹‰æ˜¯å«æœ‰å‚æ•°æœ‰16å±‚,åˆ†åˆ«æ˜¯13ä¸ªå·ç§¯å±‚+3ä¸ªå…¨è¿æ¥å±‚</p><img src="C:\Users\VrShadow\AppData\Roaming\Typora\typora-user-images\image-20211027195132710.png" alt="image-20211027195132710" style="zoom:65%;"><p>å›¾æ¥è‡ªç½‘ç»œ</p><img src="C:\Users\VrShadow\AppData\Roaming\Typora\typora-user-images\image-20211027195339689.png" alt="image-20211027195339689" style="zoom:60%;"><h5 id="Faster-R-CNNç®—æ³•æ­¥éª¤"><a href="#Faster-R-CNNç®—æ³•æ­¥éª¤" class="headerlink" title="Faster R-CNNç®—æ³•æ­¥éª¤"></a>Faster R-CNNç®—æ³•æ­¥éª¤</h5><p>è¿™éƒ¨åˆ†æ˜¯ä¸ºäº†ç†è§£Faster R-CNN,æ€»ä½“æè¿°ä¸‹ç®—æ³•çš„æ•´ä¸ªè¿‡ç¨‹ä»¥ä¾¿åæœŸåšç»†èŠ‚åˆ†æ</p><img src="C:\Users\VrShadow\AppData\Roaming\Typora\typora-user-images\image-20211027195754031.png" alt="image-20211027195754031" style="zoom:50%;"><p>å¤§è‡´æµç¨‹æ˜¯:å°†æ•´å¼ å›¾ç‰‡è¾“å…¥CNNå±‚,å¾—åˆ°feature map,å·ç§¯ç‰¹å¾è¾“å…¥åˆ°**RPN(Region Proposal Network)**å¾—åˆ°å€™é€‰æ¡†çš„ç‰¹å¾ä¿¡æ¯,å¯¹å€™é€‰æ¡†ä¸­æå–çš„ç‰¹å¾ä½¿ç”¨åˆ†ç±»å™¨åˆ¤åˆ«æ˜¯å¦å±äºä¸€ä¸ªç‰¹å®šç±»åˆ«,å¯¹äºå±äºæŸä¸€ç‰¹å¾çš„å€™é€‰æ¡†ç”¨å›å½’å™¨è¿›ä¸€æ­¥è°ƒæ•´å…¶ä½ç½®.</p><img src="C:\Users\VrShadow\AppData\Roaming\Typora\typora-user-images\image-20211027200749657.png" alt="image-20211027200749657" style="zoom:50%;"><p>Faster R-CNNå¯ä»¥çœ‹ä½œRPNå’ŒFast R-CNNæ¨¡å‹çš„ç»“åˆ,å³Faster R-CNN = RPN + Fast R-CNN.ä¸‹é¢ä»‹ç»æ¯ä¸€æ­¥éª¤çš„è¾“å…¥è¾“å‡ºçš„ç»†èŠ‚.</p><ul><li>é¦–å…ˆé€šè¿‡é¢„è®­ç»ƒæ¨¡å‹è®­ç»ƒå¾—åˆ°Conv layers(è¿™ä¸ªconv layerå®é™…ä¸Šå°±æ˜¯VGG-16)èƒ½å¤Ÿæ¥æ”¶æ•´å¼ å›¾ç‰‡å¹¶æå–ç‰¹å¾å›¾feature maps,è¿™ä¸ªfeature mapæ˜¯åœ¨convå±‚ä¹‹åè·å¾—çš„ç‰¹å¾.</li><li>feature mapè¢«å…±äº«ä¹‹åç”¨äºåç»­çš„RPNå’ŒRolæ± åŒ–å±‚<ul><li>BPNå±‚:BPNç½‘ç»œç”¨äºç”Ÿæˆregion proposals.è¯¥å±‚é€šè¿‡softmaxåˆ¤æ–­anchorså±äºå‰æ™¯(foreground)è¿˜æ˜¯èƒŒæ™¯(background),å†åˆ©ç”¨è¾¹æ¡†å›å½’ä¿®æ­£anchors,è·å¾—ç²¾ç¡®çš„proposals </li><li>RoI Poolingå±‚:è¯¥å±‚æ”¶é›†è¾“å…¥çš„feature mapå’Œproposalsç»¼åˆè¿™äº›ä¿¡æ¯æå–proposal feature map,è¿›å…¥åˆ°åé¢å¯åˆ©ç”¨å…¨è¿æ¥æ“ä½œå±‚è¿›è¡Œç›®æ ‡è¯†åˆ«å’Œå®šä½</li></ul></li><li>æœ€åçš„classifierä¼šå°†Roi Poolingå±‚å½¢æˆå›ºå®šå¤§å°çš„feature mapè¿›è¡Œå…¨è¿æ¥æ“ä½œ,åˆ©ç”¨softmaxè¿›è¡Œå…·ä½“ç±»åˆ«çš„åˆ†ç±»,åŒæ—¶åˆ©ç”¨L1 losså®Œæˆbounding box regressionå›å½’æ“ä½œè·å¾—ç‰©ä½“çš„å‡†ç¡®ä½ç½®</li></ul><h5 id="ç»†èŠ‚"><a href="#ç»†èŠ‚" class="headerlink" title="ç»†èŠ‚"></a>ç»†èŠ‚</h5><h6 id="1-RPN"><a href="#1-RPN" class="headerlink" title="1.RPN"></a>1.RPN</h6><p>ä¹‹å‰çš„R-CNNå’ŒFast R-CNNéƒ½æ˜¯é‡‡ç”¨å¯é€‰æ‹©æ€§æœç´¢(SS)æ¥äº§ç”Ÿå€™é€‰æ¡†çš„,ä½†æ˜¯è¿™ç§æ–¹æ³•ç‰¹åˆ«è€—æ—¶;Faster R-CNNæœ€å¤§çš„äº®ç‚¹æ˜¯æŠ›å¼ƒSS,é‡‡ç”¨RPNç”Ÿæˆå€™é€‰æ¡†.<br><img src="C:\Users\VrShadow\AppData\Roaming\Typora\typora-user-images\image-20211027204057233.png" alt="image-20211027204057233" style="zoom:67%;"></p><p>è¯´æ˜:</p><ol><li>Conv feature map:VGG-16ç½‘ç»œæœ€åä¸€ä¸ªå·ç§¯å±‚è¾“å‡ºçš„feature map</li><li>Sliding window:æ»‘åŠ¨çª—å£å®é™…ä¸Šå°±æ˜¯3*3çš„å·ç§¯æ ¸,æ»‘çª—åªè¦é€‰å–æ‰€æœ‰å¯èƒ½çš„åŒºåŸŸå¹¶æ²¡æœ‰é¢å¤–çš„ä½œç”¨</li><li>K anchor boxes:åœ¨æ¯ä¸ªsliding windowçš„ç‚¹ä¸Šåˆå§‹åŒ–çš„å‚è€ƒåŒºåŸŸ(è®ºæ–‡ä¸­k=9)å°±æ˜¯9ä¸ªçŸ©å½¢æ¡†</li><li>Intermediate layer:ä¸­é—´å±‚ï¼Œ256-dæ˜¯ä¸­é—´å±‚çš„ç»´åº¦(è®ºæ–‡ä¸­è°ç”¨ZFç½‘ç»œå°±æ˜¯256ç»´,VGGå°±æ˜¯512ç»´)</li><li>Cls layer:åˆ†ç±»å±‚,é¢„æµ‹proposalçš„anchorå¯¹åº”çš„proposalçš„(x,y,w,h)</li><li>2k scores:2kä¸ªåˆ†æ•°(18ä¸ª)</li><li>Reg layer:å›å½’å±‚,åˆ¤æ–­è¯¥proposalæ˜¯å‰æ™¯è¿˜æ˜¯èƒŒæ™¯</li><li>4k coordinates:4kåæ ‡(36ä¸ª)</li></ol><ul><li>RPNçš„è¾“å…¥æ˜¯å·ç§¯ç‰¹å¾å›¾,è¾“å‡ºæ˜¯å›¾ç‰‡ç”Ÿæˆçš„proposals,RPNé€šè¿‡ä¸€ä¸ªæ»‘åŠ¨çª—å£è¿æ¥åœ¨æœ€åä¸€ä¸ªå·ç§¯å±‚çš„feature mapä¸Š,ç”Ÿæˆä¸€ä¸ªé•¿åº¦256çš„å…¨è¿æ¥ç‰¹å¾</li><li>è¿™ä¸ªå…¨è¿æ¥å±‚ç‰¹å¾åˆ†åˆ«é€å…¥ä¸¤ä¸ªå…¨è¿æ¥å±‚ä¸€ä¸ªæ˜¯åˆ†ç±»å±‚,ç”¨äºåˆ†ç±»æ£€æµ‹;ä¸€ä¸ªæ˜¯å›å½’å±‚,ç”¨äºå›å½’;å¯¹äºæ¯ä¸ªæ»‘åŠ¨çª—å£ä½ç½®ä¸€èˆ¬è®¾ç½®k(è®ºæ–‡ä¸­k=9)ä¸ªä¸åŒå¤§å°æˆ–è€…æ¯”ä¾‹çš„anchorsè¿™æ„å‘³ç€æ¯ä¸ªæ»‘çª—è¦†ç›–çš„ä½ç½®å°±ä¼šé¢„æµ‹9å“¥å€™é€‰åŒºåŸŸ<br><strong>åˆ†ç±»å±‚</strong>:æ¯ä¸ªanchorè¾“å‡ºä¸¤ä¸ªé¢„æµ‹å€¼:anchoræ˜¯èƒŒæ™¯(background,éobject)çš„scoreå’Œanchoræ˜¯å‰æ™¯(foreground,object)çš„score<br><strong>å›å½’å±‚</strong>:è¾“å‡º4k(4*9=36)ä¸ªåæ ‡å€¼è¡¨ç¤ºæ¯ä¸ªå€™é€‰åŒºåŸŸçš„ä½ç½®(x,y,w,h)</li></ul><p>ä¹Ÿå°±æ˜¯è¯´æˆ‘ä¹ˆæ˜¯é€šè¿‡è¿™äº›ç‰¹å¾å›¾åº”ç”¨æ»‘åŠ¨çª—å£åŠ anchoræœºåˆ¶è¿›è¡Œç›®æ ‡åŒºåŸŸåˆ¤å®šå’Œåˆ†ç±»çš„,è¿™é‡Œçš„æ»‘çª—åŠ anchoræœºåˆ¶åŠŸèƒ½ç±»ä¼¼äºfast rcnnçš„selective searchç”Ÿæˆproposalsçš„ä½œç”¨,è€Œæˆ‘ä»¬æ˜¯é€šè¿‡RPNç”Ÿæˆproposals.RPNå°±æ˜¯ä¸€ä¸ªå·ç§¯å±‚ + relu +å·¦å³ä¸¤ä¸ªå±‚(cls layerå’Œreg layer)çš„å°å‹ç½‘ç»œ</p><h6 id="2-anchor"><a href="#2-anchor" class="headerlink" title="2.anchor"></a>2.anchor</h6><p>è®ºæ–‡å†…å®¹:The k proposals are parameterized relative to k reference boxes, which we call anchors;å¯ä»¥ç†è§£ä¸ºé”šç‚¹ä½äºä¹‹å‰è¯´çš„3 * 3çš„æ»‘çª—ä¸­å¿ƒå¤„,å°±æ˜¯å› ä¸ºæœ‰å¤šä¸ªanchor.è¿™9ä¸ªanchoræ˜¯ä½œè€…è®¾ç½®çš„,è®ºæ–‡ä¸­scale=[128,256,512],é•¿å®½æ¯”[1:1,1:2,2:1]æœ‰9ç§ï¼›è‡ªå·±å¯ä»¥æ ¹æ®ç›®æ ‡çš„ç‰¹ç‚¹åšå‡ºä¸åŒçš„è®¾è®¡;å¯¹äºä¸€å¹… w * hçš„feature mapä¸€å…±æœ‰w * h * kä¸ªé”šç‚¹.</p><img src="C:\Users\VrShadow\AppData\Roaming\Typora\typora-user-images\image-20211027213420072.png" alt="image-20211027213420072" style="zoom:50%;"><h6 id="3-VGGæå–ç‰¹å¾"><a href="#3-VGGæå–ç‰¹å¾" class="headerlink" title="3.VGGæå–ç‰¹å¾"></a>3.VGGæå–ç‰¹å¾</h6><p>VGGçš„ç½‘ç»œæµç¨‹å›¾:</p><img src="C:\Users\VrShadow\AppData\Roaming\Typora\typora-user-images\image-20211027213725540.png" alt="image-20211027213725540" style="zoom:67%;"><p>æ¯ä¸ªå·ç§¯å±‚åˆ©ç”¨å‰é¢ç½‘ç»œä¿¡æ¯ç”ŸæˆæŠ½è±¡æè¿°:<br>ç¬¬ä¸€å±‚å­¦ä¹ è¾¹ç¼˜edgesä¿¡æ¯ï¼›<br>ç¬¬äºŒå±‚:å­¦ä¹ è¾¹ç¼˜edgesä¸­å›¾æ¡ˆpatternsä»¥å­¦ä¹ æ›´åŠ å¤æ‚çš„å½¢çŠ¶ä¿¡æ¯ï¼›æœ€ç»ˆå¾—åˆ°å·ç§¯ç‰¹å¾å›¾å…¶ç©ºé—´ç»´åº¦(åˆ†è¾¨ç‡)æ¯”åŸå›¾å°äº†å¾ˆå¤šä½†æ›´æ·±ï¼›<br>ç‰¹å¾å›¾çš„widthå’Œheightç”±äºå·ç§¯å±‚é—´çš„æ± åŒ–å±‚è€Œé™ä½,è€Œdepthç”±äºå·ç§¯å±‚å­¦ä¹ çš„filtersæ•°é‡è€Œå¢åŠ .</p><h6 id="4-ROI-pooling"><a href="#4-ROI-pooling" class="headerlink" title="4.ROI pooling"></a>4.ROI pooling</h6><p>ROIå°±æ˜¯region of interestæŒ‡çš„æ˜¯æ„Ÿå…´è¶£åŒºåŸŸ;å¦‚æœæ˜¯åŸå›¾ï¼Œroiå°±æ˜¯ç›®æ ‡ï¼Œå¦‚æœæ˜¯featuremapï¼Œroiå°±æ˜¯ç‰¹å¾å›¾åƒç›®æ ‡çš„ç‰¹å¾äº†ï¼Œroiåœ¨è¿™é‡Œå°±æ˜¯ç»è¿‡RPNç½‘ç»œå¾—åˆ°çš„ï¼Œæ€»ä¹‹å°±æ˜¯ä¸€ä¸ªæ¡†ã€‚poolingå°±æ˜¯æ± åŒ–ã€‚æ‰€ä»¥ROI Poolingå°±æ˜¯Poolingçš„ä¸€ç§ï¼Œåªæ˜¯æ˜¯é’ˆå¯¹äºRoisçš„poolingæ“ä½œè€Œå·²ã€‚RPN å¤„ç†åï¼Œå¯ä»¥å¾—åˆ°ä¸€å †æ²¡æœ‰ class score çš„ object proposals.å¾…å¤„ç†é—®é¢˜ä¸ºï¼šå¦‚ä½•åˆ©ç”¨è¿™äº›proposalsåˆ†ç±».Roi poolingå±‚çš„è¿‡ç¨‹å°±æ˜¯ä¸ºäº†å°†ä¸åŒè¾“å…¥å°ºå¯¸çš„feature mapï¼ˆROIï¼‰æŠ å‡ºæ¥ï¼Œç„¶åresizeåˆ°ç»Ÿä¸€çš„å¤§å°.</p><p>ROI poolingå±‚çš„è¾“å…¥:</p><ol><li>ç‰¹å¾å›¾features map(è¿™ä¸ªç‰¹å¾å›¾å°±æ˜¯cnnå·ç§¯å‡ºæ¥ä»¥åç”¨äºå…±äº«çš„é‚£ä¸ªç‰¹å¾å›¾)</li><li>roiä¿¡æ¯:(å°±æ˜¯RPNç½‘ç»œçš„è¾“å‡º,ä¸€ä¸ªè¡¨ç¤ºæ‰€æœ‰ROIçš„N*5çŸ©é˜µ,Nè¡¨ç¤ºROIçš„æ•°ç›®;ç¬¬ä¸€åˆ—è¡¨ç¤ºå›¾åƒindex,å…¶ä½™å››åˆ—è¡¨ç¤ºå…¶ä½™çš„å·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡,åæ ‡ä¿¡æ¯æ˜¯å¯¹åº”åŸå›¾ä¸­çš„ç»å¯¹åæ ‡)</li></ol><p>ROI poolingå±‚çš„è¿‡ç¨‹:</p><p>é¦–å…ˆå°†RPNä¸­å¾—åˆ°çš„åŸå›¾ä¸­roiä¿¡æ¯æ˜ å°„åˆ°feature mapä¸ŠæŒ‰åŸå›¾ä¸featuremapçš„æ¯”ä¾‹ç¼©å°roiåæ ‡å°±è¡Œäº†ï¼‰ï¼Œç„¶åç»è¿‡æœ€å¤§æ± åŒ–ï¼Œæ± åŒ–åˆ°å›ºå®šå¤§å°wÃ—hã€‚ä½†è¿™ä¸ªpoolingä¸æ˜¯ä¸€èˆ¬çš„Poolingï¼Œè€Œæ˜¯å°†åŒºåŸŸç­‰åˆ†ï¼Œç„¶åå–æ¯ä¸€å°å—çš„æœ€å¤§å€¼ï¼Œæœ€åæ‰èƒ½å¾—åˆ°å›ºå®šå°ºå¯¸çš„roiã€‚</p><p>ä¹Ÿå°±æ˜¯ï¼š</p><p>æ ¹æ®è¾“å…¥çš„imageï¼Œå°†Roiæ˜ å°„åˆ°feature mapå¯¹åº”çš„ä½ç½®ï¼›<br>å°†æ˜ å°„åçš„åŒºåŸŸåˆ’åˆ†ä¸ºç›¸åŒå¤§å°çš„sectionsï¼ˆsectionsæ•°é‡å’Œè¾“å‡ºçš„ç»´åº¦ç›¸åŒï¼‰ï¼›<br>å¯¹æ¯ä¸ªsectionè¿›è¡Œmax poolingæ“ä½œï¼›<br>ROI poolingå±‚çš„è¾“å‡ºï¼š</p><p>ç»“æœæ˜¯ï¼Œç”±ä¸€ç»„å¤§å°å„å¼‚çš„çŸ©å½¢ï¼Œæˆ‘ä»¬å¿«é€Ÿè·å–åˆ°å…·æœ‰å›ºå®šå¤§å°çš„ç›¸åº”ç‰¹å¾å›¾ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒRoI pooling è¾“å‡ºçš„ç»´åº¦å®é™…ä¸Šå¹¶ä¸å–å†³äºè¾“å…¥ç‰¹å¾å›¾çš„å¤§å°ï¼Œä¹Ÿä¸å–å†³äºåŒºåŸŸææ¡ˆçš„å¤§å°ã€‚è¿™å®Œå…¨å–å†³äºæˆ‘ä»¬å°†åŒºåŸŸåˆ†æˆå‡ éƒ¨åˆ†ã€‚ä¹Ÿå°±æ˜¯ï¼Œbatchä¸ªroiçŸ©é˜µï¼Œæ¯ä¸€ä¸ªroiçŸ©é˜µä¸ºï¼šé€šé“æ•°xWxH,ä¹Ÿå°±æ˜¯ä»selective searchå¾—åˆ°batchä¸ªroiï¼Œç„¶åæ˜ å°„ä¸ºå›ºå®šå¤§å°ã€‚</p><h6 id="5-NMS"><a href="#5-NMS" class="headerlink" title="5.NMS"></a>5.NMS</h6><p>NMSï¼ˆNon Maximum Suppressionï¼Œéæå¤§å€¼æŠ‘åˆ¶ï¼‰ç”¨äºåæœŸçš„ç‰©ä½“å†—ä½™è¾¹ç•Œæ¡†å»é™¤ï¼Œå› ä¸ºç›®æ ‡æ£€æµ‹æœ€ç»ˆä¸€ä¸ªç›®æ ‡åªéœ€è¦ä¸€ä¸ªæ¡†ï¼Œæ‰€ä»¥è¦æŠŠå¤šä½™çš„æ¡†å¹²æ‰ï¼Œç•™ä¸‹æœ€å‡†ç¡®çš„é‚£ä¸ªã€‚</p><p>NMSçš„è¾“å…¥ï¼š</p><p>æ£€æµ‹åˆ°çš„Boxes(åŒä¸€ä¸ªç‰©ä½“å¯èƒ½è¢«æ£€æµ‹åˆ°å¾ˆå¤šBoxesï¼Œæ¯ä¸ªboxå‡æœ‰åˆ†ç±»score)</p><p>NMSçš„è¾“å‡ºï¼š</p><p>æœ€ä¼˜çš„Box.</p><h6 id="6-FC-layer"><a href="#6-FC-layer" class="headerlink" title="6.FC layer"></a>6.FC layer</h6><p>ç»è¿‡roi poolingå±‚ä¹‹åï¼Œbatch_size=300, proposal feature mapçš„å¤§å°æ˜¯7Ã—7,512-d,å¯¹ç‰¹å¾å›¾è¿›è¡Œå…¨è¿æ¥ï¼Œå‚ç…§ä¸‹å›¾ï¼Œæœ€ååŒæ ·åˆ©ç”¨Softmax Losså’ŒL1 Losså®Œæˆåˆ†ç±»å’Œå®šä½ã€‚</p><p><img src="C:\Users\VrShadow\AppData\Roaming\Typora\typora-user-images\image-20211027220232527.png" alt="image-20211027220232527"></p><p>é€šè¿‡å…¨è¿æ¥å±‚ä¸softmaxè®¡ç®—æ¯ä¸ªregion proposalå…·ä½“å±äºå“ªä¸ªç±»åˆ«ï¼ˆå¦‚äººï¼Œé©¬ï¼Œè½¦ç­‰ï¼‰ï¼Œè¾“å‡ºcls_probæ¦‚ç‡å‘é‡ï¼›åŒæ—¶å†æ¬¡åˆ©ç”¨bounding box regressionè·å¾—æ¯ä¸ªregion proposalçš„ä½ç½®åç§»é‡bbox_predï¼Œç”¨äºå›å½’è·å¾—æ›´åŠ ç²¾ç¡®çš„ç›®æ ‡æ£€æµ‹æ¡†</p><p>å³ä»PoI Poolingè·å–åˆ°7x7å¤§å°çš„proposal feature mapsåï¼Œé€šè¿‡å…¨è¿æ¥ä¸»è¦åšäº†ï¼š</p><p>é€šè¿‡å…¨è¿æ¥å’Œsoftmaxå¯¹region proposalsè¿›è¡Œå…·ä½“ç±»åˆ«çš„åˆ†ç±»ï¼›</p><p>å†æ¬¡å¯¹region proposalsè¿›è¡Œbounding box regressionï¼Œè·å–æ›´é«˜ç²¾åº¦çš„rectangle boxã€‚</p><h5 id="ä¸»è¦éƒ¨åˆ†"><a href="#ä¸»è¦éƒ¨åˆ†" class="headerlink" title="ä¸»è¦éƒ¨åˆ†"></a>ä¸»è¦éƒ¨åˆ†</h5><p><strong>Faster</strong> <strong>RCNN</strong>å…¶å®å¯ä»¥åˆ†ä¸ºå››éƒ¨åˆ†ä¸»è¦å†…å®¹</p><h6 id="1-Conv-Layer"><a href="#1-Conv-Layer" class="headerlink" title="1.Conv Layer"></a>1.Conv Layer</h6><p>ä½œä¸ºä¸€ç§CNNç›®æ ‡æ£€æµ‹æ–¹æ³•,Faster RCNNé¦–å…ˆä½¿ç”¨ä¸€ç»„åŸºç¡€çš„cnn+relu+poolingå±‚æå–imageçš„feature map,è¿™ä¸ªfeature mapè¢«å…±äº«ç”¨ç”¨äºåç»­RPNå±‚å’Œå…¨è¿æ¥å±‚</p><h6 id="2-Region-Proposal-NetWorks"><a href="#2-Region-Proposal-NetWorks" class="headerlink" title="2.Region Proposal NetWorks"></a>2.Region Proposal NetWorks</h6><p>RPNç½‘ç»œç”¨äºç”Ÿæˆregion proposals,è¯¥å±‚é€šè¿‡softmaxåˆ¤æ–­anchorså±äºpositiveè¿˜æ˜¯negative,å†åˆ©ç”¨bounding</p><p>box regressionä¿®æ­£anchorsè·å¾—ç²¾ç¡®çš„proposals</p><h6 id="3-Roi-Pooling"><a href="#3-Roi-Pooling" class="headerlink" title="3.Roi Pooling"></a>3.Roi Pooling</h6><p>è¯¥å±‚æ‰‹æœºè¾“å…¥çš„feature mapå’Œproposals,ç»¼åˆè¿™äº›ä¿¡æ¯ä¹‹åæå–proposals,ç»¼åˆè¿™äº›ä¿¡æ¯æå–proposals feature mapsé€å…¥åç»­å…¨è¿æ¥å±‚åˆ¤å®šç›®æ ‡ç±»åˆ«</p><h6 id="4-Classfication"><a href="#4-Classfication" class="headerlink" title="4.Classfication"></a>4.Classfication</h6><p>åˆ©ç”¨proposals feature mapè®¡ç®—proposalsçš„ç±»åˆ«åŒæ—¶å†æ¬¡bounding box regressionè·å¾—æ£€æµ‹æ¡†æœ€ç»ˆçš„ç²¾ç¡®ä½ç½®</p><img src="C:\Users\VrShadow\AppData\Roaming\Typora\typora-user-images\image-20211028212022996.png" alt="image-20211028212022996" style="zoom:67%;"><p>ä¸Šå›¾å±•ç¤ºäº†pythonç‰ˆæœ¬ä¸­çš„VGG16æ¨¡å‹ä¸­çš„faster rcnnçš„ç½‘ç»œç»“æ„å¯ä»¥æ¸…æ™°çš„çœ‹åˆ°è¯¥ç½‘ç»œå¯¹äºä¸€å¹…ä»»æ„å¤§å°çš„P*Qçš„å›¾åƒ:</p><ul><li>é¦–å…ˆå›ºå®šè‡³å¤§å°MÃ—Nç„¶åå°†MÃ—Nå›¾åƒé€å…¥ç½‘ç»œ;</li><li>è€ŒConv layer</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> cv </tag>
            
            <tag> RCNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dian2021å¤ä»¤è¥</title>
      <link href="/year/11/06/002/"/>
      <url>/year/11/06/002/</url>
      
        <content type="html"><![CDATA[<p>æŠ¥åå‚åŠ å¤ä»¤è¥èµ·åˆæ˜¯æƒ³èŠ±æ—¶é—´ç ”ç©¶AIæœºå™¨å­¦ä¹ é¢†åŸŸçš„ç»å…¸ç®—æ³•ï¼Œç„¶ååšäº†diançš„ä¸€ä¸ª<strong>lab</strong></p>]]></content>
      
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> dian </tag>
            
            <tag> æœºå™¨å­¦ä¹  </tag>
            
            <tag> CNNç®€æ˜“æ¡†æ¶æ­å»º </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SeqToSeq_Translation(Attention)</title>
      <link href="/year/09/27/seq2seq_translation_tutorial/"/>
      <url>/year/09/27/seq2seq_translation_tutorial/</url>
      
        <content type="html"><![CDATA[<pre class="line-numbers language-python"><code class="language-python"><span class="token operator">%</span>matplotlib inline<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>NLP From Scratch: Translation with a Sequence to Sequence Network and Attention</p><hr><p><strong>Author</strong>: <code>Sean Robertson &lt;https://github.com/spro/practical-pytorch&gt;</code>_</p><p>This is the third and final tutorial on doing â€œNLP From Scratchâ€, where we<br>write our own classes and functions to preprocess the data to do our NLP<br>modeling tasks. We hope after you complete this tutorial that youâ€™ll proceed to<br>learn how <code>torchtext</code> can handle much of this preprocessing for you in the<br>three tutorials immediately following this one.</p><p>In this project we will be teaching a neural network to translate from<br>French to English.</p><p>::</p><pre class="line-numbers language-yaml"><code class="language-yaml"><span class="token punctuation">[</span><span class="token key atrule">KEY</span><span class="token punctuation">:</span> <span class="token punctuation">></span> input<span class="token punctuation">,</span> = target<span class="token punctuation">,</span> &lt; output<span class="token punctuation">]</span><span class="token punctuation">></span> il est en train de peindre un tableau .= he is painting a picture .&lt; he is painting a picture .<span class="token punctuation">></span> pourquoi ne pas essayer ce vin delicieux <span class="token punctuation">?</span>= why not try that delicious wine <span class="token punctuation">?</span>&lt; why not try that delicious wine <span class="token punctuation">?</span><span class="token punctuation">></span> elle n est pas poete mais romanciere .= she is not a poet but a novelist .&lt; she not not a poet but a novelist .<span class="token punctuation">></span> vous etes trop maigre .= you re too skinny .&lt; you re all alone .<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>â€¦ to varying degrees of success.</p><p>This is made possible by the simple but powerful idea of the <code>sequence to sequence network &lt;https://arxiv.org/abs/1409.3215&gt;</code>__, in which two<br>recurrent neural networks work together to transform one sequence to<br>another. An encoder network condenses an input sequence into a vector,<br>and a decoder network unfolds that vector into a new sequence.</p><p>.. figure:: /_static/img/seq-seq-images/seq2seq.png<br>   :alt:</p><p>To improve upon this model weâ€™ll use an <code>attention mechanism &lt;https://arxiv.org/abs/1409.0473&gt;</code>__, which lets the decoder<br>learn to focus over a specific range of the input sequence.</p><p><strong>Recommended Reading:</strong></p><p>I assume you have at least installed PyTorch, know Python, and<br>understand Tensors:</p><ul><li> <a href="https://pytorch.org/">https://pytorch.org/</a> For installation instructions</li><li> :doc:<code>/beginner/deep_learning_60min_blitz</code> to get started with PyTorch in general</li><li> :doc:<code>/beginner/pytorch_with_examples</code> for a wide and deep overview</li><li> :doc:<code>/beginner/former_torchies_tutorial</code> if you are former Lua Torch user</li></ul><p>It would also be useful to know about Sequence to Sequence networks and<br>how they work:</p><ul><li><code>Learning Phrase Representations using RNN Encoder-Decoder for  Statistical Machine Translation &lt;https://arxiv.org/abs/1406.1078&gt;</code>__</li><li><code>Sequence to Sequence Learning with Neural  Networks &lt;https://arxiv.org/abs/1409.3215&gt;</code>__</li><li><code>Neural Machine Translation by Jointly Learning to Align and  Translate &lt;https://arxiv.org/abs/1409.0473&gt;</code>__</li><li> <code>A Neural Conversational Model &lt;https://arxiv.org/abs/1506.05869&gt;</code>__</li></ul><p>You will also find the previous tutorials on<br>:doc:<code>/intermediate/char_rnn_classification_tutorial</code><br>and :doc:<code>/intermediate/char_rnn_generation_tutorial</code><br>helpful as those concepts are very similar to the Encoder and Decoder<br>models, respectively.</p><p><strong>Requirements</strong></p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> __future__ <span class="token keyword">import</span> unicode_literals<span class="token punctuation">,</span> print_function<span class="token punctuation">,</span> division<span class="token keyword">from</span> io <span class="token keyword">import</span> open<span class="token keyword">import</span> unicodedata<span class="token keyword">import</span> string<span class="token keyword">import</span> re<span class="token keyword">import</span> random<span class="token keyword">import</span> torch<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">from</span> torch <span class="token keyword">import</span> optim<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> Fdevice <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="Loading-data-files"><a href="#Loading-data-files" class="headerlink" title="Loading data files"></a>Loading data files</h1><p>The data for this project is a set of many thousands of English to<br>French translation pairs.</p><p><code>This question on Open Data Stack Exchange &lt;https://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages&gt;</code>__<br>pointed me to the open translation site <a href="https://tatoeba.org/">https://tatoeba.org/</a> which has<br>downloads available at <a href="https://tatoeba.org/eng/downloads">https://tatoeba.org/eng/downloads</a> - and better<br>yet, someone did the extra work of splitting language pairs into<br>individual text files here: <a href="https://www.manythings.org/anki/">https://www.manythings.org/anki/</a></p><p>The English to French pairs are too big to include in the repo, so<br>download to <code>data/eng-fra.txt</code> before continuing. The file is a tab<br>separated list of translation pairs:</p><p>::</p><pre><code>I am cold.    J'ai froid.</code></pre><p>.. Note::<br>   Download the data from<br>   <code>here &lt;https://download.pytorch.org/tutorial/data.zip&gt;</code>_<br>   and extract it to the current directory.</p><p>Similar to the character encoding used in the character-level RNN<br>tutorials, we will be representing each word in a language as a one-hot<br>vector, or giant vector of zeros except for a single one (at the index<br>of the word). Compared to the dozens of characters that might exist in a<br>language, there are many many more words, so the encoding vector is much<br>larger. We will however cheat a bit and trim the data to only use a few<br>thousand words per language.</p><p>.. figure:: /_static/img/seq-seq-images/word-encoding.png<br>   :alt:</p><p>Weâ€™ll need a unique index per word to use as the inputs and targets of<br>the networks later. To keep track of all this we will use a helper class<br>called <code>Lang</code> which has word â†’ index (<code>word2index</code>) and index â†’ word<br>(<code>index2word</code>) dictionaries, as well as a count of each word<br><code>word2count</code> which will be used to replace rare words later.</p><pre class="line-numbers language-python"><code class="language-python">SOS_token <span class="token operator">=</span> <span class="token number">0</span>EOS_token <span class="token operator">=</span> <span class="token number">1</span><span class="token keyword">class</span> <span class="token class-name">Lang</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>name <span class="token operator">=</span> name        self<span class="token punctuation">.</span>word2index <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>        self<span class="token punctuation">.</span>word2count <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>        self<span class="token punctuation">.</span>index2word <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">"SOS"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">"EOS"</span><span class="token punctuation">}</span>        self<span class="token punctuation">.</span>n_words <span class="token operator">=</span> <span class="token number">2</span>  <span class="token comment" spellcheck="true"># Count SOS and EOS</span>    <span class="token keyword">def</span> <span class="token function">addSentence</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> word <span class="token keyword">in</span> sentence<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>addWord<span class="token punctuation">(</span>word<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">addWord</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> word<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> word <span class="token operator">not</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>word2index<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>word2index<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>n_words            self<span class="token punctuation">.</span>word2count<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>            self<span class="token punctuation">.</span>index2word<span class="token punctuation">[</span>self<span class="token punctuation">.</span>n_words<span class="token punctuation">]</span> <span class="token operator">=</span> word            self<span class="token punctuation">.</span>n_words <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>word2count<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>The files are all in Unicode, to simplify we will turn Unicode<br>characters to ASCII, make everything lowercase, and trim most<br>punctuation.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># Turn a Unicode string to plain ASCII, thanks to</span><span class="token comment" spellcheck="true"># https://stackoverflow.com/a/518232/2809427</span><span class="token keyword">def</span> <span class="token function">unicodeToAscii</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>        c <span class="token keyword">for</span> c <span class="token keyword">in</span> unicodedata<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span><span class="token string">'NFD'</span><span class="token punctuation">,</span> s<span class="token punctuation">)</span>        <span class="token keyword">if</span> unicodedata<span class="token punctuation">.</span>category<span class="token punctuation">(</span>c<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token string">'Mn'</span>    <span class="token punctuation">)</span><span class="token comment" spellcheck="true"># Lowercase, trim, and remove non-letter characters</span><span class="token keyword">def</span> <span class="token function">normalizeString</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>    s <span class="token operator">=</span> unicodeToAscii<span class="token punctuation">(</span>s<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    s <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>r<span class="token string">"([.!?])"</span><span class="token punctuation">,</span> r<span class="token string">" \1"</span><span class="token punctuation">,</span> s<span class="token punctuation">)</span>    s <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>r<span class="token string">"[^a-zA-Z.!?]+"</span><span class="token punctuation">,</span> r<span class="token string">" "</span><span class="token punctuation">,</span> s<span class="token punctuation">)</span>    <span class="token keyword">return</span> s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>To read the data file we will split the file into lines, and then split<br>lines into pairs. The files are all English â†’ Other Language, so if we<br>want to translate from Other Language â†’ English I added the <code>reverse</code><br>flag to reverse the pairs.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">readLangs</span><span class="token punctuation">(</span>lang1<span class="token punctuation">,</span> lang2<span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Reading lines..."</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Read the file and split into lines</span>    lines <span class="token operator">=</span> open<span class="token punctuation">(</span><span class="token string">'data/%s-%s.txt'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>lang1<span class="token punctuation">,</span> lang2<span class="token punctuation">)</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>\   <span class="token operator">//</span> ç›¸åº”æ•°æ®é›†ä¸‹è½½ä»¥åæ³¨æ„ç›¸å¯¹è·¯å¾„çš„è®¾ç½®        read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Split every line into pairs and normalize</span>    pairs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>normalizeString<span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token keyword">for</span> s <span class="token keyword">in</span> l<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> l <span class="token keyword">in</span> lines<span class="token punctuation">]</span>    <span class="token comment" spellcheck="true"># Reverse pairs, make Lang instances</span>    <span class="token keyword">if</span> reverse<span class="token punctuation">:</span>        pairs <span class="token operator">=</span> <span class="token punctuation">[</span>list<span class="token punctuation">(</span>reversed<span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> pairs<span class="token punctuation">]</span>        input_lang <span class="token operator">=</span> Lang<span class="token punctuation">(</span>lang2<span class="token punctuation">)</span>        output_lang <span class="token operator">=</span> Lang<span class="token punctuation">(</span>lang1<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        input_lang <span class="token operator">=</span> Lang<span class="token punctuation">(</span>lang1<span class="token punctuation">)</span>        output_lang <span class="token operator">=</span> Lang<span class="token punctuation">(</span>lang2<span class="token punctuation">)</span>    <span class="token keyword">return</span> input_lang<span class="token punctuation">,</span> output_lang<span class="token punctuation">,</span> pairs<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>Since there are a <em>lot</em> of example sentences and we want to train<br>something quickly, weâ€™ll trim the data set to only relatively short and<br>simple sentences. Here the maximum length is 10 words (that includes<br>ending punctuation) and weâ€™re filtering to sentences that translate to<br>the form â€œI amâ€ or â€œHe isâ€ etc. (accounting for apostrophes replaced<br>earlier).</p><pre class="line-numbers language-python"><code class="language-python">MAX_LENGTH <span class="token operator">=</span> <span class="token number">10</span>eng_prefixes <span class="token operator">=</span> <span class="token punctuation">(</span>    <span class="token string">"i am "</span><span class="token punctuation">,</span> <span class="token string">"i m "</span><span class="token punctuation">,</span>    <span class="token string">"he is"</span><span class="token punctuation">,</span> <span class="token string">"he s "</span><span class="token punctuation">,</span>    <span class="token string">"she is"</span><span class="token punctuation">,</span> <span class="token string">"she s "</span><span class="token punctuation">,</span>    <span class="token string">"you are"</span><span class="token punctuation">,</span> <span class="token string">"you re "</span><span class="token punctuation">,</span>    <span class="token string">"we are"</span><span class="token punctuation">,</span> <span class="token string">"we re "</span><span class="token punctuation">,</span>    <span class="token string">"they are"</span><span class="token punctuation">,</span> <span class="token string">"they re "</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">filterPair</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> len<span class="token punctuation">(</span>p<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> MAX_LENGTH <span class="token operator">and</span> \        len<span class="token punctuation">(</span>p<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> MAX_LENGTH <span class="token operator">and</span> \        p<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>startswith<span class="token punctuation">(</span>eng_prefixes<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">filterPairs</span><span class="token punctuation">(</span>pairs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token punctuation">[</span>pair <span class="token keyword">for</span> pair <span class="token keyword">in</span> pairs <span class="token keyword">if</span> filterPair<span class="token punctuation">(</span>pair<span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>The full process for preparing the data is:</p><ul><li> Read text file and split into lines, split lines into pairs</li><li> Normalize text, filter by length and content</li><li> Make word lists from sentences in pairs</li></ul><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">prepareData</span><span class="token punctuation">(</span>lang1<span class="token punctuation">,</span> lang2<span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    input_lang<span class="token punctuation">,</span> output_lang<span class="token punctuation">,</span> pairs <span class="token operator">=</span> readLangs<span class="token punctuation">(</span>lang1<span class="token punctuation">,</span> lang2<span class="token punctuation">,</span> reverse<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Read %s sentence pairs"</span> <span class="token operator">%</span> len<span class="token punctuation">(</span>pairs<span class="token punctuation">)</span><span class="token punctuation">)</span>    pairs <span class="token operator">=</span> filterPairs<span class="token punctuation">(</span>pairs<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Trimmed to %s sentence pairs"</span> <span class="token operator">%</span> len<span class="token punctuation">(</span>pairs<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Counting words..."</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> pair <span class="token keyword">in</span> pairs<span class="token punctuation">:</span>        input_lang<span class="token punctuation">.</span>addSentence<span class="token punctuation">(</span>pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        output_lang<span class="token punctuation">.</span>addSentence<span class="token punctuation">(</span>pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Counted words:"</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>input_lang<span class="token punctuation">.</span>name<span class="token punctuation">,</span> input_lang<span class="token punctuation">.</span>n_words<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>output_lang<span class="token punctuation">.</span>name<span class="token punctuation">,</span> output_lang<span class="token punctuation">.</span>n_words<span class="token punctuation">)</span>    <span class="token keyword">return</span> input_lang<span class="token punctuation">,</span> output_lang<span class="token punctuation">,</span> pairsinput_lang<span class="token punctuation">,</span> output_lang<span class="token punctuation">,</span> pairs <span class="token operator">=</span> prepareData<span class="token punctuation">(</span><span class="token string">'eng'</span><span class="token punctuation">,</span> <span class="token string">'fra'</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>pairs<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>Reading lines...Read 135842 sentence pairsTrimmed to 10599 sentence pairsCounting words...Counted words:fra 4345eng 2803['je suis lessive et fatigue .', 'i m broke and tired .']</code></pre><h1 id="The-Seq2Seq-Model"><a href="#The-Seq2Seq-Model" class="headerlink" title="The Seq2Seq Model"></a>The Seq2Seq Model</h1><p>A Recurrent Neural Network, or RNN, is a network that operates on a<br>sequence and uses its own output as input for subsequent steps.</p><p>A <code>Sequence to Sequence network &lt;https://arxiv.org/abs/1409.3215&gt;</code><strong>, or<br>seq2seq network, or <code>Encoder Decoder network &lt;https://arxiv.org/pdf/1406.1078v3.pdf&gt;</code></strong>, is a model<br>consisting of two RNNs called the encoder and decoder. The encoder reads<br>an input sequence and outputs a single vector, and the decoder reads<br>that vector to produce an output sequence.</p><p>.. figure:: /_static/img/seq-seq-images/seq2seq.png<br>   :alt:</p><p>Unlike sequence prediction with a single RNN, where every input<br>corresponds to an output, the seq2seq model frees us from sequence<br>length and order, which makes it ideal for translation between two<br>languages.</p><p>Consider the sentence â€œJe ne suis pas le chat noirâ€ â†’ â€œI am not the<br>black catâ€. Most of the words in the input sentence have a direct<br>translation in the output sentence, but are in slightly different<br>orders, e.g. â€œchat noirâ€ and â€œblack catâ€. Because of the â€œne/pasâ€<br>construction there is also one more word in the input sentence. It would<br>be difficult to produce a correct translation directly from the sequence<br>of input words.</p><p>With a seq2seq model the encoder creates a single vector which, in the<br>ideal case, encodes the â€œmeaningâ€ of the input sequence into a single<br>vector â€” a single point in some N dimensional space of sentences.</p><h2 id="The-Encoder"><a href="#The-Encoder" class="headerlink" title="The Encoder"></a>The Encoder</h2><p>The encoder of a seq2seq network is a RNN that outputs some value for<br>every word from the input sentence. For every input word the encoder<br>outputs a vector and a hidden state, and uses the hidden state for the<br>next input word.</p><p>.. figure:: /_static/img/seq-seq-images/encoder-network.png<br>   :alt:</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">EncoderRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>EncoderRNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>gru <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span><span class="token punctuation">:</span>        embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>input<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        output <span class="token operator">=</span> embedded        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>gru<span class="token punctuation">(</span>output<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>        <span class="token keyword">return</span> output<span class="token punctuation">,</span> hidden    <span class="token keyword">def</span> <span class="token function">initHidden</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="The-Decoder"><a href="#The-Decoder" class="headerlink" title="The Decoder"></a>The Decoder</h2><p>The decoder is another RNN that takes the encoder output vector(s) and<br>outputs a sequence of words to create the translation.</p><p>Simple Decoder<br>^^^^^^^^^^^^^^</p><p>In the simplest seq2seq decoder we use only last output of the encoder.<br>This last output is sometimes called the <em>context vector</em> as it encodes<br>context from the entire sequence. This context vector is used as the<br>initial hidden state of the decoder.</p><p>At every step of decoding, the decoder is given an input token and<br>hidden state. The initial input token is the start-of-string <code>&lt;SOS&gt;</code><br>token, and the first hidden state is the context vector (the encoderâ€™s<br>last hidden state).</p><p>.. figure:: /_static/img/seq-seq-images/decoder-network.png<br>   :alt:</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DecoderRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>DecoderRNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>output_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>gru <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>LogSoftmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span><span class="token punctuation">:</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>input<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        output <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>output<span class="token punctuation">)</span>        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>gru<span class="token punctuation">(</span>output<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>output<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> output<span class="token punctuation">,</span> hidden    <span class="token keyword">def</span> <span class="token function">initHidden</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>I encourage you to train and observe the results of this model, but to<br>save space weâ€™ll be going straight for the gold and introducing the<br>Attention Mechanism.</p><p>Attention Decoder<br>^^^^^^^^^^^^^^^^^</p><p>If only the context vector is passed between the encoder and decoder,<br>that single vector carries the burden of encoding the entire sentence.</p><p>Attention allows the decoder network to â€œfocusâ€ on a different part of<br>the encoderâ€™s outputs for every step of the decoderâ€™s own outputs. First<br>we calculate a set of <em>attention weights</em>. These will be multiplied by<br>the encoder output vectors to create a weighted combination. The result<br>(called <code>attn_applied</code> in the code) should contain information about<br>that specific part of the input sequence, and thus help the decoder<br>choose the right output words.</p><p>.. figure:: <a href="https://i.imgur.com/1152PYf.png">https://i.imgur.com/1152PYf.png</a><br>   :alt:</p><p>Calculating the attention weights is done with another feed-forward<br>layer <code>attn</code>, using the decoderâ€™s input and hidden state as inputs.<br>Because there are sentences of all sizes in the training data, to<br>actually create and train this layer we have to choose a maximum<br>sentence length (input length, for encoder outputs) that it can apply<br>to. Sentences of the maximum length will use all the attention weights,<br>while shorter sentences will only use the first few.</p><p>.. figure:: /_static/img/seq-seq-images/attention-decoder-network.png<br>   :alt:</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">AttnDecoderRNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> output_size<span class="token punctuation">,</span> dropout_p<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span>MAX_LENGTH<span class="token punctuation">)</span><span class="token punctuation">:</span>        super<span class="token punctuation">(</span>AttnDecoderRNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size        self<span class="token punctuation">.</span>output_size <span class="token operator">=</span> output_size        self<span class="token punctuation">.</span>dropout_p <span class="token operator">=</span> dropout_p        self<span class="token punctuation">.</span>max_length <span class="token operator">=</span> max_length        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>self<span class="token punctuation">.</span>output_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attn <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>max_length<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attn_combine <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout_p<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>gru <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>output_size<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input<span class="token punctuation">,</span> hidden<span class="token punctuation">,</span> encoder_outputs<span class="token punctuation">)</span><span class="token punctuation">:</span>        embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>input<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>embedded<span class="token punctuation">)</span>        attn_weights <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>            self<span class="token punctuation">.</span>attn<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>embedded<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hidden<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        attn_applied <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>attn_weights<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                                 encoder_outputs<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        output <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>embedded<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> attn_applied<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>attn_combine<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>        output <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>output<span class="token punctuation">)</span>        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>gru<span class="token punctuation">(</span>output<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>        output <span class="token operator">=</span> F<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>output<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> output<span class="token punctuation">,</span> hidden<span class="token punctuation">,</span> attn_weights    <span class="token keyword">def</span> <span class="token function">initHidden</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><div class="alert alert-info"><h4>Note</h4><p>There are other forms of attention that work around the length  limitation by using a relative position approach. Read about "local  attention" in `Effective Approaches to Attention-based Neural Machine  Translation <https: arxiv.org="" abs="" 1508.04025="">`__.</https:></p></div><h1 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h1><h2 id="Preparing-Training-Data"><a href="#Preparing-Training-Data" class="headerlink" title="Preparing Training Data"></a>Preparing Training Data</h2><p>To train, for each pair we will need an input tensor (indexes of the<br>words in the input sentence) and target tensor (indexes of the words in<br>the target sentence). While creating these vectors we will append the<br>EOS token to both sequences.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">indexesFromSentence</span><span class="token punctuation">(</span>lang<span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> <span class="token punctuation">[</span>lang<span class="token punctuation">.</span>word2index<span class="token punctuation">[</span>word<span class="token punctuation">]</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> sentence<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token keyword">def</span> <span class="token function">tensorFromSentence</span><span class="token punctuation">(</span>lang<span class="token punctuation">,</span> sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>    indexes <span class="token operator">=</span> indexesFromSentence<span class="token punctuation">(</span>lang<span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>    indexes<span class="token punctuation">.</span>append<span class="token punctuation">(</span>EOS_token<span class="token punctuation">)</span>    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>indexes<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>long<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">tensorsFromPair</span><span class="token punctuation">(</span>pair<span class="token punctuation">)</span><span class="token punctuation">:</span>    input_tensor <span class="token operator">=</span> tensorFromSentence<span class="token punctuation">(</span>input_lang<span class="token punctuation">,</span> pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    target_tensor <span class="token operator">=</span> tensorFromSentence<span class="token punctuation">(</span>output_lang<span class="token punctuation">,</span> pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token punctuation">(</span>input_tensor<span class="token punctuation">,</span> target_tensor<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Training-the-Model"><a href="#Training-the-Model" class="headerlink" title="Training the Model"></a>Training the Model</h2><p>To train we run the input sentence through the encoder, and keep track<br>of every output and the latest hidden state. Then the decoder is given<br>the <code>&lt;SOS&gt;</code> token as its first input, and the last hidden state of the<br>encoder as its first hidden state.</p><p>â€œTeacher forcingâ€ is the concept of using the real target outputs as<br>each next input, instead of using the decoderâ€™s guess as the next input.<br>Using teacher forcing causes it to converge faster but <code>when the trained network is exploited, it may exhibit instability &lt;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&amp;rep=rep1&amp;type=pdf&gt;</code>__.</p><p>You can observe outputs of teacher-forced networks that read with<br>coherent grammar but wander far from the correct translation -<br>intuitively it has learned to represent the output grammar and can â€œpick<br>upâ€ the meaning once the teacher tells it the first few words, but it<br>has not properly learned how to create the sentence from the translation<br>in the first place.</p><p>Because of the freedom PyTorchâ€™s autograd gives us, we can randomly<br>choose to use teacher forcing or not with a simple if statement. Turn<br><code>teacher_forcing_ratio</code> up to use more of it.</p><pre class="line-numbers language-python"><code class="language-python">teacher_forcing_ratio <span class="token operator">=</span> <span class="token number">0.5</span><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>input_tensor<span class="token punctuation">,</span> target_tensor<span class="token punctuation">,</span> encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">,</span> encoder_optimizer<span class="token punctuation">,</span> decoder_optimizer<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> max_length<span class="token operator">=</span>MAX_LENGTH<span class="token punctuation">)</span><span class="token punctuation">:</span>    encoder_hidden <span class="token operator">=</span> encoder<span class="token punctuation">.</span>initHidden<span class="token punctuation">(</span><span class="token punctuation">)</span>    encoder_optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    decoder_optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    input_length <span class="token operator">=</span> input_tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    target_length <span class="token operator">=</span> target_tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>    encoder_outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>max_length<span class="token punctuation">,</span> encoder<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>    loss <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">for</span> ei <span class="token keyword">in</span> range<span class="token punctuation">(</span>input_length<span class="token punctuation">)</span><span class="token punctuation">:</span>        encoder_output<span class="token punctuation">,</span> encoder_hidden <span class="token operator">=</span> encoder<span class="token punctuation">(</span>            input_tensor<span class="token punctuation">[</span>ei<span class="token punctuation">]</span><span class="token punctuation">,</span> encoder_hidden<span class="token punctuation">)</span>        encoder_outputs<span class="token punctuation">[</span>ei<span class="token punctuation">]</span> <span class="token operator">=</span> encoder_output<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>    decoder_input <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>SOS_token<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>    decoder_hidden <span class="token operator">=</span> encoder_hidden    use_teacher_forcing <span class="token operator">=</span> <span class="token boolean">True</span> <span class="token keyword">if</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> teacher_forcing_ratio <span class="token keyword">else</span> <span class="token boolean">False</span>    <span class="token keyword">if</span> use_teacher_forcing<span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Teacher forcing: Feed the target as the next input</span>        <span class="token keyword">for</span> di <span class="token keyword">in</span> range<span class="token punctuation">(</span>target_length<span class="token punctuation">)</span><span class="token punctuation">:</span>            decoder_output<span class="token punctuation">,</span> decoder_hidden<span class="token punctuation">,</span> decoder_attention <span class="token operator">=</span> decoder<span class="token punctuation">(</span>                decoder_input<span class="token punctuation">,</span> decoder_hidden<span class="token punctuation">,</span> encoder_outputs<span class="token punctuation">)</span>            loss <span class="token operator">+=</span> criterion<span class="token punctuation">(</span>decoder_output<span class="token punctuation">,</span> target_tensor<span class="token punctuation">[</span>di<span class="token punctuation">]</span><span class="token punctuation">)</span>            decoder_input <span class="token operator">=</span> target_tensor<span class="token punctuation">[</span>di<span class="token punctuation">]</span>  <span class="token comment" spellcheck="true"># Teacher forcing</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># Without teacher forcing: use its own predictions as the next input</span>        <span class="token keyword">for</span> di <span class="token keyword">in</span> range<span class="token punctuation">(</span>target_length<span class="token punctuation">)</span><span class="token punctuation">:</span>            decoder_output<span class="token punctuation">,</span> decoder_hidden<span class="token punctuation">,</span> decoder_attention <span class="token operator">=</span> decoder<span class="token punctuation">(</span>                decoder_input<span class="token punctuation">,</span> decoder_hidden<span class="token punctuation">,</span> encoder_outputs<span class="token punctuation">)</span>            topv<span class="token punctuation">,</span> topi <span class="token operator">=</span> decoder_output<span class="token punctuation">.</span>topk<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            decoder_input <span class="token operator">=</span> topi<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># detach from history as input</span>            loss <span class="token operator">+=</span> criterion<span class="token punctuation">(</span>decoder_output<span class="token punctuation">,</span> target_tensor<span class="token punctuation">[</span>di<span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> decoder_input<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> EOS_token<span class="token punctuation">:</span>                <span class="token keyword">break</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    encoder_optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    decoder_optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> target_length<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>This is a helper function to print time elapsed and estimated time<br>remaining given the current time and progress %.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> time<span class="token keyword">import</span> math<span class="token keyword">def</span> <span class="token function">asMinutes</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>    m <span class="token operator">=</span> math<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>s <span class="token operator">/</span> <span class="token number">60</span><span class="token punctuation">)</span>    s <span class="token operator">-=</span> m <span class="token operator">*</span> <span class="token number">60</span>    <span class="token keyword">return</span> <span class="token string">'%dm %ds'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>m<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">timeSince</span><span class="token punctuation">(</span>since<span class="token punctuation">,</span> percent<span class="token punctuation">)</span><span class="token punctuation">:</span>    now <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    s <span class="token operator">=</span> now <span class="token operator">-</span> since    es <span class="token operator">=</span> s <span class="token operator">/</span> <span class="token punctuation">(</span>percent<span class="token punctuation">)</span>    rs <span class="token operator">=</span> es <span class="token operator">-</span> s    <span class="token keyword">return</span> <span class="token string">'%s (- %s)'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>asMinutes<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">,</span> asMinutes<span class="token punctuation">(</span>rs<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>The whole training process looks like this:</p><ul><li> Start a timer</li><li> Initialize optimizers and criterion</li><li> Create set of training pairs</li><li> Start empty losses array for plotting</li></ul><p>Then we call <code>train</code> many times and occasionally print the progress (%<br>of examples, time so far, estimated time) and average loss.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">trainIters</span><span class="token punctuation">(</span>encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">,</span> n_iters<span class="token punctuation">,</span> print_every<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> plot_every<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> learning_rate<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    plot_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    print_loss_total <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment" spellcheck="true"># Reset every print_every</span>    plot_loss_total <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment" spellcheck="true"># Reset every plot_every</span>    encoder_optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>encoder<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>    decoder_optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>decoder<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>    training_pairs <span class="token operator">=</span> <span class="token punctuation">[</span>tensorsFromPair<span class="token punctuation">(</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>pairs<span class="token punctuation">)</span><span class="token punctuation">)</span>                      <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n_iters<span class="token punctuation">)</span><span class="token punctuation">]</span>    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>NLLLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> iter <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n_iters <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        training_pair <span class="token operator">=</span> training_pairs<span class="token punctuation">[</span>iter <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span>        input_tensor <span class="token operator">=</span> training_pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        target_tensor <span class="token operator">=</span> training_pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        loss <span class="token operator">=</span> train<span class="token punctuation">(</span>input_tensor<span class="token punctuation">,</span> target_tensor<span class="token punctuation">,</span> encoder<span class="token punctuation">,</span>                     decoder<span class="token punctuation">,</span> encoder_optimizer<span class="token punctuation">,</span> decoder_optimizer<span class="token punctuation">,</span> criterion<span class="token punctuation">)</span>        print_loss_total <span class="token operator">+=</span> loss        plot_loss_total <span class="token operator">+=</span> loss        <span class="token keyword">if</span> iter <span class="token operator">%</span> print_every <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            print_loss_avg <span class="token operator">=</span> print_loss_total <span class="token operator">/</span> print_every            print_loss_total <span class="token operator">=</span> <span class="token number">0</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'%s (%d %d%%) %.4f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>timeSince<span class="token punctuation">(</span>start<span class="token punctuation">,</span> iter <span class="token operator">/</span> n_iters<span class="token punctuation">)</span><span class="token punctuation">,</span>                                         iter<span class="token punctuation">,</span> iter <span class="token operator">/</span> n_iters <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">,</span> print_loss_avg<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> iter <span class="token operator">%</span> plot_every <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            plot_loss_avg <span class="token operator">=</span> plot_loss_total <span class="token operator">/</span> plot_every            plot_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>plot_loss_avg<span class="token punctuation">)</span>            plot_loss_total <span class="token operator">=</span> <span class="token number">0</span>    showPlot<span class="token punctuation">(</span>plot_losses<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Plotting-results"><a href="#Plotting-results" class="headerlink" title="Plotting results"></a>Plotting results</h2><p>Plotting is done with matplotlib, using the array of loss values<br><code>plot_losses</code> saved while training.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>switch_backend<span class="token punctuation">(</span><span class="token string">'agg'</span><span class="token punctuation">)</span><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>ticker <span class="token keyword">as</span> ticker<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">def</span> <span class="token function">showPlot</span><span class="token punctuation">(</span>points<span class="token punctuation">)</span><span class="token punctuation">:</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>    fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># this locator puts ticks at regular intervals</span>    loc <span class="token operator">=</span> ticker<span class="token punctuation">.</span>MultipleLocator<span class="token punctuation">(</span>base<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>    ax<span class="token punctuation">.</span>yaxis<span class="token punctuation">.</span>set_major_locator<span class="token punctuation">(</span>loc<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>points<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h1><p>Evaluation is mostly the same as training, but there are no targets so<br>we simply feed the decoderâ€™s predictions back to itself for each step.<br>Every time it predicts a word we add it to the output string, and if it<br>predicts the EOS token we stop there. We also store the decoderâ€™s<br>attention outputs for display later.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">,</span> sentence<span class="token punctuation">,</span> max_length<span class="token operator">=</span>MAX_LENGTH<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        input_tensor <span class="token operator">=</span> tensorFromSentence<span class="token punctuation">(</span>input_lang<span class="token punctuation">,</span> sentence<span class="token punctuation">)</span>        input_length <span class="token operator">=</span> input_tensor<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        encoder_hidden <span class="token operator">=</span> encoder<span class="token punctuation">.</span>initHidden<span class="token punctuation">(</span><span class="token punctuation">)</span>        encoder_outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>max_length<span class="token punctuation">,</span> encoder<span class="token punctuation">.</span>hidden_size<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>        <span class="token keyword">for</span> ei <span class="token keyword">in</span> range<span class="token punctuation">(</span>input_length<span class="token punctuation">)</span><span class="token punctuation">:</span>            encoder_output<span class="token punctuation">,</span> encoder_hidden <span class="token operator">=</span> encoder<span class="token punctuation">(</span>input_tensor<span class="token punctuation">[</span>ei<span class="token punctuation">]</span><span class="token punctuation">,</span>                                                     encoder_hidden<span class="token punctuation">)</span>            encoder_outputs<span class="token punctuation">[</span>ei<span class="token punctuation">]</span> <span class="token operator">+=</span> encoder_output<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>        decoder_input <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>SOS_token<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># SOS</span>        decoder_hidden <span class="token operator">=</span> encoder_hidden        decoded_words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        decoder_attentions <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>max_length<span class="token punctuation">,</span> max_length<span class="token punctuation">)</span>        <span class="token keyword">for</span> di <span class="token keyword">in</span> range<span class="token punctuation">(</span>max_length<span class="token punctuation">)</span><span class="token punctuation">:</span>            decoder_output<span class="token punctuation">,</span> decoder_hidden<span class="token punctuation">,</span> decoder_attention <span class="token operator">=</span> decoder<span class="token punctuation">(</span>                decoder_input<span class="token punctuation">,</span> decoder_hidden<span class="token punctuation">,</span> encoder_outputs<span class="token punctuation">)</span>            decoder_attentions<span class="token punctuation">[</span>di<span class="token punctuation">]</span> <span class="token operator">=</span> decoder_attention<span class="token punctuation">.</span>data            topv<span class="token punctuation">,</span> topi <span class="token operator">=</span> decoder_output<span class="token punctuation">.</span>data<span class="token punctuation">.</span>topk<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> topi<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> EOS_token<span class="token punctuation">:</span>                decoded_words<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'&lt;EOS>'</span><span class="token punctuation">)</span>                <span class="token keyword">break</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                decoded_words<span class="token punctuation">.</span>append<span class="token punctuation">(</span>output_lang<span class="token punctuation">.</span>index2word<span class="token punctuation">[</span>topi<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            decoder_input <span class="token operator">=</span> topi<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> decoded_words<span class="token punctuation">,</span> decoder_attentions<span class="token punctuation">[</span><span class="token punctuation">:</span>di <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>We can evaluate random sentences from the training set and print out the<br>input, target, and output to make some subjective quality judgements:</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">evaluateRandomly</span><span class="token punctuation">(</span>encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>        pair <span class="token operator">=</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>pairs<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'>'</span><span class="token punctuation">,</span> pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'='</span><span class="token punctuation">,</span> pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        output_words<span class="token punctuation">,</span> attentions <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">,</span> pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        output_sentence <span class="token operator">=</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>output_words<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'&lt;'</span><span class="token punctuation">,</span> output_sentence<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="Training-and-Evaluating"><a href="#Training-and-Evaluating" class="headerlink" title="Training and Evaluating"></a>Training and Evaluating</h1><p>With all these helper functions in place (it looks like extra work, but<br>it makes it easier to run multiple experiments) we can actually<br>initialize a network and start training.</p><p>Remember that the input sentences were heavily filtered. For this small<br>dataset we can use relatively small networks of 256 hidden nodes and a<br>single GRU layer. After about 40 minutes on a MacBook CPU weâ€™ll get some<br>reasonable results.</p><p>.. Note::<br>   If you run this notebook you can train, interrupt the kernel,<br>   evaluate, and continue training later. Comment out the lines where the<br>   encoder and decoder are initialized and run <code>trainIters</code> again.</p><pre class="line-numbers language-python"><code class="language-python">hidden_size <span class="token operator">=</span> <span class="token number">20</span>encoder1 <span class="token operator">=</span> EncoderRNN<span class="token punctuation">(</span>input_lang<span class="token punctuation">.</span>n_words<span class="token punctuation">,</span> hidden_size<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>attn_decoder1 <span class="token operator">=</span> AttnDecoderRNN<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> output_lang<span class="token punctuation">.</span>n_words<span class="token punctuation">,</span> dropout_p<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>trainIters<span class="token punctuation">(</span>encoder1<span class="token punctuation">,</span> attn_decoder1<span class="token punctuation">,</span> <span class="token number">75000</span><span class="token punctuation">,</span> print_every<span class="token operator">=</span><span class="token number">5000</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>2m 24s (- 33m 37s) (5000 6%) 3.37745m 0s (- 32m 31s) (10000 13%) 2.86507m 36s (- 30m 26s) (15000 20%) 2.736810m 9s (- 27m 56s) (20000 26%) 2.655212m 38s (- 25m 17s) (25000 33%) 2.582015m 17s (- 22m 55s) (30000 40%) 2.538217m 50s (- 20m 23s) (35000 46%) 2.521520m 30s (- 17m 57s) (40000 53%) 2.459122m 51s (- 15m 14s) (45000 60%) 2.425925m 22s (- 12m 41s) (50000 66%) 2.362327m 50s (- 10m 7s) (55000 73%) 2.340230m 22s (- 7m 35s) (60000 80%) 2.308033m 3s (- 5m 5s) (65000 86%) 2.272235m 38s (- 2m 32s) (70000 93%) 2.276438m 20s (- 0m 0s) (75000 100%) 2.2802</code></pre><pre class="line-numbers language-python"><code class="language-python">evaluateRandomly<span class="token punctuation">(</span>encoder1<span class="token punctuation">,</span> attn_decoder1<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre><code>&gt; il s en met plein les poches .= he s raking it in .&lt; he s always to the . . &lt;EOS&gt;&gt; je suis en train de griller du poisson .= i am grilling fish .&lt; i m a . . &lt;EOS&gt;&gt; c est un mannequin .= she s a model .&lt; he s a nice . &lt;EOS&gt;&gt; il n est pas un saint .= he s no saint .&lt; he s not a . . &lt;EOS&gt;&gt; je n abandonne pas .= i m not giving up .&lt; i m not alone . &lt;EOS&gt;&gt; vous etes jeunes .= you re young .&lt; you re a . &lt;EOS&gt;&gt; il fait un super boulot .= he is doing a super job .&lt; he s a to of . . &lt;EOS&gt;&gt; tu es trop maigre .= you re too skinny .&lt; you re very busy . &lt;EOS&gt;&gt; je ne suis pas intimide .= i m not intimidated .&lt; i m not alone . &lt;EOS&gt;&gt; il est plus fort que moi .= he s stronger than me .&lt; he s not as . &lt;EOS&gt;</code></pre><p>â€‹    </p><h2 id="Visualizing-Attention"><a href="#Visualizing-Attention" class="headerlink" title="Visualizing Attention"></a>Visualizing Attention</h2><p>A useful property of the attention mechanism is its highly interpretable<br>outputs. Because it is used to weight specific encoder outputs of the<br>input sequence, we can imagine looking where the network is focused most<br>at each time step.</p><p>You could simply run <code>plt.matshow(attentions)</code> to see attention output<br>displayed as a matrix, with the columns being input steps and rows being<br>output steps:</p><pre class="line-numbers language-python"><code class="language-python">output_words<span class="token punctuation">,</span> attentions <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>    encoder1<span class="token punctuation">,</span> attn_decoder1<span class="token punctuation">,</span> <span class="token string">"je suis trop froid ."</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>matshow<span class="token punctuation">(</span>attentions<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre><code>&lt;matplotlib.image.AxesImage at 0x7f68d8ef77b8&gt;</code></pre><p>For a better viewing experience we will do the extra work of adding axes<br>and labels:</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">showAttention</span><span class="token punctuation">(</span>input_sentence<span class="token punctuation">,</span> output_words<span class="token punctuation">,</span> attentions<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># Set up figure with colorbar</span>    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>    ax <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">111</span><span class="token punctuation">)</span>    cax <span class="token operator">=</span> ax<span class="token punctuation">.</span>matshow<span class="token punctuation">(</span>attentions<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'bone'</span><span class="token punctuation">)</span>    fig<span class="token punctuation">.</span>colorbar<span class="token punctuation">(</span>cax<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Set up axes</span>    ax<span class="token punctuation">.</span>set_xticklabels<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">''</span><span class="token punctuation">]</span> <span class="token operator">+</span> input_sentence<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span> <span class="token operator">+</span>                       <span class="token punctuation">[</span><span class="token string">'&lt;EOS>'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> rotation<span class="token operator">=</span><span class="token number">90</span><span class="token punctuation">)</span>    ax<span class="token punctuation">.</span>set_yticklabels<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">''</span><span class="token punctuation">]</span> <span class="token operator">+</span> output_words<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># Show label at every tick</span>    ax<span class="token punctuation">.</span>xaxis<span class="token punctuation">.</span>set_major_locator<span class="token punctuation">(</span>ticker<span class="token punctuation">.</span>MultipleLocator<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    ax<span class="token punctuation">.</span>yaxis<span class="token punctuation">.</span>set_major_locator<span class="token punctuation">(</span>ticker<span class="token punctuation">.</span>MultipleLocator<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">evaluateAndShowAttention</span><span class="token punctuation">(</span>input_sentence<span class="token punctuation">)</span><span class="token punctuation">:</span>    output_words<span class="token punctuation">,</span> attentions <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>        encoder1<span class="token punctuation">,</span> attn_decoder1<span class="token punctuation">,</span> input_sentence<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'input ='</span><span class="token punctuation">,</span> input_sentence<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'output ='</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>output_words<span class="token punctuation">)</span><span class="token punctuation">)</span>    showAttention<span class="token punctuation">(</span>input_sentence<span class="token punctuation">,</span> output_words<span class="token punctuation">,</span> attentions<span class="token punctuation">)</span>evaluateAndShowAttention<span class="token punctuation">(</span><span class="token string">"elle a cinq ans de moins que moi ."</span><span class="token punctuation">)</span>evaluateAndShowAttention<span class="token punctuation">(</span><span class="token string">"elle est trop petit ."</span><span class="token punctuation">)</span>evaluateAndShowAttention<span class="token punctuation">(</span><span class="token string">"je ne crains pas de mourir ."</span><span class="token punctuation">)</span>evaluateAndShowAttention<span class="token punctuation">(</span><span class="token string">"c est un jeune directeur plein de talent ."</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre><code>input = elle a cinq ans de moins que moi .output = she is always to of as me . &lt;EOS&gt;input = elle est trop petit .output = she is very nice . &lt;EOS&gt;input = je ne crains pas de mourir .output = i m not going to . . &lt;EOS&gt;input = c est un jeune directeur plein de talent .output = he s a a man . &lt;EOS&gt;</code></pre><h1 id="Exercises"><a href="#Exercises" class="headerlink" title="Exercises"></a>Exercises</h1><ul><li><p>Try with a different dataset</p><ul><li> Another language pair</li><li> Human â†’ Machine (e.g. IOT commands)</li><li> Chat â†’ Response</li><li> Question â†’ Answer</li></ul></li><li><p>Replace the embeddings with pre-trained word embeddings such as word2vec or<br> GloVe</p></li><li><p>Try with more layers, more hidden units, and more sentences. Compare<br> the training time and results.</p></li><li><p>If you use a translation file where pairs have two of the same phrase<br> (<code>I am test \t I am test</code>), you can use this as an autoencoder. Try<br> this:</p><ul><li> Train as an autoencoder</li><li> Save only the Encoder network</li><li> Train a new Decoder for translation from there</li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> è®ºæ–‡å¤ç° </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>sshè¿œç¨‹è¿æ¥æœåŠ¡å™¨</title>
      <link href="/year/09/21/004/"/>
      <url>/year/09/21/004/</url>
      
        <content type="html"><![CDATA[<p>â€‹    æœ¬æ–‡ç®€å•ä»‹ç»sshè¿œç¨‹è¿æ¥å®éªŒå®¤æœåŠ¡å™¨çš„æ­¥éª¤ï¼Œè¸©å‘è®¸å¤šï¼Œå¾ˆå¤šåŸç†ä¾æ—§ä¸æ‡‚ï¼Œä½†æœ€åå®ç°:</p><ul><li>è¿æ¥å®éªŒå®¤ç½‘ç»œåå†…ç½‘è¿æ¥è¿œç¨‹æœåŠ¡å™¨åŠŸèƒ½</li><li>é…ç½®æœ¬åœ°å¯†é’¥å’Œè¿œç¨‹æœåŠ¡å™¨ç”¨æˆ·å¯†é’¥ä½¿å…¶å…å¯†é’¥åŠŸèƒ½</li><li>2021/09/25æ›´æ–°ï¼šå®ç°å¤–ç½‘è¿æ¥å®éªŒå®¤æœåŠ¡å™¨çš„åŠŸèƒ½</li></ul><h5 id="1-å®ç°è¿œç¨‹è¿æ¥æœåŠ¡å™¨"><a href="#1-å®ç°è¿œç¨‹è¿æ¥æœåŠ¡å™¨" class="headerlink" title="1.å®ç°è¿œç¨‹è¿æ¥æœåŠ¡å™¨"></a>1.å®ç°è¿œç¨‹è¿æ¥æœåŠ¡å™¨</h5><h6 id="1-æœ¬åœ°æœåŠ¡å‡†å¤‡"><a href="#1-æœ¬åœ°æœåŠ¡å‡†å¤‡" class="headerlink" title="1.æœ¬åœ°æœåŠ¡å‡†å¤‡"></a>1.æœ¬åœ°æœåŠ¡å‡†å¤‡</h6><p>æœ¬åœ°ä¸»æœºä¸Šæ‰“å¼€windows terminalçª—å£(ç°åœ¨çš„windowsä¸€èˆ¬ä¼šè‡ªåŠ¨å®‰è£…openSSHå®¢æˆ·ç«¯å’ŒæœåŠ¡ç«¯),æ‰§è¡Œå‘½ä»¤ï¼š</p><pre class="line-numbers language-none"><code class="language-none">ssh-keygen -t rsa<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>æ‰§è¡Œå‘½ä»¤åä¼šåœ¨<code>.ssh</code>æ–‡ä»¶ä¸‹ç”Ÿæˆä¸¤ä¸ªå¯†é’¥ï¼Œ<code>id_rsa</code>å’Œ<code>id_rsa.pub</code>ä¸€ä¸ªç§é’¥ä¸€ä¸ªå…¬é’¥;å®ç°è¿œç¨‹è¿æ¥æœåŠ¡å™¨å…³é”®æ˜¯æŠŠ<strong>å…¬é’¥</strong>å­˜æ”¾åˆ°è¿œç¨‹æœåŠ¡å™¨ç«¯</p><h6 id="2-é…ç½®æœ¬åœ°configæ–‡ä»¶"><a href="#2-é…ç½®æœ¬åœ°configæ–‡ä»¶" class="headerlink" title="2.é…ç½®æœ¬åœ°configæ–‡ä»¶"></a>2.é…ç½®æœ¬åœ°configæ–‡ä»¶</h6><h6 id="3-å°†æœ¬åœ°å…¬é’¥ä¸Šä¼ è‡³æœåŠ¡å™¨"><a href="#3-å°†æœ¬åœ°å…¬é’¥ä¸Šä¼ è‡³æœåŠ¡å™¨" class="headerlink" title="3.å°†æœ¬åœ°å…¬é’¥ä¸Šä¼ è‡³æœåŠ¡å™¨"></a>3.å°†æœ¬åœ°å…¬é’¥ä¸Šä¼ è‡³æœåŠ¡å™¨</h6><p>åœ¨windows terminalä¸‹æ‰§è¡Œå‘½ä»¤</p><pre class="line-numbers language-none"><code class="language-none">scp C:\Users\VrShadow\.ssh\id_rsa.pub XXX@192.168.0.75:\home\xxx\<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>æœ¬åœ°å…¬é’¥æ‹·è´è‡³è¿œç¨‹æœåŠ¡å™¨[æ³¨æ„xxxæ›´æ”¹ä¸ºè‡ªå·±åœ¨è¿œç¨‹æœåŠ¡å™¨ç«¯åˆ†é…çš„ç”¨æˆ·åï¼ï¼ï¼],æ­¤æ—¶ä¼ è¿‡æ¥çš„å…¬é’¥å­˜åœ¨<code>./home/xxx</code>ä¸‹</p><h6 id="4-å…¬é’¥å†™å…¥æˆæƒæ–‡ä»¶"><a href="#4-å…¬é’¥å†™å…¥æˆæƒæ–‡ä»¶" class="headerlink" title="4.å…¬é’¥å†™å…¥æˆæƒæ–‡ä»¶"></a>4.å…¬é’¥å†™å…¥æˆæƒæ–‡ä»¶</h6><p>åœ¨è¿œç¨‹æœåŠ¡å™¨ä¸Šæ‰§è¡Œå‘½ä»¤</p><pre class="line-numbers language-none"><code class="language-none">touch ./.ssh/authorized_keys<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>è¿œç¨‹æœåŠ¡å™¨ç«¯è¿™è¾¹ç”¨çš„æ˜¯linuxç³»ç»Ÿï¼Œæ‰€ä»¥å…ˆè¦åˆ›å»ºæ–‡ä»¶<code>authorized_keys</code></p><p>å°†æœ¬åœ°ä¼ è¿‡æ¥çš„å¯†é’¥<strong>å†™å…¥authorizd_keys</strong>ä¸­</p><pre class="line-numbers language-none"><code class="language-none">cat ./home/xxx/id_rsa.pub >> ./.ssh/authorized_keys<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h5 id="2-vscodeå…å¯†ç™»å½•"><a href="#2-vscodeå…å¯†ç™»å½•" class="headerlink" title="2.vscodeå…å¯†ç™»å½•"></a>2.vscodeå…å¯†ç™»å½•</h5><h6 id="1-å‡†å¤‡æ’ä»¶SSH"><a href="#1-å‡†å¤‡æ’ä»¶SSH" class="headerlink" title="1.å‡†å¤‡æ’ä»¶SSH"></a>1.å‡†å¤‡æ’ä»¶SSH</h6><p>åœ¨æ’ä»¶é‡Œæœç´¢å®‰è£…å³å¯</p><h6 id="2-ä¿®æ”¹æœ¬åœ°configé…ç½®æ–‡ä»¶"><a href="#2-ä¿®æ”¹æœ¬åœ°configé…ç½®æ–‡ä»¶" class="headerlink" title="2.ä¿®æ”¹æœ¬åœ°configé…ç½®æ–‡ä»¶"></a>2.ä¿®æ”¹æœ¬åœ°configé…ç½®æ–‡ä»¶</h6><p>æœ¬åœ°configæ–‡ä»¶é‡Œé¢åŠ å…¥<strong>â€IdentifyFileâ€ â€C:\Users\VrShadow.ssh\id_rsaâ€</strong></p><p>å®Œæˆä¹‹åä¾§è¾¹å¯¼èˆªæ ä¼šå‡ºç°è¿œç¨‹èµ„æºç®¡ç†å™¨å›¾æ ‡ï¼Œç‚¹å‡»ä¹‹åé€‰æ‹©è¿œç¨‹æœåŠ¡å™¨æ—¶å¯¹åº”çš„ç«¯å£ä¸‹çš„åˆ†æ”¯ç”¨æˆ·ï¼Œç‚¹å‡»å°±ä¼šå¼€å¯æ–°çš„çª—å£(ç¬¬ä¸€æ¬¡ä¼šè®©ä½ é€‰æ‹©è¿œç¨‹æœåŠ¡å™¨çš„æ“ä½œç³»ç»Ÿ)ï¼Œä¹‹åå°±ä¼šè¿›å…¥å¯¹åº”ç”¨æˆ·ä¸‹çš„ç›®å½•è¿›è¡Œå·¥ä½œã€‚</p><h5 id="3-å¤–ç½‘è¿œç¨‹è¿æ¥"><a href="#3-å¤–ç½‘è¿œç¨‹è¿æ¥" class="headerlink" title="3.å¤–ç½‘è¿œç¨‹è¿æ¥"></a>3.å¤–ç½‘è¿œç¨‹è¿æ¥</h5><p>è‡ªå·±çš„æœ¬åœ°ç”¨æˆ·<code>.ssh</code>æ–‡ä»¶é‡Œé¢å·²ç»é…ç½®äº†<strong>config</strong>æ–‡ä»¶ï¼Œå·²ç»é…ç½®äº†jumpå†…ç½‘æƒé™<br>å‘½ä»¤è¡Œæ‰§è¡Œï¼š</p><pre class="line-numbers language-none"><code class="language-none">ssh jumpnone<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>æ‰§è¡Œåéœ€è¦è¿œç¨‹æœåŠ¡å™¨çš„å¯†ç ï¼š********</p><p>è¾“å…¥å¯†ç åè¿›è¡Œè¿œç¨‹è¿æ¥æ“ä½œ</p><pre class="line-numbers language-none"><code class="language-none">ssh username@host<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>å¦‚æœæœ¬åœ°ç”¨æˆ·åå’Œè¿œç¨‹ç”¨æˆ·åä¸€è‡´,ç™»å½•æ—¶å¯ä»¥çœç•¥ç”¨æˆ·å</p><pre class="line-numbers language-none"><code class="language-none">ssh host<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>SSHçš„é»˜è®¤ç«¯å£æ˜¯22,ä¹Ÿå°±æ˜¯è¯´ä½ çš„ç™»å½•è¯·æ±‚ä¼šé€è¿›è¿œç¨‹ä¸»æœºçš„22ç«¯å£.ä½¿ç”¨<code>-p</code>å‚æ•°å¯ä»¥ä¿®æ”¹ç«¯å£</p><pre><code>ssh -p 2222 user@host  # æ­¤æ¡å‘½ä»¤è¡¨ç¤ºsshç›´æ¥è¿æ¥è¿œç¨‹ä¸»æœºçš„2222ç«¯å£</code></pre><p>æˆ‘å†™çš„æ¯”è¾ƒç²—ç³™,(å·ä¸ªæ‡’)å¯ä»¥å‚è€ƒæˆ‘æœ‹å‹çš„blogï¼š</p><blockquote><p><a href="https://lry89757.github.io/2021/09/24/linux-bi-ji/">æœ‹å‹çš„åšå®¢</a></p></blockquote><p>ã€æœ€åçš„å®éªŒå°±æ˜¯å¦‚ä¸‹çš„æ•ˆæœ:</p><ul><li><p>è¿æ¥å¤–ç½‘çš„æƒ…å†µä¸‹</p><h5 id="è¿æ¥æœåŠ¡å™¨"><a href="#è¿æ¥æœåŠ¡å™¨" class="headerlink" title="è¿æ¥æœåŠ¡å™¨"></a>è¿æ¥æœåŠ¡å™¨</h5><pre><code># ä¸¤ç§æ–¹æ³•ï¼š(åœ¨å·²ç»é…ç½®å¥½confiå’Œå…¬é’¥æ–‡ä»¶ä¸‹å¹¶ä¸”æ‰“å¼€jumpè·³æ¿å’Œå¼€å¯â€œIdentiyfile"ä¸‹)ssh 43004   # å¿…é¡»è¦æ‰“å¼€è·³æ¿æƒé™,è€Œä¸”å›è½¦åæ¯æ¬¡éƒ½è¦è¾“å…¥æœåŠ¡å™¨æ‰€åœ¨å…¬ç½‘åœ°å€çš„å¯†ç             # å½“ç„¶åˆ†é…ç»™user@hostsçš„å¯†ç è¦çœ‹ä½ æ˜¯å¦æ³¨é‡Šäº†å…¬é’¥ssh gyf@192.168.0.75 # è¿™æ ·è®¿é—®åœ¨å†…ç½‘ä¸‹ä½¿ç”¨ï¼Œå½“ç„¶å†…ç½‘ä¸‹ä¹Ÿå¯ä»¥ä½¿ç”¨ssh 43004è¿æ¥æœåŠ¡å™¨</code></pre><ul><li><h5 id="å¤–ç½‘è®¿é—®"><a href="#å¤–ç½‘è®¿é—®" class="headerlink" title="å¤–ç½‘è®¿é—®"></a>å¤–ç½‘è®¿é—®</h5><ul><li><strong>ssh 43004</strong>:éœ€è¦è¾“å…¥æœåŠ¡å™¨æ‰€åœ¨å…¬ç½‘åœ°å€å¯†ç å’Œåˆ†é…ç»™ç”¨æˆ·çš„å¯†ç </li><li><strong>ssh user@host</strong>:ä¸èƒ½è¿æ¥æœåŠ¡å™¨</li></ul></li><li><h5 id="å†…ç½‘è®¿é—®"><a href="#å†…ç½‘è®¿é—®" class="headerlink" title="å†…ç½‘è®¿é—®"></a>å†…ç½‘è®¿é—®</h5><ul><li><strong>ssh 43004</strong>:ä»ç„¶éœ€è¦è¾“å…¥æœåŠ¡å™¨æ‰€åœ¨å…¬ç½‘åœ°å€å¯†ç ä½†æ˜¯ä¸ç”¨è¾“å…¥åˆ†é…ç»™ç”¨æˆ·çš„å¯†ç äº†</li><li><strong>ssh user@host</strong>:è¿™æ ·å…¬ç½‘å¯†ç å’Œåˆ†é…ç»™ç”¨æˆ·çš„å¯†ç éƒ½ä¸ç”¨è¾“å…¥äº†ç›´æ¥è¿æ¥</li></ul></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> æ­å»ºç¯å¢ƒ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> windows terminal </tag>
            
            <tag> ssh </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>è®ºæ–‡é˜…è¯»ä¸€:Attention Mechanism</title>
      <link href="/year/09/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB(%E4%B8%80)/"/>
      <url>/year/09/19/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB(%E4%B8%80)/</url>
      
        <content type="html"><![CDATA[<h4 id="Abstract-amp-amp-Introduction"><a href="#Abstract-amp-amp-Introduction" class="headerlink" title="Abstract &amp;&amp; Introduction"></a>Abstract &amp;&amp; Introduction</h4><p>â€‹    è¿™å‡ å¤©é˜…è¯»äº†ä¸€ç¯‡è¾ƒæ—©æå‡ºAttention machanismçš„è®ºæ–‡<a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a>,è¿™ç¯‡è®ºæ–‡å°†æ³¨æ„åŠ›æœºåˆ¶åº”ç”¨åœ¨ç¥ç»ç½‘ç»œç¿»è¯‘ä¸­ï¼Œè®ºæ–‡çš„æ€è·¯ä»ä¼ ç»ŸNMT(Neural Machine Translation)ç³»ç»Ÿçš„ç¼ºé™·è¯´èµ·ï¼Œé’ˆå¯¹å…¶è¿›è¡Œæ”¹è¿›ï¼Œæœ€åè¿›è¡Œäº†å®šé‡å’Œå®šæ€§åˆ†æ.</p><p>â€‹    é¦–å…ˆæˆ‘ä»¬è¦äº†è§£ç»å…¸çš„Sea2Seqæ¨¡å‹æ˜¯å¦‚ä½•è¿›è¡Œç¿»è¯‘çš„ï¼šæ•´ä½“æ¨¡å‹é‡‡ç”¨Encoder-Decoderè¿›è¡Œåˆ†æï¼Œå°†è¾“å…¥çš„åºåˆ—ç»è¿‡Encoderå¤„ç†ï¼Œå‹ç¼©æˆä¸€ä¸ªFixed-length Vectorï¼›åœ¨Decoderé˜¶æ®µï¼Œå°†è¿™ä¸ªå‘é‡çš„ä¿¡æ¯è¿˜åŸæˆä¸€ä¸ªåºåˆ—å®Œæˆç¿»è¯‘ä»»åŠ¡ã€‚åŸºäºRNNçš„Seq2Seqæ¨¡å‹ä¸»è¦ç”±ä¸¤ç¯‡æ–‡ç« ä»‹ç»ï¼Œåªæ˜¯é‡‡ç”¨äº†ä¸åŒçš„RNNæ¨¡å‹ã€‚Ilya Sutskeverç­‰äºº2014å¹´åœ¨è®ºæ–‡ã€ŠSequence to Sequence Learning with Neural Networksã€‹ä¸­ä½¿ç”¨LSTMæ¥æ­å»ºSeq2Seqæ¨¡å‹ã€‚éšåï¼Œ2015å¹´ï¼ŒKyunghyun Choç­‰äººåœ¨è®ºæ–‡ã€ŠLearning Phrase Representations using RNN Encoderâ€“Decoder for Statistical Machine Translationã€‹æå‡ºäº†åŸºäºGRUçš„Seq2Seqæ¨¡å‹ã€‚æƒ³è¦è§£å†³çš„ä¸»è¦é—®é¢˜å°±æ˜¯å¦‚ä½•æŠŠæœºå™¨ç¿»è¯‘ä¸­ï¼Œå˜é•¿çš„è¾“å…¥Xæ˜ å°„åˆ°ä¸€ä¸ªå˜é•¿è¾“å‡ºYã€‚è€Œè¿™ç¯‡è®ºæ–‡æå‡ºä¸€ç§æ–°çš„æ–¹æ³•ï¼Œè¿™ä¸ªæ–¹æ³•ä¹Ÿæ˜¯åŸºäº<code>encoder-decoder</code>çš„ï¼Œä¸ä¹‹å‰çš„<code>encoder-decoder</code>æ¨¡å‹ä¸åŒçš„æ˜¯ï¼Œæ¯æ¬¡åœ¨ç¿»è¯‘ä¸€ä¸ªå•è¯çš„æ—¶å€™ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨æœå¯»è¯¥å•è¯ä¸æºå¥å­å“ªäº›å•è¯æœ‰å…³è”ï¼Œå¹¶å°†è¿™ç§å…³è”çš„å¼ºåº¦è¿›è¡Œæ•°å­—åŒ–è¡¨ç¤º(åœ¨æ¨¡å‹ä¸­å°±æ˜¯æƒé‡)ï¼Œå¹¶ä¸”è®­ç»ƒå¾—å‡ºè¿™ç§æ–¹æ³•å¯ä»¥è§£å†³å¥å­ç¿»è¯‘ä¸å‡†çš„é—®é¢˜ã€‚</p><h4 id="ä¼ ç»ŸRNN"><a href="#ä¼ ç»ŸRNN" class="headerlink" title="ä¼ ç»ŸRNN"></a>ä¼ ç»ŸRNN</h4><p>â€‹    å¤§éƒ¨åˆ†çš„ç¥ç»æœºå™¨ç¿»è¯‘éƒ½æ˜¯åŸºäº<code>encoder-decoder</code>æ¡†æ¶çš„å¹¶ä¸”éƒ½ä¼šå°†æºè¯­è¨€å¥å­åºåˆ—å‹ç¼©æˆä¸€ä¸ªå›ºå®šçš„å‘é‡ï¼Œç„¶åä¼ é€’ç»™decoderã€‚ä¼ ç»Ÿçš„RNN Encoder-Decoderæ¨¡å‹åœ¨è®­ç»ƒé˜¶æ®µæ—¶å€™ï¼Œä¼šä½¿æ¨¡å‹å»æœ€å¤§åŒ–æºè¯­è¨€ç¿»è¯‘æˆç›®æ ‡è¯­è¨€çš„æ¡ä»¶æ¦‚ç‡ã€‚å½“æ¨¡å‹è®­ç»ƒå¥½ä¹‹åï¼Œå½“ä»£ç¿»è¯‘çš„æºè¯­è¨€å¥å­æ”¾å…¥åˆ°æ¨¡å‹ä¸­åï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨è®¡ç®—æœ€å¤§ç›®æ ‡å¥å­çš„æ¦‚ç‡å¹¶ä¸”å°†è¿™ä¸ªå¥å­å½“ä½œæ˜¯ç¿»è¯‘åçš„å¥å­ã€‚ç®€å•ä»‹ç»ä»¥ä¸‹ä¼ ç»Ÿçš„RNN:</p><p><img src="C:\Users\VrShadow\AppData\Roaming\Typora\typora-user-images\image-20210920180508294.png" alt="image-20210920180508294"></p><p>ä¸Šå›¾ä¸­<code>C</code>çš„å·¦ä¾§æ˜¯<code>Encoder</code>,å³ä¾§æ˜¯<code>Decoder</code>,â€Câ€æ˜¯å¾…ç¿»è¯‘è¯­å¥çš„è¯­ä¹‰ä¿¡æ¯ï¼›è¾“å…¥ä¸€ä¸ªå¥å­çš„æ—¶å€™ä¼šç»è¿‡Encoderï¼ŒEncoderè®²è¿™å¥è¯è¿›è¡Œç¼–ç ï¼ŒEncoderç”¨åˆ°çš„æ¨¡å‹æ˜¯RNNï¼Œç¼–ç ç»“æŸä»¥åå°†æœ€åä¸€ä¸ªæ—¶åˆ»RNNçš„éšå±‚çš„è¾“å‡ºå½“ä½œè¾“å…¥çš„è¿™å¥è¯çš„â€è¯­ä¹‰å‹ç¼©â€ã€‚ç„¶åè§£ç å™¨æ¯äº§ç”Ÿä¸€ä¸ªç¿»è¯‘åçš„è‹±æ–‡å•è¯çš„æ—¶å€™ï¼Œéƒ½ä¼šåˆ©ç”¨<strong>C</strong>å¹¶ä¸”è¿˜ä¼šæ¥å—è¾“å…¥tæ—¶åˆ»çš„ä¸Šä¸€ä¸ªéšè—å‘é‡<strong>s</strong>ã€‚è¿™ä¸ªæ—¶åˆ»çš„è¾“å‡ºç«¯å°±ä¼šäº§ç”Ÿç¬¬ä¸€ä¸ªå•è¯(è¿™é‡Œä½¿ç”¨äº†softmaxå‡½æ•°ï¼Œè¾“å‡ºå±‚æ˜¯ä¸€ä¸ªè¯å…¸å¤§å°ç»´åº¦çš„å‘é‡)ï¼Œå“ªä¸ªç»´åº¦çš„å€¼æœ€å¤§å°±å–å“ªä¸ªç»´åº¦æ‰€å¯¹åº”çš„å•è¯ã€‚å¤§å®¶å¯ä»¥æ˜ç™½çš„æ˜¯è®­ç»ƒé˜¶æ®µï¼ŒEncoderå’ŒDecoderä¸å¯èƒ½ç«‹é©¬äº§ç”Ÿç›®æ ‡å•è¯ï¼Œè€Œæ˜¯äº§ç”Ÿä¸€ä¸ªé¢„æµ‹ç»“æœï¼Œè®­ç»ƒçš„ç›®çš„å°±æ˜¯ä¸æ–­ä¼˜åŒ–å‚æ•°ã€‚</p><h4 id="Attentionæœºåˆ¶åŠ å…¥"><a href="#Attentionæœºåˆ¶åŠ å…¥" class="headerlink" title="Attentionæœºåˆ¶åŠ å…¥"></a>Attentionæœºåˆ¶åŠ å…¥</h4><p>æœ¬paperæå‡ºçš„æ¨¡å‹å«åš<strong>RNNsearch</strong>ï¼š</p><p><img src="C:\Users\VrShadow\AppData\Roaming\Typora\typora-user-images\image-20210920183014609.png" alt="image-20210920183014609"></p><p>â€‹    å›¾ä¸­çš„å³åŠéƒ¨åˆ†æ˜¯encoderï¼Œè¿™ä¸€éƒ¨åˆ†å’ŒRNNencæ¨¡å‹ä¸€æ ·ï¼Œé‡ç‚¹åœ¨decoderéƒ¨åˆ†å’Œä¼ ç»Ÿçš„ä¼šæœ‰å·¨å¤§çš„å·®åˆ«ï¼›åœ¨t=0æ—¶åˆ»ï¼Œdecoderçš„BiLSTMæ¥å—ä¸‰ä¸ªè¾“å…¥ï¼Œç¬¬ä¸€ä¸ªæ˜¯åˆå§‹çŠ¶æ€s0(è¿™ä¸ªæ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œæ— è®ºæ˜¯è®­ç»ƒé˜¶æ®µè¿˜æ˜¯é¢„æµ‹é˜¶æ®µéƒ½æ˜¯éšæœº)ï¼›ç¬¬äºŒä¸ªè¾“å…¥æ¥æºäºemdeddingåçš„å‘é‡ï¼›ç¬¬ä¸‰ä¸ªè¾“å…¥æ¯”è¾ƒå¤æ‚ï¼Œä¹Ÿæ˜¯æ–°æ¨¡å‹çš„æ ¸å¿ƒåˆ›æ–°ç‚¹</p><p>â€‹    é¦–å…ˆï¼Œéšæœºåˆ ç®—(è®¡ç®—æ–¹å¼æœ‰å¾ˆå¤šç§å¯ä»¥è‡ªå·±å®šä¹‰)ï¼Œå„è‡ªå¾—åˆ°ä¸€ä¸ªe1 ~ e6çš„å€¼ï¼Œå¯¹è¿™ä¸ª6ä¸ªå€¼è¿›è¡Œä¸€æ¬¡softmaxå¾—åˆ°Î±1 ~ Î±6ï¼Œå’Œæ˜¯1ï¼›å°†Î±1ï¼ŒÎ±2ï¼ŒÎ±3ï¼ŒÎ±4ï¼ŒÎ±5ï¼ŒÎ±6çœ‹ä½œæ˜¯s0å’Œh1 ~ h6çš„ç›¸ä¼¼åº¦ã€‚ç„¶åÎ±å’Œhå‘é‡åšä¸€æ¬¡å…ƒç´ ä¹˜ç§¯ï¼Œå¾—åˆ°çš„6ä¸ªå‘é‡åšä¸€æ¬¡å…ƒç´ çš„ç›¸åŠ å¾—åˆ°æœ€ç»ˆçš„å‘é‡ã€‚å°†è¿™ä¸ªå‘é‡å½“ä½œ0æ—¶åˆ»BiLSTMçš„ç¬¬ä¸‰ä¸ªè¾“å…¥ã€‚æ—¶åˆ»0ï¼ŒBiLSTMå°±ä¼šæœ‰ä¸€ä¸ªè¾“å‡ºï¼Œæ—¶åˆ»å˜ä¸º1ï¼Œæ¥ä¸‹æ¥çš„è¿‡ç¨‹ç»§ç»­å‘åè¿›è¡Œã€‚</p><p><a href="https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html">NLP From Scratch: Translation with a Sequence to Sequence Network and Attention</a>å®ç°Seq2Seq(Attention)åçš„æ¨¡å‹ï¼ŒåŸºæœ¬å®ç°äº†æ­¤ç¯‡è®ºæ–‡çš„åˆ›æ–°ç‚¹ã€‚</p>]]></content>
      
      
      <categories>
          
          <category> è®ºæ–‡ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ³¨æ„åŠ›æœºåˆ¶ </tag>
            
            <tag> nlp </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>åŸºç¡€ç®—æ³•è€Œå·²</title>
      <link href="/year/09/17/003/"/>
      <url>/year/09/17/003/</url>
      
        <content type="html"><![CDATA[<p>ç®—æ³•å…¥é—¨ï¼šå•Šå“ˆç®—æ³• ç®—æ³•å›¾è§£ å¤§è¯æ•°æ®ç»“æ„</p><p>ç®—æ³•è¿›é˜¶ï¼šcf ç™½ä¹¦ ç´«ä¹¦ è“ä¹¦</p><h2 id="ç¬¬ä¸€ç« -åŸºç¡€ç®—æ³•"><a href="#ç¬¬ä¸€ç« -åŸºç¡€ç®—æ³•" class="headerlink" title="ç¬¬ä¸€ç«  åŸºç¡€ç®—æ³•"></a>ç¬¬ä¸€ç«  åŸºç¡€ç®—æ³•</h2><h3 id="åŸºç¡€ç®—æ³•-ä¸€"><a href="#åŸºç¡€ç®—æ³•-ä¸€" class="headerlink" title="åŸºç¡€ç®—æ³•(ä¸€)"></a>åŸºç¡€ç®—æ³•(ä¸€)</h3><h4 id="æ’åº"><a href="#æ’åº" class="headerlink" title="æ’åº"></a>æ’åº</h4><ul><li>å«ä¹‰:æ’åºæ˜¯æŒ‡å°†ä¸€ä¸ªæ— åºåºåˆ—æŒ‰ç…§æŸä¸ªè§„åˆ™è¿›è¡Œæœ‰åºæ’åˆ—(ä»¥ä¸‹æ’åºå‡å®ç°çš„æ˜¯ä»å°åˆ°å¤§æ’åº)</li></ul><h5 id="ç®€å•æ’åº"><a href="#ç®€å•æ’åº" class="headerlink" title="ç®€å•æ’åº"></a>ç®€å•æ’åº</h5><ul><li><p>å†’æ³¡æ’åºçš„æœ¬è´¨åœ¨äº==äº¤æ¢== ï¼Œå³æ¯æ¬¡é€šè¿‡äº¤æ¢çš„æ–¹å¼æŠŠå½“å‰å‰©ä½™å…ƒç´ çš„æœ€å¤§å€¼ç§»åŠ¨åˆ°ä¸€ç«¯</p><pre class="line-numbers language-c++"><code class="language-c++"># å†’æ³¡æ’åº(ä»¥ä¸‹å®ç°ä»å°åˆ°å¤§æ’åº)int a[n]={......};for(int i=1;i<n;i++){  //è¿›è¡Œn-1èºº//ç¬¬ièººï¼Œä»a[0]-a[n-i-1]æ¯ä¸€ä¸ªæ•°éƒ½è¦ä¸ä¸‹ä¸€ä¸ªæ•°è¿›è¡Œæ¯”è¾ƒï¼Œé‡åˆ°åé¢æ¯”è‡ªå·±è¾ƒå¤§çš„æ•°å°±äº¤æ¢ï¼Œå®ç°æ¯ä¸€è¶Ÿå‰©ä½™çš„æ•°a[0]-a[n-    i]çš„å†’æ³¡æ’åºï¼Œä½¿å½“å‰a[0]~a[n-i]ä¸­çš„æœ€å¤§çš„å…ƒç´ ç§»åŠ¨åˆ°æœ€åé¢çš„,a[n-i+1]-a[i]å·²ç»æ’å¥½åº    for(int j=0;j< n-i;j++){        if(a[j] > a[j+1]){  //å¦‚æœå·¦è¾¹çš„æ•°æ›´å¤§ï¼Œåˆ™a[j]ä¸a[j+1]äº¤æ¢            int temp = a[j];            a[j] = a[j+1];            a[j+1] = temp;        }    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>(ç®€å•)é€‰æ‹©æ’åºï¼š</p><pre class="line-numbers language-c++"><code class="language-c++"># é€‰æ‹©æ’åº(ä»¥ä¸‹å®ç°ä»å°åˆ°å¤§æ’åº)# ç®€å•é€‰æ‹©æ’åºæ˜¯æŒ‡å¯¹ä¸€ä¸ªåºåˆ—a[n]ä¸­çš„å…ƒç´ a[1]~a[n]ï¼Œä»¤iä»1~nè¿›è¡Œæšä¸¾ï¼Œè¿›è¡Œnè¶Ÿæ“ä½œï¼Œæ¯è¶Ÿä»å¾…æ’åºéƒ¨åˆ†[i,n]å…¶ä¸­é€‰æ‹©æœ€å°çš„å…ƒç´ ï¼Œä»¤å…¶ä¸å¾…æ’éƒ¨åˆ†çš„ç¬¬ä¸€ä¸ªå…ƒç´ a[i]è¿›è¡Œäº¤æ¢ï¼Œè¿™æ ·å…ƒç´ a[i]å°±ä¼šä¸å½“å‰åŒºé—´[1,i-1]å½¢æˆæ–°çš„æœ‰åºåŒºé—´[1,i],nè¶Ÿæ“ä½œä»¥åï¼Œå°±å½¢æˆæœ‰åºåŒºé—´int a[n]={......};void select_sort(){    for(int i=1;i<=n;i++){  //è¿›è¡Œnè¶Ÿæ“ä½œ        int k = i;        for(int j=i;j<=n;j++){  //é€‰å‡º[i,n]ä¸­æœ€å°å…ƒç´ çš„ä¸‹æ ‡ï¼Œå¹¶ä¸”å°†ä¸‹æ ‡è®°ä¸ºk            if(a[j]<a[k]){                k = j;            }        }        int temp = a[i];  //äº¤æ¢a[k]ä¸å½“å‰å¾…æ’åºåºåˆ—[i,n]çš„ç¬¬ä¸€ä¸ªå…ƒç´ a[i]        a[i] = a[k];        a[j] = temp;    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>(ç›´æ¥)æ’å…¥æ’åºï¼š</p><pre class="line-numbers language-c++"><code class="language-c++"># ç›´æ¥æ’å…¥æ’åº# ç›´æ¥æ’å…¥æ’åºæ˜¯æŒ‡å¯¹åºåˆ—a[n]ä¸­çš„å…ƒç´ a[i]~a[n]ï¼Œiä»2~nè¿›è¡Œæšä¸¾ï¼Œè¿›è¡Œn-1è¶Ÿæ“ä½œã€‚å‡è®¾æŸä¸€è¶Ÿï¼Œåºåˆ—a[1]~a[i-1]å·²ç»æœ‰åºï¼Œé‚£ä¹ˆè¿™ä¸€æ¬¡å°±æ˜¯ä»èŒƒå›´[1,i-1]ä¸­å¯»æ‰¾æŸä¸ªä½ç½®j,ä½¿å¾—a[i]æ’å…¥åˆ°è¿™ä¸ªä½ç½®jåï¼Œæ­¤æ—¶a[j]~a[i-1]ä¼šè‡ªåŠ¨å‘åç§»åŠ¨ä¸€ä½åˆ°a[j+1]~a[i],èŒƒå›´a[1,i]æœ‰åºint a[n]={......};  //nä¸ºå…ƒç´ ä¸ªæ•°ï¼Œæ•°ç»„ä¸‹æ ‡ä¸º1~nvoid insert_sort(){    for(int i=2;i<=n;i++){  //è¿›è¡Œn-1è¶Ÿæ’åº        int temp = a[i],j = i; //tempä¸´æ—¶å­˜æ”¾a[i]        while(j>1 && temp<a[j-1]){            a[j] = a[j-1];            j--;        }        a[j] = temp;    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h5 id="å¿«æ’"><a href="#å¿«æ’" class="headerlink" title="å¿«æ’"></a>å¿«æ’</h5><ul><li><p>å¿«æ’çš„ä¸»è¦æ€æƒ³æ˜¯åˆ†æ²»</p><pre class="line-numbers language-c++"><code class="language-c++">//å¿«æ’çš„æ—¶é—´å¤æ‚åº¦æ˜¯nlogn(è¿™é‡Œæ‰€æŒ‡çš„æ˜¯å¹³å‡å¤æ‚åº¦)#include <iostream>acwing 785å¿«é€Ÿæ’åºusing namespace std;const int N = 1e6+10;int n;int q[N];void quick_sort(int q[], int l, int r){    if (l >= r) return;    int i = l - 1, j = r + 1, x = q[l + r >> 1];  //xçš„å–å€¼å¯ä»¥å–åŒºé—´é‡Œé¢ä»»æ„ä¸€ä¸ª    while (i < j)    {        do i ++ ; while (q[i] < x);        do j -- ; while (q[j] > x);        if (i < j) swap(q[i], q[j]);    }    quick_sort(q, l, j); //å¯¹å·¦è¾¹çš„è¿›è¡Œå¿«æ’    quick_sort(q, j + 1, r); //å¯¹å³è¾¹è¿›è¡Œå¿«æ’}int main(){    scanf("%d",&n);    for(int i=0;i<n;i++){        scanf("%d",&q[i]);    }    quick_sort(q,0,n-1);        for(int i=0;i<n;i++){        printf("%d ",q[i]);    }}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h5 id="å½’å¹¶æ’åº"><a href="#å½’å¹¶æ’åº" class="headerlink" title="å½’å¹¶æ’åº"></a>å½’å¹¶æ’åº</h5><ul><li><p>å½’å¹¶çš„ä¸»è¦æ€æƒ³ä¹Ÿæ˜¯åˆ†æ²»</p><pre class="line-numbers language-c++"><code class="language-c++">acwing787 å½’å¹¶æ’åº#include <iostream>using namespace std;const int N = 1e6+10;int n;int q[N];int tmp[N];void merge_sort(int q[],int l,int r){    if(l>=r) return ;        int mid = l+r >> 1;  //1ï¼šç¡®å®šåˆ†ç•Œç‚¹        merge_sort(q,l,mid);   //å¯¹å·¦å³ä¸¤è¾¹åˆ†åˆ«è¿›è¡Œå½’å¹¶æ’åº    merge_sort(q,mid+1,r);        // å°†å·¦å³ä¸¤è¾¹è¿›è¡Œå½’å¹¶æ’åºï¼ŒæŠŠä¸¤ä¸ªæœ‰åºçš„åºåˆ—æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œæ‹¼æ¥çš„æ–¹æ³•å°±æ˜¯å½’å¹¶    int k=0,i=l,j=mid+1;     while(i<=mid && j<= r){        if(q[i]<=q[j]) tmp[k++] = q[i++];        else tmp[k++] = q[j++];    }    while(i<=mid) tmp[k++]=q[i++];  //å¯¹äºq[l]~[mid]å’Œq[mid+1~r]ä¸¤ä¸ªåºåˆ—ï¼Œå¦‚æœå­˜åœ¨åºåˆ—æ²¡æœ‰å¾ªç¯ç»“æŸçš„è¯å°±ç›´æ¥                                åˆ°tmpåºåˆ—åé¢å³å¯    while(j<=r) tmp[k++]=q[j++];        for(i=l,j=0;i <= r;i++,j++) q[i] = tmp[j];}int main(){    scanf("%d",&n);    for(int i=0;i<n;i++) scanf("%d",&q[i]);        merge_sort(q,0,n-1);        for(int i=0;i<n;i++) printf("%d ",q[i]);        return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h4 id="äºŒåˆ†"><a href="#äºŒåˆ†" class="headerlink" title="äºŒåˆ†"></a>äºŒåˆ†</h4><h5 id="æ•´æ•°"><a href="#æ•´æ•°" class="headerlink" title="æ•´æ•°"></a>æ•´æ•°</h5><ul><li><p>æ•´æ•°äºŒåˆ†çš„æœ¬è´¨:æœ‰å•è°ƒæ€§çš„è¯ä¸€å®šå¯ä»¥äºŒåˆ†ï¼›ä½†æ˜¯èƒ½äºŒåˆ†çš„ä¸ä¸€å®šå…·æœ‰å•è°ƒæ€§<br>äºŒåˆ†çš„æœ¬è´¨æ˜¯å¯¹äºä¸€ä¸ªæ•´æ•°åŒºé—´ï¼Œæˆ‘ä»¬å…ˆå®šä¹‰ä¸€ä¸ªæ€§è´¨ï¼Œè¦æ‰¾åˆ°ä¸€ä¸ªä¸­é—´ç‚¹ï¼Œæ˜¯çš„åœ¨è¿™ä¸ªç‚¹çš„å³åŠè¾¹æ»¡è¶³è¿™ä¸ªæ€§è´¨ï¼Œå·¦åŠè¾¹ä¸æ»¡è¶³è¿™ä¸ªæ€§è´¨ï¼Œè¿™æ ·å°±å¯ä»¥æŠŠä¸€ä¸ªåŒºé—´ä¸€åˆ†ä¸ºäºŒï¼Œæ‰¾åˆ°è¿™ä¸ªè¾¹ç•Œ</p><pre class="line-numbers language-c++"><code class="language-c++">#1.æ‰¾åˆ°ä¸€ä¸ªä¸­é—´å€¼mid# if(check(mid)) true:midæ»¡è¶³è¿™ä¸ªæ€§è´¨  false:midä¸æ»¡è¶³è¿™ä¸ªæ€§è´¨# äºŒåˆ†çš„æ—¶å€™ä¸€å®šè¦ä¿è¯è¦å¯»æ‰¾çš„å€¼ä¸€å®šåœ¨ä¸æ–­ç¼©å°çš„é‚£ä¸ªåŒºé—´é‡Œé¢ï¼Œå½“åŒºé—´çš„é•¿åº¦ä¸º1çš„æ—¶å€™å°±ä»£è¡¨æ‰¾åˆ°ç­”æ¡ˆ#acwing789:æ•°çš„èŒƒå›´#include <iostream>#include <algorithm>#include <cstring>using namespace std;const int N=100010;int a,b;int q[N];int main(){    scanf("%d %d",&a,&b);    for(int i=0;i<a;i++) scanf("%d",&q[i]);        while(b--){        int x;        scanf("%d",&x);                int l=0,r=a-1;        while(l<r){            int mid= l+r >> 1;            if(q[mid]>=x) r=mid;            else l=mid+1;        }                if(q[l]!=x) cout<<"-1 -1"<<endl;  // è¿™ä¸ªè¡¨ç¤ºè¦å¯»æ‰¾çš„é‚£ä¸ªå€¼ä¸åœ¨åŒºé—´é‡Œé¢ï¼Œæ­¤æ—¶q[l]çš„å€¼æ˜¯ç¬¬ä¸€ä¸ªæ»¡è¶³å¤§äºxçš„æ•°        else{            cout<<l<<' ';                        int l=0,r=a-1;            while(l<r){                int mid= l+r+1 >> 1;                if(q[mid]<=x) l=mid;                else r=mid-1;            }            cout<<l        }    }    return 0;}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul><h5 id="æµ®ç‚¹æ•°"><a href="#æµ®ç‚¹æ•°" class="headerlink" title="æµ®ç‚¹æ•°"></a>æµ®ç‚¹æ•°</h5><ul><li><p>æµ®ç‚¹æ•°äºŒåˆ†:æœ¬è´¨ä¸Šä¹Ÿæ˜¯å¯»æ‰¾è¾¹ç•Œï¼Œæ»¡è¶³å·¦åŠè¾¹æ»¡è¶³æ€§è´¨ï¼Œå³åŠè¾¹ä¸æ»¡è¶³æ€§è´¨ï¼ŒçŸ¥é“</p></li><li><pre class="line-numbers language-c++"><code class="language-c++"># ä¾‹å­:ç®—å¹³æ–¹æ ¹#include <iostream>using namespace std;int mian(){    double x;    cin>>x;        double l=0,r=x;    double mid = (l+r)/2;    while(r-l > 1e-8){        if(mid*mid>=x)  r=mid;        else l=mid;    }        printf("%lf",&l);}<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> ç®—æ³• </category>
          
      </categories>
      
      
        <tags>
            
            <tag> æ’åºç®—æ³• </tag>
            
            <tag> acwing </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ç¬¬ä¸€ç¯‡ï¼Œè¡¨è¾¾ç‚¹çœ‹æ³•å§</title>
      <link href="/year/09/15/001/"/>
      <url>/year/09/15/001/</url>
      
        <content type="html"><![CDATA[<p><span class="github-emoji"><span>ğŸ˜„</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span><span class="github-emoji"><span>ğŸ˜†</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span><span class="github-emoji"><span>ğŸ˜†</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>å€¼å¾—è®°å½•ä¸€ä¸‹</p><p>è¿™æ˜¯æˆ‘çš„ç¬¬ä¸€ç¯‡åšæ–‡ï¼ŒèŠ±äº†å¾ˆé•¿æ—¶é—´æ¥è¿›è¡Œæ“ä½œï¼Œåœ¨ç½‘ä¸Šæœç´¢çš„æ•™ç¨‹å‚å·®ä¸é½ï¼Œä¹ŸåŒæ ·ä¼šå‡ºç°å„ç§å„æ ·çš„é—®é¢˜ï¼Œæ¯”å¦‚nodejsç‰ˆæœ¬è¿‡é«˜ä¸hexoä¸å…¼å®¹é—®é¢˜ï¼Œæˆ‘è§‰å¾—è¿˜æ˜¯æœ‰é—®é¢˜è¿˜æ˜¯è¦å¤šå’Œå…¶ä»–äººæ²Ÿé€šï¼Œå¦å¤–å¯¹ä¸»é¢˜çš„è®¾ç½®å¯ä»¥æŒ‰ç…§è‡ªå·±çš„é£æ ¼æ¥ï¼Œä½†æ˜¯è¿™å°±éœ€è¦å¯¹webçŸ¥è¯†æœ‰ä¸€å®šçš„äº†è§£ï¼Œå¯¹æ’ç‰ˆæœ‰è‡ªå·±çš„ç†è§£æ‰å¯ä»¥ã€‚<br>åœ¨æˆ‘çœ‹æ¥ï¼Œåšå®¢æ›´åŠ æ³¨é‡çš„åº”è¯¥æ˜¯å†…å®¹ï¼Œä»¥åŠå…»æˆè®°å½•æ—¥è®°çš„ä¹ æƒ¯ï¼Œå¯¹è‡ªå·±æ¯ä¸ªé˜¶æ®µçš„å­¦ä¹ æœ‰ä¸€ä¸ªé€‚å½“çš„æ€»ç»“ï¼Œå¯ä»¥è®©è‡ªå·±è®¡åˆ’æ›´åŠ æ˜ç¡®ã€‚<br>æ‰€ä»¥æˆ‘å°±ç®€å•ä»‹ç»hexo+github.ioæ­å»ºåšå®¢è¿‡ç¨‹ä¸­é‡è¦çš„ç‚¹å§(æˆ‘æ˜¯ç”¨çš„ä¸»é¢˜æ˜¯matery)</p><h4 id="æœ¬åœ°é…ç½®æ–‡ä»¶"><a href="#æœ¬åœ°é…ç½®æ–‡ä»¶" class="headerlink" title="æœ¬åœ°é…ç½®æ–‡ä»¶"></a>æœ¬åœ°é…ç½®æ–‡ä»¶</h4><p><img src="C:\Users\VrShadow\AppData\Roaming\Typora\typora-user-images\image-20210916214915453.png" alt="image-20210916214915453"></p><ul><li><p><strong>_config.yml</strong>ï¼š</p><p>ç½‘ç«™<strong>ç«™ç‚¹é…ç½®æ–‡ä»¶</strong>ï¼Œåˆå«æ ¹ç›®å½•ç«™ç‚¹é…ç½®æ–‡ä»¶ï¼Œåœ¨è¿™ä¸ªæ–‡ä»¶é‡Œé¢å¯ä»¥é…ç½®å¤§éƒ¨åˆ†çš„å‚æ•°</p></li><li><p><strong>scaffolds</strong>:</p><p>æ­¤æ–‡ä»¶å¤¹ä¼šæ”¾ä¸€äº›é»˜è®¤çš„æ–‡ä»¶ï¼Œç”¨æ¥å½“ä½œåˆ›å»ºåšæ–‡çš„æ¨¡æ¿mdæ–‡ä»¶ï¼Œhexoä¼šæ ¹æ®scaffoldæ¥å»ºç«‹æ–‡ä»¶ã€‚æ¨¡æ¿æ˜¯æŒ‡æ–°å»ºçš„mdæ–‡ä»¶ä¼šé»˜è®¤æ”¾å…¥æ¨¡æ¿æ–‡ä»¶çš„åˆå§‹å†…å®¹</p></li><li><p><strong>public</strong>ï¼š</p><p>è¿™ä¸ªæ–‡ä»¶çš„å†…å®¹æœ€ç»ˆéƒ½ä¼špushåˆ°githubä»“åº“ä¸­</p></li><li><p><strong>source</strong>:</p><p>è¿™ä¸ªæ–‡ä»¶å¤¹æ˜¯å­˜æ”¾ç”¨æˆ·èµ„æºçš„åœ°æ–¹ï¼Œé™¤äº†<code>_posts</code>æ–‡ä»¶å¤¹ä¹‹å¤–ï¼Œå¼€å¤´å‘½åä¸º_(ä¸‹åˆ’çº¿çš„æ–‡ä»¶/æ–‡ä»¶å¤¹ä»¥åŠéšè—çš„æ–‡ä»¶éƒ½ä¼šè¢«å¿½ç•¥)ã€‚markdownå’Œhtmlæ–‡ä»¶éƒ½ä¼šè¢«è§£æå¹¶æ”¾åˆ°<strong>public</strong>æ–‡ä»¶å¤¹é‡Œé¢ï¼Œè€Œå…¶ä»–æ–‡ä»¶ä¼šè¢«æ‹·è´åˆ°publicæ–‡ä»¶å¤¹ã€‚</p></li><li><p>**ä¸ºgithubä»“åº“æ·»åŠ readme</p><p>æ—¢ç„¶<code>source</code>æ–‡ä»¶å¤¹ä¸­çš„å†…å®¹ä¼šè¢«å…¨éƒ¨æ¨é€åˆ°publicæ–‡ä»¶å¤¹ï¼Œpublicæ–‡ä»¶å¤¹ä¸­çš„å†…å®¹æœ€ç»ˆåˆä¼šè¢«pushåˆ°githubä»“åº“ï¼Œæ‰€ä»¥å¦‚æœæƒ³è¦ä¸ºgithubä»“åº“æ·»åŠ readme.mdï¼Œåªè¦åœ¨sourceæ–‡ä»¶å¤¹ä¸­åˆ›å»ºå°±å¥½äº†ã€‚æœ€å<strong>éƒ¨ç½²</strong>åˆ°githubå°±æœ‰readmeäº†ã€‚ä½†æ˜¯ä¼šå‘ç°ï¼ŒREADME.mdæ–‡ä»¶éƒ¨ç½²çš„æ—¶å€™ä¼šè¢«è§£ææˆhtmlæ–‡ä»¶ï¼Œæ˜¾ç¤ºçš„æ˜¯htmlä»£ç ï¼Œä¸æ˜¯æˆ‘ä»¬æƒ³è¦çš„æ–‡æ¡£å†…å®¹ã€‚</p><p><strong>è§£å†³åŠæ³•</strong>ï¼šå°†åœ¨sourceæ–‡ä»¶å¤¹æ–°å»ºçš„README.mdé‡å‘½åä¸ºREMADE.MDWNï¼Œåœ¨é‡æ–°éƒ¨ç½²åˆ°githubã€‚(sourceæ–‡ä»¶å¤¹ä¸­ï¼Œ.mdä¼šè¢«è§£æä¸ºhtmlã€‚å¹¶æ”¾åˆ°publicæ–‡ä»¶å¤¹è¢«pushåˆ°githubï¼Œä½†.MDWNä¸ä¼šè¢«è§£æ)</p></li></ul><h4 id="ä¸€äº›å¸¸ç”¨çš„Hexoå‘½ä»¤"><a href="#ä¸€äº›å¸¸ç”¨çš„Hexoå‘½ä»¤" class="headerlink" title="ä¸€äº›å¸¸ç”¨çš„Hexoå‘½ä»¤"></a>ä¸€äº›å¸¸ç”¨çš„Hexoå‘½ä»¤</h4><ul><li><p>å¸¸ç”¨å‘½ä»¤</p><pre><code>hexo new "postName" #æ–°å»ºåšæ–‡hexo generate #ç”Ÿæˆé™æ€é¡µé¢è‡³publicç›®å½•hexo server #å¼€å¯é¢„è§ˆè®¿é—®ç«¯å£ï¼ˆé»˜è®¤ç«¯å£4000ï¼Œâ€™crtl+c'å…³é—­serverï¼‰hexo deploy #éƒ¨ç½²åˆ°githubhexo help #æŸ¥çœ‹å¸®åŠ©hexo version #æŸ¥çœ‹ç‰ˆæœ¬</code></pre></li><li><p>ç¼©å†™</p><pre><code>hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deploy</code></pre></li><li><p>ç»„åˆå‘½ä»¤</p><pre><code>hexo s -g #ç”Ÿæˆå¹¶æœ¬åœ°é¢„è§ˆhexo d -g #ç”Ÿæˆå¹¶éƒ¨ç½²åˆ°äº‘ç«¯</code></pre></li></ul>]]></content>
      
      
      <categories>
          
          <category> æµ‹è¯•ï¼Œæµ‹è¯•çš„å­åˆ†ç±» </category>
          
      </categories>
      
      
        <tags>
            
            <tag> åšæ–‡ </tag>
            
            <tag> æµ‹è¯• </tag>
            
            <tag> whatever </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>README.md</title>
      <link href="/year/09/14/README/"/>
      <url>/year/09/14/README/</url>
      
        <content type="html"><![CDATA[<h3 id="20201-9-17-ç¬¬ä¸€æ¬¡æ›´æ–°"><a href="#20201-9-17-ç¬¬ä¸€æ¬¡æ›´æ–°" class="headerlink" title="20201.9.17 ç¬¬ä¸€æ¬¡æ›´æ–°"></a>20201.9.17 ç¬¬ä¸€æ¬¡æ›´æ–°</h3><ul><li>å¯¹æ–‡ç« Front-matterä»‹ç»çš„ä¸€äº›åº”ç”¨å°è¯•å¢åŠ <ul><li>æ¯”å¦‚title,date,topï¼Œsummaryç­‰ï¼Œå‰©ä¸‹çš„å¾…æ›´æ–°å°è¯•<span class="github-emoji"><span>ğŸ‘Š</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f44a.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span><span class="github-emoji"><span>ğŸ’¤</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a4.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span></li></ul></li></ul><h3 id="2021-9-14-æ°´ç¬¬ä¸€ç¯‡ï¼Œå•¥åŠŸèƒ½æ²¡æœ‰"><a href="#2021-9-14-æ°´ç¬¬ä¸€ç¯‡ï¼Œå•¥åŠŸèƒ½æ²¡æœ‰" class="headerlink" title="2021.9.14 æ°´ç¬¬ä¸€ç¯‡ï¼Œå•¥åŠŸèƒ½æ²¡æœ‰"></a>2021.9.14 æ°´ç¬¬ä¸€ç¯‡ï¼Œå•¥åŠŸèƒ½æ²¡æœ‰</h3><ul><li>èƒ½æ­£å¸¸éƒ¨ç½²æ–‡ç« å’Œæ¸²æŸ“æ­£å¸¸</li><li>èƒ½å¤Ÿè®¿é—®blog</li></ul><h3 id="2021-11-05"><a href="#2021-11-05" class="headerlink" title="2021.11.05"></a>2021.11.05</h3><ul><li>å»ºç«™åŠŸèƒ½</li><li>ä¸è’œå­åˆå§‹åŒ–è®¡æ•°</li></ul><h3 id="2021-11-07"><a href="#2021-11-07" class="headerlink" title="2021.11.07"></a>2021.11.07</h3><ul><li>å…¨å±€æœç´¢</li><li>ä»£ç é«˜äº®</li></ul>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
